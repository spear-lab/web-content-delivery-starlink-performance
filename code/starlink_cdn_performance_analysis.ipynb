{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import ipaddress\n",
    "import datetime\n",
    "import requests\n",
    "import dns.message\n",
    "import pyasn\n",
    "import sys\n",
    "import ast\n",
    "import socket\n",
    "import statistics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import ipaddress\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import os, glob\n",
    "from matplotlib import colors as pltColors\n",
    "import geopandas\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib.lines import Line2D\n",
    "import copy\n",
    "import collections\n",
    "import sqlite3\n",
    "import haversine as hs\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.patches as patches\n",
    "from scipy import stats\n",
    "from matplotlib import ticker\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set formatting parameters and file paths\n",
    "rcParams[\"font.family\"] = \"CMU Sans Serif\"\n",
    "rcParams[\"font.size\"] = 10\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "# We are using the tab10 colormap\n",
    "cols = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "asndb = pyasn.pyasn(\"../dataset/ipasn_25082025.dat\")\n",
    "cloudflare_aim_path = \"../dataset/late-2025/cloudflare-AIM\"\n",
    "top_level_folder_path = \"../dataset/late-2025/ripe_atlas\"\n",
    "old_top_level_folder_path = \"../dataset/early-2025/ripe_atlas\"\n",
    "old_controlled_top_level_folder_path = \"../dataset/early-2025/controlled_nodes\"\n",
    "controlled_top_level_folder_path = \"../dataset/late-2025/controlled_nodes\"\n",
    "figs_top_level_folder_path = \"../figs\"\n",
    "ip_to_loc_map_filename = \"../dataset/ip_to_location.json\"\n",
    "ipinfo_ip_to_country_filename = \"../dataset/ip-to-country-Aug2025.csv\"\n",
    "prb_map_dict = {}\n",
    "prb_map_filename = \"../dataset/ripe_probe_date_archive_list.json\"\n",
    "# ip_country_map_filename = \"../dataset/cdn_ip_to_country_map.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "\n",
    "def ip_to_int(ip):\n",
    "    return int(ipaddress.ip_address(ip))\n",
    "\n",
    "def find_ip(ip,df):\n",
    "    ip_int = ip_to_int(ip)\n",
    "\n",
    "    result = df[(df['start_ip_int'] <= ip_int) & (df['end_ip_int'] >= ip_int)]\n",
    "\n",
    "    if len(result) == 1:\n",
    "        country = result['country_name'].iloc[0]\n",
    "        country_code = result['country'].iloc[0]\n",
    "        continent = result['continent_name'].iloc[0]\n",
    "        continent_code = result['continent'].iloc[0]\n",
    "        return {\n",
    "            'country': country,\n",
    "            'country_code': country_code,\n",
    "            'continent': continent,\n",
    "            'continent_code': continent_code\n",
    "        }\n",
    "\n",
    "    return None\n",
    "\n",
    "def reverse_dns_lookup(ip_address):\n",
    "    \"\"\"\n",
    "    Performs a reverse DNS lookup for a given IP address.\n",
    "    \n",
    "    Args:\n",
    "        ip_address (str): The IP address to look up.\n",
    "        \n",
    "    Returns:\n",
    "        str or None: The domain name if found, otherwise None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # gethostbyaddr returns a tuple: (hostname, aliaslist, ipaddrlist)\n",
    "        hostname, _, _ = socket.gethostbyaddr(ip_address)\n",
    "        return hostname\n",
    "    except socket.herror:\n",
    "        # Handle cases where no reverse DNS entry exists\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    \n",
    "def check_ip_version(ip):\n",
    "    try:\n",
    "        ip_obj = ipaddress.ip_address(ip)\n",
    "        if isinstance(ip_obj, ipaddress.IPv4Address):\n",
    "            return \"IPv4\"\n",
    "        elif isinstance(ip_obj, ipaddress.IPv6Address):\n",
    "            return \"IPv6\"\n",
    "    except ValueError:\n",
    "        return \"Invalid IP address\"\n",
    "    \n",
    "def is_valid_ipv4(ip):\n",
    "    try:\n",
    "        ipaddress.IPv4Address(ip)\n",
    "        return True\n",
    "    except ipaddress.AddressValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_to_loc = {}\n",
    "with open(ip_to_loc_map_filename, \"r\") as json_file:\n",
    "    ip_to_loc = json.load(json_file)\n",
    "    print(\"IP to Loc file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading IPInfo IP to country database\n",
    "ip_to_country_df = pd.read_csv(filepath_or_buffer=ipinfo_ip_to_country_filename,delimiter=',',keep_default_na=False)\n",
    "ip_to_country_df['start_ip_int'] = ip_to_country_df['start_ip'].apply(ip_to_int)\n",
    "ip_to_country_df['end_ip_int'] = ip_to_country_df['end_ip'].apply(ip_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS Measurements - Cloudflare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAOS queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"Starlink\"\n",
    "dns_server = \"cloudflare\"\n",
    "msm_type = \"dns\"\n",
    "\n",
    "acc_result_cf_filepath = os.path.join(top_level_folder_path,network_type,msm_type,dns_server,\"CHAOS\",\"acc_result\",f\"acc_dns_{dns_server}_CHAOS_final_result.json\")\n",
    "print(acc_result_cf_filepath)\n",
    "with open(acc_result_cf_filepath,\"r\") as file:\n",
    "    try:\n",
    "        cf_data = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_cf_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate probes with different country \n",
    "cf_prb_country_map = {}\n",
    "for prb_tuple_str, results in cf_data.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    \n",
    "    if prb_id not in cf_prb_country_map:\n",
    "        cf_prb_country_map[prb_id] = {}\n",
    "    if country_code not in cf_prb_country_map[prb_id]:\n",
    "        cf_prb_country_map[prb_id][country_code] = 0\n",
    "    cf_prb_country_map[prb_id][country_code] += len(results['response_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_country_wise_dns_CHAOS_response_time_dict = {}\n",
    "cf_country_prb_resolver_responsetime_dns_CHAOS_dict = {}\n",
    "for prb_tuple_str, results in cf_data.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    countries_dict = cf_prb_country_map[prb_id]\n",
    "    max_key_country = max(countries_dict,key=countries_dict.get)\n",
    "    if country_code == max_key_country:\n",
    "        if country_code not in cf_country_wise_dns_CHAOS_response_time_dict:\n",
    "            cf_country_wise_dns_CHAOS_response_time_dict[country_code] = []\n",
    "        cf_country_wise_dns_CHAOS_response_time_dict[country_code] += results['response_time']\n",
    "\n",
    "        if country_code not in cf_country_prb_resolver_responsetime_dns_CHAOS_dict:\n",
    "            cf_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code] = {}\n",
    "        if prb_id not in cf_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code]:\n",
    "            cf_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id] = {}\n",
    "        for idx, resolver_loc in enumerate(results['resolver_location']):\n",
    "                if resolver_loc not in cf_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id]:\n",
    "                    cf_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id][resolver_loc] = []\n",
    "                cf_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id][resolver_loc].append(results['response_time'][idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS Measurement - Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAOS queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"Starlink\"\n",
    "dns_server = \"google\"\n",
    "\n",
    "acc_result_google_filepath = os.path.join(top_level_folder_path,network_type,msm_type,dns_server,\"CHAOS\",\"acc_result\",f\"acc_dns_{dns_server}_CHAOS_final_result.json\")\n",
    "print(acc_result_google_filepath)\n",
    "with open(acc_result_google_filepath,\"r\") as file:\n",
    "    try:\n",
    "        google_data = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_google_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate probes with different country \n",
    "google_prb_country_map = {}\n",
    "for prb_tuple_str, results in google_data.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    \n",
    "    if prb_id not in google_prb_country_map:\n",
    "        google_prb_country_map[prb_id] = {}\n",
    "    if country_code not in google_prb_country_map[prb_id]:\n",
    "        google_prb_country_map[prb_id][country_code] = 0\n",
    "    google_prb_country_map[prb_id][country_code] += len(results['response_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_country_wise_dns_CHAOS_response_time_dict = {}\n",
    "google_country_prb_resolver_responsetime_dns_CHAOS_dict = {}\n",
    "for prb_tuple_str, results in google_data.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    countries_dict = google_prb_country_map[prb_id]\n",
    "    max_key_country = max(countries_dict,key=countries_dict.get)\n",
    "    if country_code == max_key_country:\n",
    "        if country_code not in google_country_wise_dns_CHAOS_response_time_dict:\n",
    "            google_country_wise_dns_CHAOS_response_time_dict[country_code] = []\n",
    "        google_country_wise_dns_CHAOS_response_time_dict[country_code] += results['response_time']\n",
    "\n",
    "        if country_code not in google_country_prb_resolver_responsetime_dns_CHAOS_dict:\n",
    "            google_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code] = {}\n",
    "        if prb_id not in google_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code]:\n",
    "            google_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id] = {}\n",
    "        for idx, resolver_loc_str in enumerate(results['resolver_location']):\n",
    "            if resolver_loc_str:\n",
    "                resolver_loc = resolver_loc_str.split(\"-\")[1]\n",
    "                if resolver_loc not in google_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id]:\n",
    "                    google_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id][resolver_loc] = []\n",
    "                google_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id][resolver_loc].append(results['response_time'][idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del google_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS Measurement - Quad9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAOS queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"Starlink\"\n",
    "dns_server = \"quad9\"\n",
    "msm_type = \"dns\"\n",
    "\n",
    "acc_result_quad9_filepath = os.path.join(top_level_folder_path,network_type,msm_type,dns_server,\"CHAOS\",\"acc_result\",f\"acc_dns_{dns_server}_CHAOS_final_result.json\")\n",
    "print(acc_result_quad9_filepath)\n",
    "with open(acc_result_quad9_filepath,\"r\") as file:\n",
    "    try:\n",
    "        quad9_data = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_quad9_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate probes with different country \n",
    "quad9_prb_country_map = {}\n",
    "for prb_tuple_str, results in quad9_data.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "\n",
    "    if prb_id not in quad9_prb_country_map:\n",
    "        quad9_prb_country_map[prb_id] = {}\n",
    "    if country_code not in quad9_prb_country_map[prb_id]:\n",
    "        quad9_prb_country_map[prb_id][country_code] = 0\n",
    "    quad9_prb_country_map[prb_id][country_code] += len(results['response_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad9_country_wise_dns_CHAOS_response_time_dict = {}\n",
    "quad9_country_prb_resolver_responsetime_dns_CHAOS_dict = {}\n",
    "for prb_tuple_str, results in quad9_data.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    countries_dict = quad9_prb_country_map[prb_id]\n",
    "    max_key_country = max(countries_dict,key=countries_dict.get)\n",
    "    if country_code == max_key_country:\n",
    "        if country_code not in quad9_country_wise_dns_CHAOS_response_time_dict:\n",
    "            quad9_country_wise_dns_CHAOS_response_time_dict[country_code] = []\n",
    "        quad9_country_wise_dns_CHAOS_response_time_dict[country_code] += results['response_time']\n",
    "\n",
    "        if country_code not in quad9_country_prb_resolver_responsetime_dns_CHAOS_dict:\n",
    "            quad9_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code] = {}\n",
    "        if prb_id not in quad9_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code]:\n",
    "            quad9_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id] = {}\n",
    "        for idx, resolver_loc_str in enumerate(results['resolver_location']):\n",
    "            resolver_loc = resolver_loc_str.split(\".\")[1]\n",
    "            if resolver_loc not in quad9_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id]:\n",
    "                quad9_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id][resolver_loc] = []\n",
    "            quad9_country_prb_resolver_responsetime_dns_CHAOS_dict[country_code][prb_id][resolver_loc].append(results['response_time'][idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del quad9_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlled Probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHAOS queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaos_controlled_nodes_filepath = f\"{controlled_top_level_folder_path}/dns/CHAOS/08-26-2025-10-59-20_files_list\"\n",
    "controlled_CHAOS_msms = {\n",
    "       \"Cloudflare\" : {},\n",
    "       \"Google\" : {},\n",
    "       \"Quad9\" : {},\n",
    "}\n",
    "for filename in glob.glob(os.path.join(chaos_controlled_nodes_filepath, '*.json')):\n",
    "\n",
    "        count_new_items = 0\n",
    "        f = open(filename)\n",
    "        print(filename)\n",
    "        data = json.load(f)\n",
    "\n",
    "        if \"user_details\" in data:\n",
    "                if \"dns_measurements\" in data:\n",
    "                        user_details = data[\"user_details\"]\n",
    "                        dns_measurements =  data[\"dns_measurements\"]\n",
    "\n",
    "                        isp = user_details[\"ISP_AS\"]\n",
    "                        if not \"14593\" in isp:\n",
    "                                continue\n",
    "                        country_code = user_details[\"Country\"]\n",
    "\n",
    "                        \n",
    "                        for dns_resolver in dns_measurements:\n",
    "                                resolver_msm = dns_measurements[dns_resolver]\n",
    "                                if country_code not in controlled_CHAOS_msms[dns_resolver]:\n",
    "                                        for dns_resolver in controlled_CHAOS_msms:\n",
    "                                                controlled_CHAOS_msms[dns_resolver][country_code] = {\n",
    "                                                        'response_time' : [],\n",
    "                                                        'resolver_location' : []\n",
    "                                                }\n",
    "                                if 'query_time' in resolver_msm:\n",
    "                                        controlled_CHAOS_msms[dns_resolver][country_code]['response_time'].append(resolver_msm['query_time'])\n",
    "                                        if 'resolver_id' in resolver_msm:\n",
    "                                                if not resolver_msm['resolver_id'] == \"\":\n",
    "                                                        controlled_CHAOS_msms[dns_resolver][country_code]['resolver_location'].append(resolver_msm['resolver_id'])\n",
    "                                                elif not resolver_msm['nsid'] == \"\":\n",
    "                                                        controlled_CHAOS_msms[dns_resolver][country_code]['resolver_location'].append(resolver_msm['nsid'])\n",
    "                                                else:\n",
    "                                                        controlled_CHAOS_msms[dns_resolver][country_code]['resolver_location'].append(\"\")\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add controlled node measurements to CHAOS ripe measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloudflare\n",
    "for country in controlled_CHAOS_msms['Cloudflare']:\n",
    "    if country not in cf_country_wise_dns_CHAOS_response_time_dict:\n",
    "        cf_country_wise_dns_CHAOS_response_time_dict[country] = []\n",
    "    cf_country_wise_dns_CHAOS_response_time_dict[country] += controlled_CHAOS_msms['Cloudflare'][country]['response_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google\n",
    "for country in controlled_CHAOS_msms['Google']:\n",
    "    if country not in google_country_wise_dns_CHAOS_response_time_dict:\n",
    "        google_country_wise_dns_CHAOS_response_time_dict[country] = []\n",
    "    google_country_wise_dns_CHAOS_response_time_dict[country] += controlled_CHAOS_msms['Google'][country]['response_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quad9\n",
    "for country in controlled_CHAOS_msms['Quad9']:\n",
    "    if country not in quad9_country_wise_dns_CHAOS_response_time_dict:\n",
    "        quad9_country_wise_dns_CHAOS_response_time_dict[country] = []\n",
    "    quad9_country_wise_dns_CHAOS_response_time_dict[country] += controlled_CHAOS_msms['Quad9'][country]['response_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAOS DNS Response Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_box(plot):\n",
    "    for i in range(2):\n",
    "        plt.setp(plot['boxes'][i], facecolor=cols[i], linewidth=1)\n",
    "        plt.setp(plot['medians'][i], color='yellow')\n",
    "\n",
    "\n",
    "common_countries = [\"US\", \"CA\" ,\"DE\", \"HU\", \"CL\", \"CO\", \"AU\", \"NZ\", \"PH\", \"GU\", \"BJ\", \"ZW\" , \"ZM\", \"MG\"]\n",
    "fig, ax = plt.subplots(figsize=(4.66, 2))\n",
    "\n",
    "pos1 = np.arange(0, 4 * len(common_countries), 4)\n",
    "pos2 = np.arange(1, 4 * len(common_countries) + 1, 4)\n",
    "pos3 = np.arange(2, 4 * len(common_countries) + 2, 4)\n",
    "\n",
    "ax.boxplot([cf_country_wise_dns_CHAOS_response_time_dict[country] for country in common_countries], positions=pos1, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[1], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "ax.boxplot([google_country_wise_dns_CHAOS_response_time_dict[country] for country in common_countries], positions=pos2, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[0], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "ax.boxplot([quad9_country_wise_dns_CHAOS_response_time_dict[country] for country in common_countries], positions=pos3, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[3], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "xspan = 4\n",
    "[ax.axvspan(i * xspan - 1, i * xspan - 1 + xspan, facecolor=\"k\", alpha=0.2)\n",
    "    for i in range(len(common_countries))\n",
    "    if i % 2 == 1]\n",
    "\n",
    "ax.set_xticks(np.arange(1.0, 4 * len(common_countries), 4))\n",
    "ax.set_xticklabels(common_countries)\n",
    "ax.set_ylabel(\"DNS Response Time [ms]\")\n",
    "ax.set_yticks(np.arange(0, 260, 50))\n",
    "# ax.set_ylim(-5,90)\n",
    "ax.xaxis.get_major_formatter()._usetex = False\n",
    "ax.yaxis.get_major_formatter()._usetex = False\n",
    "\n",
    "handles = [Patch(facecolor=cols[1]),Patch(facecolor=cols[0]),Patch(facecolor=cols[3])]\n",
    "labels = [\"Cloudflare\", \"Google\", \"Quad9\"]\n",
    "ax.set_xlim(-1,55)\n",
    "ax.legend(handles, labels, loc=\"upper left\", fontsize=\"small\", edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4)\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\")\n",
    "# plt.ylim(0,100)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/dns_comparison_CHAOS_rt_selected_countries.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/dns_comparison_CHAOS_rt_selected_countries.svg\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS Measurements - Cloudflare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudflare_dns_domains = [\"www.broadcom.com.\",\"www.comodoca.com.\",\"www.apnic.net.\",\"www.riskified.com.\",\"www.wiley.com.\",]\n",
    "akamai_dns_domains = [\"www.microsoft.com.\", \"www.apple.com.\",\"www.bing.com.\", \"www.icloud.com.\", \"www.intuit.com.\",]\n",
    "cloudfront_dns_domains = [ \"www.soundcloud.com.\",\"www.zynga.com.\",\"www.doi.org.\",\"www.booking.com.\",\"www.brave.com.\",]\n",
    "\n",
    "check_domains = [\"www.microsoft.com.\", \"www.apple.com.\",\"www.bing.com.\", \"www.icloud.com.\",]\n",
    "\n",
    "# Check top 500 domains\n",
    "check_domains_top500 = []\n",
    "tranco_df = pd.read_csv('../dataset/tranco_Sep2025.csv',header=0)\n",
    "for full_domain in cloudflare_dns_domains + akamai_dns_domains + cloudfront_dns_domains:\n",
    "    domain_split = full_domain.split(\".\")\n",
    "    tld_part = domain_split[1] + \".\" + domain_split[2]\n",
    "    domain_ranking = tranco_df.loc[(tranco_df['domain'] == tld_part), 'ranking'].iloc[0]\n",
    "    if domain_ranking <= 500:\n",
    "        check_domains_top500.append(full_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"Starlink\"\n",
    "dns_server = \"cloudflare\"\n",
    "msm_type = \"dns\"\n",
    "rd_bit = True\n",
    "\n",
    "acc_result_cf_filepath = os.path.join(top_level_folder_path,network_type,msm_type,dns_server,f\"RD-{str(rd_bit)}\",\"acc_result\",f\"acc_dns_{dns_server}_final_result.json\")\n",
    "with open(acc_result_cf_filepath,\"r\") as file:\n",
    "    try:\n",
    "        cf_data_resolution = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_cf_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add controlled nodes measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_WebMsms_folder_path = f\"{controlled_top_level_folder_path}/dns/WebMsms\"\n",
    "network_type = \"Starlink\"\n",
    "dns_server = \"cf\"\n",
    "msm_type = \"dns\"\n",
    "rd_bit = True\n",
    "\n",
    "acc_result_google_filepath = os.path.join(controlled_WebMsms_folder_path,\"acc_result\",f\"{dns_server}_controlled_DNS_acc_msms.json\")\n",
    "with open(acc_result_google_filepath,\"r\") as file:\n",
    "    try:\n",
    "        cf_controlled_data_resolution = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS controlled nodes accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_google_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cf_country_wise_dns_resolution_time = {}\n",
    "for prb_tuple_str, results in cf_data_resolution.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    if country_code not in cf_country_wise_dns_resolution_time:\n",
    "        cf_country_wise_dns_resolution_time[country_code] = {}\n",
    "    for domain, domain_results in results.items():\n",
    "        \n",
    "        if domain not in cf_country_wise_dns_resolution_time[country_code]:\n",
    "            cf_country_wise_dns_resolution_time[country_code][domain] = {\n",
    "                'resolved_ips': [],\n",
    "                'resolver_loc' : [],\n",
    "                'resolution_time_all' : [],\n",
    "                'resolution_time_hit' : [],\n",
    "                'resolution_time_miss' : [],\n",
    "            }\n",
    "\n",
    "        check_ttl = None\n",
    "        if domain in cloudflare_dns_domains:\n",
    "            check_ttl = 300\n",
    "        elif domain in akamai_dns_domains:\n",
    "            check_ttl = 20\n",
    "        elif domain in cloudfront_dns_domains:\n",
    "            check_ttl = 60\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        for idx, each_ans in enumerate(domain_results['dns_ans']):\n",
    "            if domain_results['response_time'][idx] > 15:\n",
    "                if each_ans['ip_addr_dict']:\n",
    "                    for _, ip_addr_list in each_ans['ip_addr_dict'].items():\n",
    "                        cf_country_wise_dns_resolution_time[country_code][domain]['resolved_ips'].append(ip_addr_list[0])\n",
    "                    cf_country_wise_dns_resolution_time[country_code][domain]['resolution_time_all'].append(domain_results['response_time'][idx])\n",
    "                    \n",
    "                    \n",
    "                    ttl_val = domain_results['ttls'][idx]\n",
    "\n",
    "                    if ttl_val == 0:\n",
    "                        continue\n",
    "                    elif ttl_val == check_ttl:\n",
    "                        cf_country_wise_dns_resolution_time[country_code][domain]['resolution_time_miss'].append(domain_results['response_time'][idx])\n",
    "                    elif ttl_val < check_ttl:\n",
    "                        cf_country_wise_dns_resolution_time[country_code][domain]['resolution_time_hit'].append(domain_results['response_time'][idx])\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_all_country_wise_dns_rt = {}\n",
    "\n",
    "for country_code in cf_country_wise_dns_resolution_time:\n",
    "    msm_results = cf_country_wise_dns_resolution_time[country_code]\n",
    "    if country_code not in cf_all_country_wise_dns_rt:\n",
    "        cf_all_country_wise_dns_rt[country_code] = {}\n",
    "    for domain , domain_results in msm_results.items():\n",
    "        if domain not in cf_all_country_wise_dns_rt[country_code]:\n",
    "            cf_all_country_wise_dns_rt[country_code][domain] = [] \n",
    "        cf_all_country_wise_dns_rt[country_code][domain] += domain_results['resolution_time_all']\n",
    "\n",
    "for country_code in cf_controlled_data_resolution:\n",
    "    msm_results = cf_controlled_data_resolution[country_code]\n",
    "    if country_code not in cf_all_country_wise_dns_rt:\n",
    "        cf_all_country_wise_dns_rt[country_code] = {}\n",
    "    for domain , domain_results in msm_results.items():\n",
    "        if domain not in cf_all_country_wise_dns_rt[country_code]:\n",
    "            cf_all_country_wise_dns_rt[country_code][domain] = []\n",
    "        cf_all_country_wise_dns_rt[country_code][domain] += domain_results['response_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS Measurements - Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"Starlink\"\n",
    "dns_server = \"google\"\n",
    "msm_type = \"dns\"\n",
    "rd_bit = True\n",
    "\n",
    "acc_result_google_filepath = os.path.join(top_level_folder_path,network_type,msm_type,dns_server,f\"RD-{str(rd_bit)}\",\"acc_result\",f\"acc_dns_{dns_server}_final_result.json\")\n",
    "print(acc_result_google_filepath)\n",
    "with open(acc_result_google_filepath,\"r\") as file:\n",
    "    try:\n",
    "        google_data_resolution = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_google_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add controlled nodes measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_WebMsms_folder_path = f\"{controlled_top_level_folder_path}/dns/WebMsms\"\n",
    "network_type = \"Starlink\"\n",
    "dns_server = \"google\"\n",
    "msm_type = \"dns\"\n",
    "rd_bit = True\n",
    "\n",
    "acc_result_google_filepath = os.path.join(controlled_WebMsms_folder_path,\"acc_result\",f\"{dns_server}_controlled_DNS_acc_msms.json\")\n",
    "with open(acc_result_google_filepath,\"r\") as file:\n",
    "    try:\n",
    "        google_controlled_data_resolution = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS controlled nodes accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_google_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "google_country_wise_dns_resolution_time = {}\n",
    "for prb_tuple_str, results in google_data_resolution.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    if country_code not in google_country_wise_dns_resolution_time:\n",
    "        google_country_wise_dns_resolution_time[country_code] = {}\n",
    "    for domain, domain_results in results.items():\n",
    "        if domain not in google_country_wise_dns_resolution_time[country_code]:\n",
    "            google_country_wise_dns_resolution_time[country_code][domain] = {\n",
    "                'resolved_ips': [],\n",
    "                'resolver_loc': [],\n",
    "                'resolution_time_all' : [],\n",
    "                'resolution_time_hit' : [],\n",
    "                'resolution_time_miss' : [],\n",
    "\n",
    "            }\n",
    "\n",
    "        check_ttl = None\n",
    "        if domain in cloudflare_dns_domains:\n",
    "            check_ttl = 300\n",
    "        elif domain in akamai_dns_domains:\n",
    "            check_ttl = 20\n",
    "        elif domain in cloudfront_dns_domains:\n",
    "            check_ttl = 60\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        for idx, each_ans in enumerate(domain_results['dns_ans']):\n",
    "            if domain_results['response_time'][idx] > 15:\n",
    "                if each_ans['ip_addr_dict']:\n",
    "                    for _, ip_addr_list in each_ans['ip_addr_dict'].items():\n",
    "                        google_country_wise_dns_resolution_time[country_code][domain]['resolved_ips'].append(ip_addr_list[0])\n",
    "                    google_country_wise_dns_resolution_time[country_code][domain]['resolution_time_all'].append(domain_results['response_time'][idx])\n",
    "\n",
    "                    resolver_loc_split = each_ans['nsid'].split('-')\n",
    "                    resolver_loc = \"\"\n",
    "                    if len(resolver_loc_split) == 2:\n",
    "                        resolver_loc = resolver_loc_split[1]\n",
    "                    google_country_wise_dns_resolution_time[country_code][domain]['resolver_loc'].append(resolver_loc)\n",
    "\n",
    "                    ttl_val = domain_results['ttls'][idx]\n",
    "\n",
    "                    if ttl_val == 0:\n",
    "                        continue\n",
    "                    elif ttl_val == check_ttl:\n",
    "                        google_country_wise_dns_resolution_time[country_code][domain]['resolution_time_miss'].append(domain_results['response_time'][idx])\n",
    "                    elif ttl_val < check_ttl:\n",
    "                        google_country_wise_dns_resolution_time[country_code][domain]['resolution_time_hit'].append(domain_results['response_time'][idx])\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_all_country_wise_dns_rt = {}\n",
    "\n",
    "for country_code in google_country_wise_dns_resolution_time:\n",
    "    msm_results = google_country_wise_dns_resolution_time[country_code]\n",
    "    if country_code not in google_all_country_wise_dns_rt:\n",
    "        google_all_country_wise_dns_rt[country_code] = {}\n",
    "    for domain , domain_results in msm_results.items():\n",
    "        if domain not in google_all_country_wise_dns_rt[country_code]:\n",
    "            google_all_country_wise_dns_rt[country_code][domain] = [] \n",
    "        google_all_country_wise_dns_rt[country_code][domain] += domain_results['resolution_time_all']\n",
    "\n",
    "for country_code in google_controlled_data_resolution:\n",
    "    msm_results = google_controlled_data_resolution[country_code]\n",
    "    if country_code not in google_all_country_wise_dns_rt:\n",
    "        google_all_country_wise_dns_rt[country_code] = {}\n",
    "    for domain , domain_results in msm_results.items():\n",
    "        if domain not in google_all_country_wise_dns_rt[country_code]:\n",
    "            google_all_country_wise_dns_rt[country_code][domain] = []\n",
    "        google_all_country_wise_dns_rt[country_code][domain] += domain_results['response_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS Measurements - Quad9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"Starlink\"\n",
    "dns_server = \"quad9\"\n",
    "msm_type = \"dns\"\n",
    "rd_bit = True\n",
    "\n",
    "acc_result_quad9_filepath = os.path.join(top_level_folder_path,network_type,msm_type,dns_server,f\"RD-{str(rd_bit)}\",\"acc_result\",f\"acc_dns_{dns_server}_final_result.json\")\n",
    "with open(acc_result_quad9_filepath,\"r\") as file:\n",
    "    try:\n",
    "        quad9_data_resolution = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_quad9_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add controlled nodes measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_WebMsms_folder_path = f\"{controlled_top_level_folder_path}/dns/WebMsms\"\n",
    "network_type = \"Starlink\"\n",
    "dns_server = \"quad9\"\n",
    "msm_type = \"dns\"\n",
    "rd_bit = True\n",
    "\n",
    "acc_result_quad9_filepath = os.path.join(controlled_WebMsms_folder_path,\"acc_result\",f\"{dns_server}_controlled_DNS_acc_msms.json\")\n",
    "with open(acc_result_quad9_filepath,\"r\") as file:\n",
    "    try:\n",
    "        quad9_controlled_data_resolution = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS controlled nodes accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_quad9_filepath, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quad9_country_wise_dns_resolution_time = {}\n",
    "for prb_tuple_str, results in quad9_data_resolution.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    if country_code not in quad9_country_wise_dns_resolution_time:\n",
    "        quad9_country_wise_dns_resolution_time[country_code] = {}\n",
    "    for domain, domain_results in results.items():\n",
    "        if domain not in quad9_country_wise_dns_resolution_time[country_code]:\n",
    "            quad9_country_wise_dns_resolution_time[country_code][domain] = {\n",
    "                'resolved_ips': [],\n",
    "                'resolver_loc': [],\n",
    "                'resolution_time_all' : [],\n",
    "                'resolution_time_hit' : [],\n",
    "                'resolution_time_miss' : [],\n",
    "            }\n",
    "\n",
    "        check_ttl = None\n",
    "        if domain in cloudflare_dns_domains:\n",
    "            check_ttl = 300\n",
    "        elif domain in akamai_dns_domains:\n",
    "            check_ttl = 20\n",
    "        elif domain in cloudfront_dns_domains:\n",
    "            check_ttl = 60\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        for idx, each_ans in enumerate(domain_results['dns_ans']):\n",
    "            if domain_results['response_time'][idx] > 15:\n",
    "                if each_ans['ip_addr_dict']:\n",
    "                    for _, ip_addr_list in each_ans['ip_addr_dict'].items():\n",
    "                        quad9_country_wise_dns_resolution_time[country_code][domain]['resolved_ips'].append(ip_addr_list[0])\n",
    "                    quad9_country_wise_dns_resolution_time[country_code][domain]['resolution_time_all'].append(domain_results['response_time'][idx])\n",
    "\n",
    "                    resolver_loc_split = each_ans['nsid'].split('.')\n",
    "                    resolver_loc = \"\"\n",
    "                    if len(resolver_loc_split) >= 2:\n",
    "                        resolver_loc = resolver_loc_split[1]\n",
    "                    quad9_country_wise_dns_resolution_time[country_code][domain]['resolver_loc'].append(resolver_loc)\n",
    "\n",
    "                    ttl_val = domain_results['ttls'][idx]\n",
    "\n",
    "                    if ttl_val == 0:\n",
    "                        continue\n",
    "                    elif ttl_val == check_ttl:\n",
    "                        quad9_country_wise_dns_resolution_time[country_code][domain]['resolution_time_miss'].append(domain_results['response_time'][idx])\n",
    "                    elif ttl_val < check_ttl:\n",
    "                        quad9_country_wise_dns_resolution_time[country_code][domain]['resolution_time_hit'].append(domain_results['response_time'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad9_all_country_wise_dns_rt = {}\n",
    "\n",
    "for country_code in quad9_country_wise_dns_resolution_time:\n",
    "    msm_results = quad9_country_wise_dns_resolution_time[country_code]\n",
    "    if country_code not in quad9_all_country_wise_dns_rt:\n",
    "        quad9_all_country_wise_dns_rt[country_code] = {}\n",
    "    for domain , domain_results in msm_results.items():\n",
    "        if domain not in quad9_all_country_wise_dns_rt[country_code]:\n",
    "            quad9_all_country_wise_dns_rt[country_code][domain] = [] \n",
    "        quad9_all_country_wise_dns_rt[country_code][domain] += domain_results['resolution_time_all']\n",
    "\n",
    "for country_code in quad9_controlled_data_resolution:\n",
    "    msm_results = quad9_controlled_data_resolution[country_code]\n",
    "    if country_code not in quad9_all_country_wise_dns_rt:\n",
    "        quad9_all_country_wise_dns_rt[country_code] = {}\n",
    "    for domain , domain_results in msm_results.items():\n",
    "        if domain not in quad9_all_country_wise_dns_rt[country_code]:\n",
    "            quad9_all_country_wise_dns_rt[country_code][domain] = []\n",
    "        quad9_all_country_wise_dns_rt[country_code][domain] += domain_results['response_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_box(plot):\n",
    "    for i in range(2):\n",
    "        plt.setp(plot['boxes'][i], facecolor=cols[i], linewidth=1)\n",
    "        plt.setp(plot['medians'][i], color='yellow')\n",
    "\n",
    "\n",
    "common_countries = [\"US\", \"CA\" ,\"DE\", \"HU\", \"CL\", \"CO\", \"AU\", \"NZ\", \"PH\", \"GU\", \"BJ\", \"ZM\", \"MG\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.66, 2))\n",
    "\n",
    "pos1 = np.arange(0, 4 * len(common_countries), 4)\n",
    "pos2 = np.arange(1, 4 * len(common_countries) + 1, 4)\n",
    "pos3 = np.arange(2, 4 * len(common_countries) + 2, 4)\n",
    "\n",
    "cf_dns_resolution_time_all = {}\n",
    "google_dns_resolution_time_all = {}\n",
    "quad9_dns_resolution_time_all = {}\n",
    "\n",
    "domain_list = check_domains_top500\n",
    "\n",
    "for country in common_countries:\n",
    "    for domain in domain_list:\n",
    "        if country not in cf_dns_resolution_time_all:\n",
    "            cf_dns_resolution_time_all[country] = []\n",
    "            google_dns_resolution_time_all[country] = []\n",
    "            quad9_dns_resolution_time_all[country] = []\n",
    "\n",
    "        if country in cf_all_country_wise_dns_rt:\n",
    "            cf_dns_resolution_time_all[country] += cf_all_country_wise_dns_rt[country][domain]\n",
    "        if country in google_all_country_wise_dns_rt:\n",
    "            google_dns_resolution_time_all[country] += google_all_country_wise_dns_rt[country][domain]\n",
    "        if country in quad9_all_country_wise_dns_rt:\n",
    "            quad9_dns_resolution_time_all[country] += quad9_all_country_wise_dns_rt[country][domain]\n",
    "\n",
    "\n",
    "ax.boxplot([cf_dns_resolution_time_all[country] for country in common_countries], positions=pos1, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[1], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "ax.boxplot([google_dns_resolution_time_all[country]  for country in common_countries], positions=pos2, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[0], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "ax.boxplot([quad9_dns_resolution_time_all[country]  for country in common_countries], positions=pos3, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[3], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "xspan = 4\n",
    "[ax.axvspan(i * xspan - 1, i * xspan - 1 + xspan, facecolor=\"k\", alpha=0.2)\n",
    "    for i in range(len(common_countries))\n",
    "    if i % 2 == 1]\n",
    "\n",
    "ax.set_xticks(np.arange(1.0, 4 * len(common_countries), 4))\n",
    "ax.set_xticklabels(common_countries)\n",
    "ax.set_ylabel(\"DNS Resolution Time [ms]\")\n",
    "ax.set_yticks(np.arange(0, 600, 100))\n",
    "# ax.set_ylim(-5,90)\n",
    "ax.xaxis.get_major_formatter()._usetex = False\n",
    "ax.yaxis.get_major_formatter()._usetex = False\n",
    "\n",
    "handles = [Patch(facecolor=cols[1]),Patch(facecolor=cols[0]),Patch(facecolor=cols[3])]\n",
    "labels = [\"Cloudflare\", \"Google\", \"Quad9\"]\n",
    "ax.set_xlim(-1,51)\n",
    "ax.legend(handles, labels, loc=\"upper left\", fontsize=\"small\", edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4)\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\")\n",
    "# plt.ylim(0,100)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/dns_resolution_time_comparison_selected_countries_all.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/dns_resolution_time_comparison_selected_countries_all.svg\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDN Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traceroute Measurements - Cloudflare CDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"cloudflare\"\n",
    "cf_acc_tracert_json = None\n",
    "full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "print(full_msms_path)\n",
    "acc_cf_tracert_filename = \"acc_trace_cloudflare_final_result.json\"\n",
    "acc_cf_tracert_filepath = os.path.join(full_msms_path,'acc_result',acc_cf_tracert_filename)\n",
    "with open(acc_cf_tracert_filepath, \"r\") as json_file:\n",
    "    cf_acc_tracert_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_country_wise_cdn_rtts_stl = {}\n",
    "cf_country_wise_pop_rtts_stl = {}\n",
    "\n",
    "idx = 0\n",
    "for each_msm in cf_acc_tracert_json:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "\n",
    "    if country_code not in cf_country_wise_cdn_rtts_stl:\n",
    "        cf_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        cf_country_wise_pop_rtts_stl[country_code] = []\n",
    "\n",
    "\n",
    "    dst_addr = each_msm['dst_addr']\n",
    "    \n",
    "    total_dst_rtts = []\n",
    "    for idx, hop_ip in enumerate(each_msm['all_hops'][-1]['hop_ips']):\n",
    "        if hop_ip == dst_addr:\n",
    "            total_dst_rtts.append(each_msm['all_hops'][-1]['hop_rtts'][idx])\n",
    "    \n",
    "    if len(total_dst_rtts):\n",
    "        cf_country_wise_cdn_rtts_stl[country_code].append(min(total_dst_rtts))\n",
    "    \n",
    "    if len(total_dst_rtts) and len(each_msm['pop_rtts']):\n",
    "        if statistics.mean(total_dst_rtts) > statistics.mean(each_msm['pop_rtts']):\n",
    "            cf_country_wise_pop_rtts_stl[country_code].append(min(each_msm['pop_rtts']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cf_acc_tracert_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traceroute Measurements - Akamai CDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"akamai\"\n",
    "\n",
    "full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "print(full_msms_path)\n",
    "acc_akamai_tracert_filename = \"acc_trace_akamai_final_result.json\"\n",
    "acc_akamai_tracert_filepath = os.path.join(full_msms_path,'acc_result',acc_akamai_tracert_filename)\n",
    "with open(acc_akamai_tracert_filepath, \"r\") as json_file:\n",
    "    akamai_acc_tracert_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akamai_country_wise_cdn_rtts_stl = {}\n",
    "akamai_country_wise_pop_rtts_stl = {}\n",
    "\n",
    "idx = 0\n",
    "for each_msm in akamai_acc_tracert_json:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    dst_addr = each_msm['dst_addr']\n",
    "    \n",
    "    total_dst_rtts = []\n",
    "    for idx, hop_ip in enumerate(each_msm['all_hops'][-1]['hop_ips']):\n",
    "        if hop_ip == dst_addr:\n",
    "            total_dst_rtts.append(each_msm['all_hops'][-1]['hop_rtts'][idx])\n",
    "\n",
    "    if country_code not in akamai_country_wise_cdn_rtts_stl:\n",
    "        akamai_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        akamai_country_wise_pop_rtts_stl[country_code] = []\n",
    "\n",
    "    if len(total_dst_rtts):\n",
    "        akamai_country_wise_cdn_rtts_stl[country_code].append(min(total_dst_rtts))\n",
    "    \n",
    "    if len(total_dst_rtts) and len(each_msm['pop_rtts']):\n",
    "        if statistics.mean(total_dst_rtts) > statistics.mean(each_msm['pop_rtts']):\n",
    "            akamai_country_wise_pop_rtts_stl[country_code].append(min(each_msm['pop_rtts']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(akamai_country_wise_cdn_rtts_stl.keys())\n",
    "print(akamai_country_wise_pop_rtts_stl.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add ZM measurements which were filtered out because of intermediate hops not being visible - but still got response from destination CDN server \n",
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"akamai\"\n",
    "country_to_add = 'ZM'\n",
    "akamai_country_cdn_rtts = {}\n",
    "country_total_msms = 0\n",
    "\n",
    "if os.path.exists(prb_map_filename):\n",
    "    with open(prb_map_filename, \"r\") as json_file:\n",
    "        prb_map_dict = json.load(json_file)\n",
    "    print(\"Prb Map JSON file loaded successfully\")\n",
    "else:\n",
    "    print(\"Error: No Prb Map JSON file found\")\n",
    "\n",
    "full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "print(full_msms_path)\n",
    "\n",
    "\n",
    "ip_to_asn = {}\n",
    "\n",
    "first_hop_filtered_json_list = []\n",
    "non_starlink_ip_set = set ()\n",
    "\n",
    "bad_probe_data_set = set()\n",
    "\n",
    "\n",
    "file_index = 1\n",
    "num_files = len(glob.glob(os.path.join(full_msms_path, '*.json')))\n",
    "print(num_files)\n",
    "\n",
    "for filename in glob.glob(os.path.join(full_msms_path, '*.json')):\n",
    "\n",
    "    count_new_items = 0\n",
    "    f = open(filename)\n",
    "    print(filename)\n",
    "    data = json.load(f)\n",
    "    \n",
    "    i=0\n",
    "    rows=0\n",
    "    for idx in tqdm(range(0,len(data))):\n",
    "        test = data[idx]\n",
    "\n",
    "        if 'result' in test:\n",
    "            # check probe id and server address in same country\n",
    "            # by checking set1_ripe_atlas_probe_dict ,or\n",
    "            # by querying RIPE Atlas API\n",
    "            prb_id = str(test['prb_id'])\n",
    "            msm_date = datetime.datetime.fromtimestamp(test['timestamp']).strftime('%Y-%m-%d')\n",
    "            client_ip = test['from']\n",
    "            if not is_valid_ipv4(client_ip):\n",
    "                continue\n",
    "            ip_version = check_ip_version(client_ip)\n",
    "            country_code = None\n",
    "            in_net_hops = []\n",
    "            gs_rtts = []\n",
    "            gw_rtts = []\n",
    "            last_hop_rtts = []\n",
    "            pop_rtts = []\n",
    "            ixp_rtts = []\n",
    "            gs_hop_id = 0\n",
    "            gs_hop_ip = ''\n",
    "            gw_hop_id = 0\n",
    "            gw_hop_ips = []\n",
    "            pop_hop_id = 0\n",
    "            pop_hop_ips = []\n",
    "            ixp_hop_id = 0\n",
    "            ixp_hop_ips = []\n",
    "            all_hops = []\n",
    "            if 'dst_addr' not in test:\n",
    "                continue\n",
    "            dst_addr = test['dst_addr']\n",
    "            prb_in_map =  False\n",
    "            asn_info = None\n",
    "            country_code = None\n",
    "\n",
    "            if prb_id in prb_map_dict:\n",
    "                if msm_date in prb_map_dict[prb_id]:\n",
    "                    if client_ip in prb_map_dict[prb_id][msm_date]:\n",
    "                        prb_in_map = True\n",
    "                        asn_info = prb_map_dict[prb_id][msm_date][client_ip]['asn']\n",
    "                        country_code = prb_map_dict[prb_id][msm_date][client_ip]['country_code']\n",
    "                        # print(f\"Found probe details for {prb_id} from prb_map for {msm_date} with ip {client_ip}\")\n",
    "            \n",
    "            # Request probe details\n",
    "            if not prb_in_map:\n",
    "                print(f\"Requesting probe details for {prb_id} from ripe atlas api for {msm_date} with ip {client_ip}\")\n",
    "                r = requests.get(f'https://atlas.ripe.net/api/v2/probes/archive/?probe={prb_id}&date={msm_date}', allow_redirects=True)\n",
    "\n",
    "                if not r.ok:\n",
    "                    # print(f\"Not getting appropriate probe response. Status Code: {r.status_code}\")\n",
    "                    continue\n",
    "                probe_data = r.json()\n",
    "\n",
    "                if 'results' not in probe_data:\n",
    "                    # print('No results key in probe_data. Trying alternative sources')\n",
    "                    asn_info, _ = asndb.lookup(client_ip)\n",
    "                    ip_geo_details = find_ip(client_ip,ip_to_country_df)\n",
    "                    if asn_info and ip_geo_details['country_code']:\n",
    "                        if prb_id not in prb_map_dict:\n",
    "                                prb_map_dict[prb_id] = {}\n",
    "                        if msm_date not in prb_map_dict[prb_id]:\n",
    "                            prb_map_dict[prb_id][msm_date] = {}\n",
    "                        if client_ip not in prb_map_dict[prb_id][msm_date]:\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip] = {}\n",
    "                        prb_map_dict[prb_id][msm_date][client_ip]['country_code'] = ip_geo_details['country_code']\n",
    "                        prb_map_dict[prb_id][msm_date][client_ip]['asn'] = asn_info\n",
    "                        country_code = ip_geo_details['country_code']\n",
    "                    else:\n",
    "                        bad_probe_data_set.add(prb_id)\n",
    "                        continue\n",
    "                if len(probe_data['results']) <= 0:\n",
    "                    # print(\"Empty results list in probe_data. Trying alternative sources\")\n",
    "                    asn_info, _ = asndb.lookup(client_ip)\n",
    "                    ip_geo_details = find_ip(client_ip,ip_to_country_df)\n",
    "                    if asn_info and ip_geo_details['country_code']:\n",
    "                        if prb_id not in prb_map_dict:\n",
    "                                prb_map_dict[prb_id] = {}\n",
    "                        if msm_date not in prb_map_dict[prb_id]:\n",
    "                            prb_map_dict[prb_id][msm_date] = {}\n",
    "                        if client_ip not in prb_map_dict[prb_id][msm_date]:\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip] = {}\n",
    "                        prb_map_dict[prb_id][msm_date][client_ip]['country_code'] = ip_geo_details['country_code']\n",
    "                        prb_map_dict[prb_id][msm_date][client_ip]['asn'] = asn_info\n",
    "                        country_code = ip_geo_details['country_code']\n",
    "                    else:\n",
    "                        bad_probe_data_set.add(prb_id)\n",
    "                        continue\n",
    "\n",
    "                if 'results' in probe_data:    \n",
    "                    for probe_details in probe_data['results']:\n",
    "                        # Find appropriate ASN based on client ip address seen in measurement\n",
    "                        # print(probe_details)\n",
    "                        asn_info = 0\n",
    "                        if ip_version == \"IPv4\":\n",
    "                            if probe_details['address_v4'] is not None and probe_details['address_v4'] == client_ip:\n",
    "                                asn_info = probe_details['asn_v4']\n",
    "                        elif ip_version == \"IPv6\":\n",
    "                            if probe_details['address_v6'] is not None and probe_details['address_v6'] == client_ip:\n",
    "                                asn_info = probe_details['asn_v6']\n",
    "\n",
    "                        \n",
    "                        if asn_info == 0:\n",
    "                            asn_info, _ = asndb.lookup(client_ip)\n",
    "                            # print(f\"ASN info blank in RIPE Atlas database for prb_id: {prb_id}. ASNDB answer -> asn: {asn_info}\")\n",
    "\n",
    "\n",
    "                        if asn_info is not None and asn_info != 0:\n",
    "                            country_code = probe_details['country_code']\n",
    "                            lat  = probe_details['geometry']['coordinates'][1]\n",
    "                            lon  = probe_details['geometry']['coordinates'][0]\n",
    "\n",
    "                            if prb_id not in prb_map_dict:\n",
    "                                prb_map_dict[prb_id] = {}\n",
    "                            if msm_date not in prb_map_dict[prb_id]:\n",
    "                                prb_map_dict[prb_id][msm_date] = {}\n",
    "                            if client_ip not in prb_map_dict[prb_id][msm_date]:\n",
    "                                prb_map_dict[prb_id][msm_date][client_ip] = {}\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip]['country_code'] = country_code\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip]['asn'] = asn_info\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip]['latitude'] = lat\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip]['longitude'] = lon\n",
    "\n",
    "                            break\n",
    "\n",
    "            asn_info, _ = asndb.lookup(client_ip)\n",
    "            if asn_info not in [14593,45700]:\n",
    "                # print(f\"Not a Starlink measurement. asndb is {asn_info}. Client IP is {client_ip}\")\n",
    "                non_starlink_ip_set.add(client_ip)\n",
    "                continue\n",
    "            \n",
    "            if country_code != country_to_add:\n",
    "                continue\n",
    "            \n",
    "            # print(\"Checking ZM msm\")\n",
    "            # add all hops\n",
    "            for hop in test['result']:\n",
    "                this_hop_ips = []\n",
    "                this_hop_rtts = []\n",
    "\n",
    "                if 'result' in hop:\n",
    "                    for each_result in hop['result']:\n",
    "                        if 'from' in each_result:\n",
    "                            if 'rtt' in each_result:\n",
    "                                this_hop_ips.append(each_result['from'])\n",
    "                                this_hop_rtts.append(each_result['rtt'])\n",
    "                    if len(this_hop_rtts):\n",
    "                        all_hops.append({\n",
    "                            \"hop_id\" : hop['hop'],\n",
    "                            \"hop_ips\" : this_hop_ips,\n",
    "                            \"hop_rtts\" : this_hop_rtts\n",
    "                        })\n",
    "            \n",
    "            total_dst_rtts = []\n",
    "            if len(all_hops):\n",
    "                for idx, hop_ip in enumerate(all_hops[-1]['hop_ips']):\n",
    "                    if hop_ip == dst_addr:\n",
    "                        total_dst_rtts.append(all_hops[-1]['hop_rtts'][idx])\n",
    "                if country_code not in akamai_country_cdn_rtts:\n",
    "                    akamai_country_cdn_rtts[country_code] = []\n",
    "                if len(total_dst_rtts):\n",
    "                    akamai_country_cdn_rtts[country_code].append(min(total_dst_rtts))\n",
    "                    country_total_msms +=1\n",
    "\n",
    "                \n",
    "    print(f'{file_index} out of {num_files} files')\n",
    "    file_index = file_index + 1\n",
    "\n",
    "    with open(prb_map_filename, \"w+\") as json_file:\n",
    "                json.dump(prb_map_dict, json_file, indent=4)\n",
    "\n",
    "print(f\"Traceroute filtering successfully completed\")\n",
    "print(f\"{country_to_add} msms to be added = {country_total_msms}\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akamai_country_wise_cdn_rtts_stl['ZM'] = akamai_country_cdn_rtts['ZM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del akamai_acc_tracert_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traceroute Measurements - Cloudfront CDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"cloudfront\"\n",
    "\n",
    "full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "print(full_msms_path)\n",
    "acc_cloudfront_tracert_filename = \"acc_trace_cloudfront_final_result.json\"\n",
    "acc_cloudfront_tracert_filepath = os.path.join(full_msms_path,'acc_result',acc_cloudfront_tracert_filename)\n",
    "with open(acc_cloudfront_tracert_filepath, \"r\") as json_file:\n",
    "    cloudfront_acc_tracert_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudfront_country_wise_cdn_rtts_stl = {}\n",
    "cloudfront_country_wise_pop_rtts_stl = {}\n",
    "\n",
    "idx = 0\n",
    "for each_msm in cloudfront_acc_tracert_json:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    dst_addr = each_msm['dst_addr']\n",
    "    \n",
    "    total_dst_rtts = []\n",
    "    for idx, hop_ip in enumerate(each_msm['all_hops'][-1]['hop_ips']):\n",
    "        if hop_ip == dst_addr:\n",
    "            total_dst_rtts.append(each_msm['all_hops'][-1]['hop_rtts'][idx])\n",
    "\n",
    "\n",
    "    if country_code not in cloudfront_country_wise_cdn_rtts_stl:\n",
    "        cloudfront_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        cloudfront_country_wise_pop_rtts_stl[country_code] = []\n",
    "\n",
    "    if len(total_dst_rtts):\n",
    "        cloudfront_country_wise_cdn_rtts_stl[country_code].append(min(total_dst_rtts))\n",
    "    \n",
    "    if len(total_dst_rtts) and len(each_msm['pop_rtts']):\n",
    "        if statistics.mean(total_dst_rtts) > statistics.mean(each_msm['pop_rtts']):\n",
    "       \n",
    "            cloudfront_country_wise_pop_rtts_stl[country_code].append(min(each_msm['pop_rtts']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add ZM measurements which were filtered out because of intermediate hops not being visible - but still got response from destination CDN server \n",
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"cloudfront\"\n",
    "country_to_add = 'ZM'\n",
    "cloudfront_country_cdn_rtts = {}\n",
    "country_total_msms = 0\n",
    "\n",
    "if os.path.exists(prb_map_filename):\n",
    "    with open(prb_map_filename, \"r\") as json_file:\n",
    "        prb_map_dict = json.load(json_file)\n",
    "    print(\"Prb Map JSON file loaded successfully\")\n",
    "else:\n",
    "    print(\"Error: No Prb Map JSON file found\")\n",
    "\n",
    "full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "print(full_msms_path)\n",
    "\n",
    "\n",
    "ip_to_asn = {}\n",
    "\n",
    "first_hop_filtered_json_list = []\n",
    "non_starlink_ip_set = set ()\n",
    "\n",
    "bad_probe_data_set = set()\n",
    "\n",
    "\n",
    "file_index = 1\n",
    "num_files = len(glob.glob(os.path.join(full_msms_path, '*.json')))\n",
    "try: \n",
    "    for filename in glob.glob(os.path.join(full_msms_path, '*.json')):\n",
    "\n",
    "        count_new_items = 0\n",
    "        f = open(filename)\n",
    "        print(filename)\n",
    "        data = json.load(f)\n",
    "        \n",
    "        i=0\n",
    "        rows=0\n",
    "        for idx in tqdm(range(0,len(data))):\n",
    "            test = data[idx]\n",
    "\n",
    "            if 'result' in test:\n",
    "                # check probe id and server address in same country\n",
    "                # by checking set1_ripe_atlas_probe_dict ,or\n",
    "                # by querying RIPE Atlas API\n",
    "                prb_id = str(test['prb_id'])\n",
    "                msm_date = datetime.datetime.fromtimestamp(test['timestamp']).strftime('%Y-%m-%d')\n",
    "                client_ip = test['from']\n",
    "                if not is_valid_ipv4(client_ip):\n",
    "                    continue\n",
    "                ip_version = check_ip_version(client_ip)\n",
    "                country_code = None\n",
    "                in_net_hops = []\n",
    "                gs_rtts = []\n",
    "                gw_rtts = []\n",
    "                last_hop_rtts = []\n",
    "                pop_rtts = []\n",
    "                ixp_rtts = []\n",
    "                gs_hop_id = 0\n",
    "                gs_hop_ip = ''\n",
    "                gw_hop_id = 0\n",
    "                gw_hop_ips = []\n",
    "                pop_hop_id = 0\n",
    "                pop_hop_ips = []\n",
    "                ixp_hop_id = 0\n",
    "                ixp_hop_ips = []\n",
    "                all_hops = []\n",
    "                if 'dst_addr' not in test:\n",
    "                    continue\n",
    "                dst_addr = test['dst_addr']\n",
    "                prb_in_map =  False\n",
    "                asn_info = None\n",
    "                country_code = None\n",
    "\n",
    "                if prb_id in prb_map_dict:\n",
    "                    if msm_date in prb_map_dict[prb_id]:\n",
    "                        if client_ip in prb_map_dict[prb_id][msm_date]:\n",
    "                            prb_in_map = True\n",
    "                            asn_info = prb_map_dict[prb_id][msm_date][client_ip]['asn']\n",
    "                            country_code = prb_map_dict[prb_id][msm_date][client_ip]['country_code']\n",
    "                            # print(f\"Found probe details for {prb_id} from prb_map for {msm_date} with ip {client_ip}\")\n",
    "                \n",
    "                # Request probe details\n",
    "                if not prb_in_map:\n",
    "                    print(f\"Requesting probe details for {prb_id} from ripe atlas api for {msm_date} with ip {client_ip}\")\n",
    "                    r = requests.get(f'https://atlas.ripe.net/api/v2/probes/archive/?probe={prb_id}&date={msm_date}', allow_redirects=True)\n",
    "\n",
    "                    if not r.ok:\n",
    "                        # print(f\"Not getting appropriate probe response. Status Code: {r.status_code}\")\n",
    "                        continue\n",
    "                    probe_data = r.json()\n",
    "\n",
    "                    if 'results' not in probe_data:\n",
    "                        # print('No results key in probe_data. Trying alternative sources')\n",
    "                        asn_info, _ = asndb.lookup(client_ip)\n",
    "                        ip_geo_details = find_ip(client_ip,ip_to_country_df)\n",
    "                        if asn_info and ip_geo_details['country_code']:\n",
    "                            if prb_id not in prb_map_dict:\n",
    "                                    prb_map_dict[prb_id] = {}\n",
    "                            if msm_date not in prb_map_dict[prb_id]:\n",
    "                                prb_map_dict[prb_id][msm_date] = {}\n",
    "                            if client_ip not in prb_map_dict[prb_id][msm_date]:\n",
    "                                prb_map_dict[prb_id][msm_date][client_ip] = {}\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip]['country_code'] = ip_geo_details['country_code']\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip]['asn'] = asn_info\n",
    "                            country_code = ip_geo_details['country_code']\n",
    "                        else:\n",
    "                            bad_probe_data_set.add(prb_id)\n",
    "                            continue\n",
    "                    if len(probe_data['results']) <= 0:\n",
    "                        # print(\"Empty results list in probe_data. Trying alternative sources\")\n",
    "                        asn_info, _ = asndb.lookup(client_ip)\n",
    "                        ip_geo_details = find_ip(client_ip,ip_to_country_df)\n",
    "                        if asn_info and ip_geo_details['country_code']:\n",
    "                            if prb_id not in prb_map_dict:\n",
    "                                    prb_map_dict[prb_id] = {}\n",
    "                            if msm_date not in prb_map_dict[prb_id]:\n",
    "                                prb_map_dict[prb_id][msm_date] = {}\n",
    "                            if client_ip not in prb_map_dict[prb_id][msm_date]:\n",
    "                                prb_map_dict[prb_id][msm_date][client_ip] = {}\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip]['country_code'] = ip_geo_details['country_code']\n",
    "                            prb_map_dict[prb_id][msm_date][client_ip]['asn'] = asn_info\n",
    "                            country_code = ip_geo_details['country_code']\n",
    "                        else:\n",
    "                            bad_probe_data_set.add(prb_id)\n",
    "                            continue\n",
    "\n",
    "                    if 'results' in probe_data:    \n",
    "                        for probe_details in probe_data['results']:\n",
    "                            # Find appropriate ASN based on client ip address seen in measurement\n",
    "                            # print(probe_details)\n",
    "                            asn_info = 0\n",
    "                            if ip_version == \"IPv4\":\n",
    "                                if probe_details['address_v4'] is not None and probe_details['address_v4'] == client_ip:\n",
    "                                    asn_info = probe_details['asn_v4']\n",
    "                            elif ip_version == \"IPv6\":\n",
    "                                if probe_details['address_v6'] is not None and probe_details['address_v6'] == client_ip:\n",
    "                                    asn_info = probe_details['asn_v6']\n",
    "\n",
    "                            \n",
    "                            if asn_info == 0:\n",
    "                                asn_info, _ = asndb.lookup(client_ip)\n",
    "                                # print(f\"ASN info blank in RIPE Atlas database for prb_id: {prb_id}. ASNDB answer -> asn: {asn_info}\")\n",
    "\n",
    "\n",
    "                            if asn_info is not None and asn_info != 0:\n",
    "                                country_code = probe_details['country_code']\n",
    "                                lat  = probe_details['geometry']['coordinates'][1]\n",
    "                                lon  = probe_details['geometry']['coordinates'][0]\n",
    "\n",
    "                                if prb_id not in prb_map_dict:\n",
    "                                    prb_map_dict[prb_id] = {}\n",
    "                                if msm_date not in prb_map_dict[prb_id]:\n",
    "                                    prb_map_dict[prb_id][msm_date] = {}\n",
    "                                if client_ip not in prb_map_dict[prb_id][msm_date]:\n",
    "                                    prb_map_dict[prb_id][msm_date][client_ip] = {}\n",
    "                                prb_map_dict[prb_id][msm_date][client_ip]['country_code'] = country_code\n",
    "                                prb_map_dict[prb_id][msm_date][client_ip]['asn'] = asn_info\n",
    "                                prb_map_dict[prb_id][msm_date][client_ip]['latitude'] = lat\n",
    "                                prb_map_dict[prb_id][msm_date][client_ip]['longitude'] = lon\n",
    "\n",
    "                                break\n",
    "\n",
    "                asn_info, _ = asndb.lookup(client_ip)\n",
    "                if asn_info not in [14593,45700]:\n",
    "                    # print(f\"Not a Starlink measurement. asndb is {asn_info}. Client IP is {client_ip}\")\n",
    "                    non_starlink_ip_set.add(client_ip)\n",
    "                    continue\n",
    "                \n",
    "\n",
    "                if country_code != country_to_add:\n",
    "                    continue\n",
    "                \n",
    "                # print(\"Checking ZM msm\")\n",
    "                # add all hops\n",
    "                for hop in test['result']:\n",
    "                    this_hop_ips = []\n",
    "                    this_hop_rtts = []\n",
    "\n",
    "                    if 'result' in hop:\n",
    "                        for each_result in hop['result']:\n",
    "                            if 'from' in each_result:\n",
    "                                if 'rtt' in each_result:\n",
    "                                    this_hop_ips.append(each_result['from'])\n",
    "                                    this_hop_rtts.append(each_result['rtt'])\n",
    "                        if len(this_hop_rtts):\n",
    "                            all_hops.append({\n",
    "                                \"hop_id\" : hop['hop'],\n",
    "                                \"hop_ips\" : this_hop_ips,\n",
    "                                \"hop_rtts\" : this_hop_rtts\n",
    "                            })\n",
    "                \n",
    "                total_dst_rtts = []\n",
    "                for idx, hop_ip in enumerate(all_hops[-1]['hop_ips']):\n",
    "                    if hop_ip == dst_addr:\n",
    "                        total_dst_rtts.append(all_hops[-1]['hop_rtts'][idx])\n",
    "                if country_code not in cloudfront_country_cdn_rtts:\n",
    "                    cloudfront_country_cdn_rtts[country_code] = []\n",
    "                if len(total_dst_rtts):\n",
    "                    cloudfront_country_cdn_rtts[country_code].append(min(total_dst_rtts))\n",
    "                    country_total_msms +=1\n",
    "\n",
    "                    \n",
    "        print(f'{file_index} out of {num_files} files')\n",
    "        file_index = file_index + 1\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    with open(prb_map_filename, \"w+\") as json_file:\n",
    "                json.dump(prb_map_dict, json_file, indent=4)\n",
    "\n",
    "print(f\"Traceroute filtering successfully completed\")\n",
    "print(f\"{country_to_add} msms to be added = {country_total_msms}\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudfront_country_wise_cdn_rtts_stl['ZM'] = cloudfront_country_cdn_rtts['ZM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cloudfront_acc_tracert_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traceroute Measurements - Add Controlled Nodes measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_nodes_traceroute_files_path = f\"{controlled_top_level_folder_path}/traceroute/08-27-2025-12-31-18_WebTrace_files_list\"\n",
    "\n",
    "cdns_list = [\"cloudflare\", \"akamai\", \"cloudfront\"]\n",
    "countries_added_set = set()\n",
    "hop_ip_match = 0\n",
    "hop_ip_no_match = 0\n",
    "for cdn_name in cdns_list:\n",
    "    acc_tracert_filename = f\"controlled_nodes_acc_trace_{cdn_name}_final_result_late.json\"\n",
    "    acc_tracert_filepath = os.path.join(controlled_nodes_traceroute_files_path,'acc_result',acc_tracert_filename)\n",
    "    with open(acc_tracert_filepath, \"r\") as json_file:\n",
    "        acc_tracert_json = json.load(json_file)\n",
    "\n",
    "    idx = 0\n",
    "    for each_msm in acc_tracert_json:\n",
    "        country_code = each_msm['country_code']\n",
    "        prb_id = each_msm['prb_id']\n",
    "        dst_addr = each_msm['dst_addr']\n",
    "        unix_timestamp = each_msm['timestamp']\n",
    "\n",
    "        threshold_date = datetime.datetime(2025,8,11)\n",
    "        timestamp_date = datetime.datetime.fromtimestamp(unix_timestamp)\n",
    "        \n",
    "        if timestamp_date < threshold_date:\n",
    "            continue\n",
    "\n",
    "        prefix = None\n",
    "        if cdn_name == \"cloudflare\":\n",
    "            prefix = \"cf\"\n",
    "        else:\n",
    "            prefix = cdn_name\n",
    "        cdn_rtts_stl = eval(f\"{prefix}_country_wise_cdn_rtts_stl\")\n",
    "        pop_rtts_stl = eval(f\"{prefix}_country_wise_pop_rtts_stl\")\n",
    "\n",
    "\n",
    "        if country_code not in cdn_rtts_stl:\n",
    "            cdn_rtts_stl[country_code] = []\n",
    "        if country_code not in pop_rtts_stl:\n",
    "            pop_rtts_stl[country_code] = []\n",
    "\n",
    "        total_dst_rtts = []\n",
    "        for idx, hop_ip in enumerate(each_msm['all_hops'][-1]['hop_ips']):\n",
    "            if hop_ip == dst_addr:\n",
    "                total_dst_rtts.append(each_msm['all_hops'][-1]['hop_rtts'][idx])\n",
    "                hop_ip_match += 1\n",
    "            else:\n",
    "                print(f\"Hop IP: {hop_ip}, DST IP: {dst_addr}\")\n",
    "                hop_ip_no_match += 1\n",
    "\n",
    "        if len(total_dst_rtts):\n",
    "            cdn_rtts_stl[country_code].append(min(total_dst_rtts))\n",
    "\n",
    "        if len(total_dst_rtts) and len(each_msm['pop_rtts']):\n",
    "            if statistics.mean(total_dst_rtts) > statistics.mean(each_msm['pop_rtts']):\n",
    "                pop_rtts_stl[country_code].append(min(each_msm['pop_rtts']))\n",
    "                countries_added_set.add(country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_box(plot):\n",
    "    for i in range(2):\n",
    "        plt.setp(plot['boxes'][i], facecolor=cols[i], linewidth=1)\n",
    "        plt.setp(plot['medians'][i], color='yellow')\n",
    "\n",
    "countries = [\"US\", \"CA\" ,\"DE\", \"HU\", \"CL\", \"CO\", \"AU\", \"NZ\" ,\"PH\", \"GU\", \"BJ\", \"ZW\" , \"ZM\", \"MG\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.66, 2))\n",
    "\n",
    "pos1 = np.arange(0, 4 * len(countries), 4)\n",
    "pos2 = np.arange(1, 4 * len(countries) + 1, 4)\n",
    "pos3 = np.arange(2, 4 * len(countries) + 2, 4)\n",
    "\n",
    "cf_country_wise_cdn_rtts_stl_filtered = {}\n",
    "akamai_country_wise_cdn_rtts_stl_filtered = {}\n",
    "cloudfront_country_wise_cdn_rtts_stl_filtered = {}\n",
    "\n",
    "# Filter out outliers less than 15 ms -- for Starlink msms \n",
    "for country in countries:\n",
    "    cf_country_wise_cdn_rtts_stl_filtered[country] = [cf_rtt for cf_rtt in cf_country_wise_cdn_rtts_stl[country] if cf_rtt > 15]\n",
    "    akamai_country_wise_cdn_rtts_stl_filtered[country] = [ak_rtt for ak_rtt in akamai_country_wise_cdn_rtts_stl[country] if ak_rtt > 15]\n",
    "    cloudfront_country_wise_cdn_rtts_stl_filtered[country] = [cfront_rtt for cfront_rtt in cloudfront_country_wise_cdn_rtts_stl[country] if cfront_rtt > 15]\n",
    "\n",
    "ax.boxplot([cf_country_wise_cdn_rtts_stl_filtered[country] for country in countries], positions=pos1, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[1], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "ax.boxplot([akamai_country_wise_cdn_rtts_stl_filtered[country] for country in countries], positions=pos2, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[2], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "ax.boxplot([cloudfront_country_wise_cdn_rtts_stl_filtered[country] for country in countries], positions=pos3, patch_artist=True,\n",
    "           showfliers=False, boxprops=dict(facecolor=cols[4], lw=1), medianprops=dict(color=\"yellow\"))\n",
    "xspan = 4\n",
    "[ax.axvspan(i * xspan - 1, i * xspan - 1 + xspan, facecolor=\"k\", alpha=0.2)\n",
    "    for i in range(len(countries))\n",
    "    if i % 2 == 1]\n",
    "\n",
    "ax.set_xticks(np.arange(1.0, 4 * len(countries), 4))\n",
    "ax.set_xticklabels(countries)\n",
    "ax.set_ylabel(\"RTT [ms]\")\n",
    "ax.set_yticks(np.arange(0, 460, 50))\n",
    "ax.set_xlim(-1,55)\n",
    "ax.xaxis.get_major_formatter()._usetex = False\n",
    "ax.yaxis.get_major_formatter()._usetex = False\n",
    "\n",
    "handles = [Patch(facecolor=cols[1]),Patch(facecolor=cols[2]),Patch(facecolor=cols[4])]\n",
    "labels = [\"Cloudflare\", \"Akamai\", \"Cloudfront\"]\n",
    "\n",
    "ax.legend(handles, labels, loc=\"upper left\", fontsize=\"small\", edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4)\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\")\n",
    "plt.ylim(0,450)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/cdn_comparison_rtt_selected_countries.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/cdn_comparison_rtt_selected_countries.svg\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Measurements - CDN vs DNS vs PoP latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starlink - accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_countries_trace_msms_stl = set(cf_country_wise_cdn_rtts_stl.keys()).intersection(set(akamai_country_wise_cdn_rtts_stl.keys())).intersection(set(cloudfront_country_wise_cdn_rtts_stl.keys()))\n",
    "common_countries_dns_msms_stl = set(cf_country_wise_dns_CHAOS_response_time_dict.keys()).intersection(google_country_wise_dns_CHAOS_response_time_dict.keys()).intersection(quad9_country_wise_dns_CHAOS_response_time_dict.keys())\n",
    "common_countries_all_msms_stl = common_countries_trace_msms_stl.intersection(common_countries_dns_msms_stl)\n",
    "print(common_countries_all_msms_stl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdn_country_wise_cdn_rtts_stl = {}\n",
    "cdn_country_wise_pop_rtts_stl = {}\n",
    "dns_country_wise_dns_CHAOS_response_time_dict_stl = {}\n",
    "\n",
    "for country in common_countries_all_msms_stl:\n",
    "    cdn_country_wise_cdn_rtts_stl[country] = cf_country_wise_cdn_rtts_stl[country] + akamai_country_wise_cdn_rtts_stl[country] + cloudfront_country_wise_cdn_rtts_stl[country]\n",
    "    cdn_country_wise_pop_rtts_stl[country] = cf_country_wise_pop_rtts_stl[country] + akamai_country_wise_pop_rtts_stl[country] + cloudfront_country_wise_pop_rtts_stl[country]\n",
    "    dns_country_wise_dns_CHAOS_response_time_dict_stl[country] = cf_country_wise_dns_CHAOS_response_time_dict[country] + google_country_wise_dns_CHAOS_response_time_dict[country] + quad9_country_wise_dns_CHAOS_response_time_dict[country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_all_rtt = []\n",
    "akamai_all_rtt = []\n",
    "cloudfront_all_rtt = []\n",
    "\n",
    "for country in common_countries_all_msms_stl:\n",
    "    cf_all_rtt.append(statistics.median(cf_country_wise_cdn_rtts_stl[country]))\n",
    "    akamai_all_rtt.append(statistics.median(akamai_country_wise_cdn_rtts_stl[country]))\n",
    "    cloudfront_all_rtt.append(statistics.median(cloudfront_country_wise_cdn_rtts_stl[country]))\n",
    "\n",
    "cf_median_rtt = statistics.mean(cf_all_rtt)\n",
    "akamai_median_rtt = statistics.mean(akamai_all_rtt)\n",
    "cloudfront_median_rtt = statistics.mean(cloudfront_all_rtt)\n",
    "\n",
    "print(f\"Cloudflare Mean CDN RTT: {cf_median_rtt}\")\n",
    "print(f\"Akamai Mean CDN RTT: {akamai_median_rtt}\")\n",
    "print(f\"Cloudfront Mean CDN RTT: {cloudfront_median_rtt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_cdn_percent_stl = []\n",
    "pop_dns_percent_stl = []\n",
    "pop_stl = []\n",
    "e2e_stl = []\n",
    "dns_stl = []\n",
    "\n",
    "dns_bar_col = cols[0]\n",
    "cdn_bar_col = cols[1]\n",
    "\n",
    "chosen_countries = [\"US\",\"CA\", \"DE\", \"HU\", \"CL\", \"CO\", \"PH\" ,\"GU\", \"BJ\", \"ZM\" ,\"ZW\"]\n",
    "\n",
    "cdn_country_wise_cdn_rtts_stl_filtered = {}\n",
    "cdn_country_wise_pop_rtts_stl_filtered = {}\n",
    "dns_country_wise_dns_CHAOS_response_time_dict_stl_filtered = {}\n",
    "\n",
    "# Filter out outliers less than 15 ms\n",
    "for country in countries:\n",
    "    cdn_country_wise_cdn_rtts_stl_filtered[country] = [cdn_rtt for cdn_rtt in cdn_country_wise_cdn_rtts_stl[country] if cdn_rtt > 15]\n",
    "    cdn_country_wise_pop_rtts_stl_filtered[country] = [pop_rtt for pop_rtt in cdn_country_wise_pop_rtts_stl[country] if pop_rtt > 15]\n",
    "    dns_country_wise_dns_CHAOS_response_time_dict_stl_filtered[country] = [dns_rt for dns_rt in dns_country_wise_dns_CHAOS_response_time_dict_stl[country] if dns_rt > 15]\n",
    "\n",
    "for country in chosen_countries[::-1]:\n",
    "\n",
    "    e2e_rtt_stl = np.percentile(cdn_country_wise_cdn_rtts_stl_filtered[country],50)\n",
    "    pop_rtt_stl = np.percentile(cdn_country_wise_pop_rtts_stl_filtered[country],50)\n",
    "    dns_rtt_stl = np.percentile(dns_country_wise_dns_CHAOS_response_time_dict_stl_filtered[country],50)\n",
    "\n",
    "\n",
    "    e2e_stl.append(e2e_rtt_stl)\n",
    "    pop_stl.append(pop_rtt_stl)\n",
    "    dns_stl.append(dns_rtt_stl)\n",
    "    pop_cdn_percent_stl.append(100 * pop_rtt_stl/e2e_rtt_stl)\n",
    "    pop_dns_percent_stl.append(100 * pop_rtt_stl/dns_rtt_stl)\n",
    "\n",
    "\n",
    "bar_width = 1.2\n",
    "group_space = 0.5\n",
    "bar_spacing = 0.2\n",
    "y_pos = np.arange(len(chosen_countries)) * (2 * bar_width + bar_spacing + group_space)\n",
    "dns_bar_positions = y_pos\n",
    "\n",
    "cdn_bar_positions = y_pos + bar_width + bar_spacing\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(4.66, 4))\n",
    "bars_dns = ax.barh(dns_bar_positions, dns_stl, bar_width, color=dns_bar_col, edgecolor='black')\n",
    "bars_e2e = ax.barh(cdn_bar_positions, e2e_stl, bar_width, color=cdn_bar_col, edgecolor='black')\n",
    "\n",
    "# Add percentage labels at the end of bars\n",
    "for bar, pop_rtt ,percent in zip(bars_e2e, pop_stl, pop_cdn_percent_stl):\n",
    "    striped_rect = patches.Rectangle(\n",
    "        (0,bar.get_y()),\n",
    "        pop_rtt,\n",
    "        bar.get_height(),\n",
    "        hatch='\\\\\\\\\\\\\\\\',\n",
    "        facecolor='none',\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    ax.add_patch(striped_rect)\n",
    "    ax.text(bar.get_width() + 2, bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{percent:.1f}\\%\", va='center', fontsize=\"small\", color =cdn_bar_col)\n",
    "\n",
    "for bar, pop_rtt ,percent in zip(bars_dns, pop_stl, pop_dns_percent_stl):\n",
    "    striped_rect = patches.Rectangle(\n",
    "        (0,bar.get_y()),\n",
    "        pop_rtt,\n",
    "        bar.get_height(),\n",
    "        hatch='\\\\\\\\\\\\\\\\',\n",
    "        facecolor='none',\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    ax.add_patch(striped_rect)\n",
    "    ax.text(bar.get_width() + 2, bar.get_y() + bar.get_height() / 2,\n",
    "            f\"{percent:.1f}\\%\", va='center', fontsize=\"small\", color =dns_bar_col)\n",
    "\n",
    "# Labels and aesthetics\n",
    "ax.set_xlabel(\"RTT to PoP vs DNS vs CDN [ms]\")\n",
    "ax.set_yticks(y_pos + bar_width / 2 + bar_spacing / 2)\n",
    "ax.set_yticklabels(chosen_countries[::-1])\n",
    "\n",
    "ax.set_xlim(0, 130)  # extra room for labels\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "handles = [Patch(facecolor=cdn_bar_col,edgecolor='black'),Patch(facecolor=dns_bar_col,edgecolor='black'),Patch(facecolor='none',edgecolor='black',hatch='\\\\\\\\\\\\\\\\')]\n",
    "labels = [\"CDN\", \"DNS\", \"PoP\"]\n",
    "ax.legend(handles, labels, loc=\"upper right\", fontsize=\"small\", edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4)\n",
    "plt.xlim(0,110)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/overall_pop_vs_dns_vs_cdn_rtt_stl.pdf\", bbox_inches = \"tight\", pad_inches = 0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newer PoPs - Before vs After"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdns_list = [\"cloudflare\", \"akamai\", \"cloudfront\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_prb_wise_cdn_rtts_stl_old = {}\n",
    "cf_prb_wise_pop_rtts_stl_old = {}\n",
    "cf_prb_wise_pop_cdn_rtts_stl_old = {}\n",
    "\n",
    "akamai_prb_wise_cdn_rtts_stl_old = {}\n",
    "akamai_prb_wise_pop_rtts_stl_old = {}\n",
    "akamai_prb_wise_pop_cdn_rtts_stl_old = {}\n",
    "\n",
    "cloudfront_prb_wise_cdn_rtts_stl_old = {}\n",
    "cloudfront_prb_wise_pop_rtts_stl_old = {}\n",
    "cloudfront_prb_wise_pop_cdn_rtts_stl_old = {}\n",
    "\n",
    "prb_pop_ips_old = {}\n",
    "\n",
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "\n",
    "\n",
    "for server in cdns_list:\n",
    "\n",
    "    cdn_rtts_stl_old = None\n",
    "    pop_rtts_stl_old = None\n",
    "    cdn_name = server\n",
    "    if server == 'cloudflare':\n",
    "        cdn_name = \"cf\"\n",
    "    cdn_rtts_stl_old = eval(f\"{cdn_name}_prb_wise_cdn_rtts_stl_old\")\n",
    "    pop_rtts_stl_old = eval(f\"{cdn_name}_prb_wise_pop_rtts_stl_old\")\n",
    "    pop_cdn_rtts_old = eval(f\"{cdn_name}_prb_wise_pop_cdn_rtts_stl_old\")\n",
    "\n",
    "    full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "\n",
    "    acc_tracert_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "    acc_tracert_filepath = os.path.join(full_msms_path,'acc_result',acc_tracert_filename)\n",
    "    print(acc_tracert_filepath)\n",
    "    with open(acc_tracert_filepath, \"r\") as json_file:\n",
    "        acc_tracert_json = json.load(json_file)\n",
    "\n",
    "    idx = 0\n",
    "    for each_msm in acc_tracert_json:\n",
    "        country_code = each_msm['country_code']\n",
    "        prb_id = each_msm['prb_id']\n",
    "\n",
    "        if prb_id not in prb_pop_ips_old:\n",
    "            prb_pop_ips_old[prb_id] = []\n",
    "\n",
    "        pop_ips = each_msm['pop_hop_ip']\n",
    "        for ip in pop_ips:\n",
    "            if ip not in prb_pop_ips_old[prb_id]:\n",
    "                prb_pop_ips_old[prb_id].append(ip)\n",
    "\n",
    "        if prb_id not in cdn_rtts_stl_old:\n",
    "            cdn_rtts_stl_old[prb_id] = []\n",
    "            pop_rtts_stl_old[prb_id] = []\n",
    "            pop_cdn_rtts_old[prb_id] = []\n",
    "        \n",
    "        if len(each_msm['total_rtts']) and len(each_msm['pop_rtts']):\n",
    "            if statistics.mean(each_msm['total_rtts']) > statistics.mean(each_msm['pop_rtts']):\n",
    "                min_cdn_rtt = min(each_msm['total_rtts'])\n",
    "                min_pop_rtt = min(each_msm['pop_rtts'])\n",
    "                cdn_rtts_stl_old[prb_id].append(min_cdn_rtt)\n",
    "                pop_rtts_stl_old[prb_id].append(min_pop_rtt)\n",
    "                pop_cdn_rtt = min_cdn_rtt - min_pop_rtt\n",
    "\n",
    "                if pop_cdn_rtt:\n",
    "                    pop_cdn_rtts_old[prb_id].append(pop_cdn_rtt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_prb_wise_cdn_rtts_stl_new = {}\n",
    "cf_prb_wise_pop_rtts_stl_new = {}\n",
    "cf_prb_wise_pop_cdn_rtts_stl_new = {}\n",
    "\n",
    "akamai_prb_wise_cdn_rtts_stl_new = {}\n",
    "akamai_prb_wise_pop_rtts_stl_new = {}\n",
    "akamai_prb_wise_pop_cdn_rtts_stl_new = {}\n",
    "\n",
    "cloudfront_prb_wise_cdn_rtts_stl_new = {}\n",
    "cloudfront_prb_wise_pop_rtts_stl_new = {}\n",
    "cloudfront_prb_wise_pop_cdn_rtts_stl_new = {}\n",
    "\n",
    "prb_pop_ips_new = {}\n",
    "\n",
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "\n",
    "\n",
    "for server in cdns_list:\n",
    "\n",
    "    cdn_rtts_stl_new = None\n",
    "    pop_rtts_stl_new = None\n",
    "    cdn_name = server\n",
    "    if server == 'cloudflare':\n",
    "        cdn_name = \"cf\"\n",
    "    cdn_rtts_stl_new = eval(f\"{cdn_name}_prb_wise_cdn_rtts_stl_new\")\n",
    "    pop_rtts_stl_new = eval(f\"{cdn_name}_prb_wise_pop_rtts_stl_new\")\n",
    "    pop_cdn_rtts_new = eval(f\"{cdn_name}_prb_wise_pop_cdn_rtts_stl_new\")\n",
    "\n",
    "    full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "\n",
    "    acc_tracert_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "    acc_tracert_filepath = os.path.join(full_msms_path,'acc_result',acc_tracert_filename)\n",
    "    print(acc_tracert_filepath)\n",
    "    with open(acc_tracert_filepath, \"r\") as json_file:\n",
    "        acc_tracert_json = json.load(json_file)\n",
    "\n",
    "    idx = 0\n",
    "    for each_msm in acc_tracert_json:\n",
    "        country_code = each_msm['country_code']\n",
    "        prb_id = each_msm['prb_id']\n",
    "\n",
    "        if prb_id not in prb_pop_ips_new:\n",
    "            prb_pop_ips_new[prb_id] = []\n",
    "\n",
    "        pop_ips = each_msm['pop_hop_ip']\n",
    "        for ip in pop_ips:\n",
    "            if ip not in prb_pop_ips_new[prb_id]:\n",
    "                prb_pop_ips_new[prb_id].append(ip)\n",
    "\n",
    "        if prb_id not in cdn_rtts_stl_new:\n",
    "            cdn_rtts_stl_new[prb_id] = []\n",
    "            pop_rtts_stl_new[prb_id] = []\n",
    "            pop_cdn_rtts_new[prb_id] = []\n",
    "        \n",
    "        if len(each_msm['total_rtts']) and len(each_msm['pop_rtts']):\n",
    "            if statistics.mean(each_msm['total_rtts']) > statistics.mean(each_msm['pop_rtts']):\n",
    "                min_cdn_rtt = min(each_msm['total_rtts'])\n",
    "                min_pop_rtt = min(each_msm['pop_rtts'])\n",
    "                cdn_rtts_stl_new[prb_id].append(min_cdn_rtt)\n",
    "                pop_rtts_stl_new[prb_id].append(min_pop_rtt)\n",
    "                pop_cdn_rtt = min_cdn_rtt - min_pop_rtt\n",
    "\n",
    "                if pop_cdn_rtt:\n",
    "                    pop_cdn_rtts_new[prb_id].append(pop_cdn_rtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del acc_tracert_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rcParams['font.size'] = 10\n",
    "\n",
    "probe_id = 65337 ## RIPE Atlas probe for Guam\n",
    "entity_colors = {\n",
    "    \"CDN\" : cols[4],\n",
    "    \"Cloudflare\" : cols[3],\n",
    "    \"Akamai\" : cols[4],\n",
    "    \"Cloudfront\" : cols[2],\n",
    "    \"PoP\" : cols[1]\n",
    "}\n",
    "\n",
    "all_pop_rtts_stl_old = {}\n",
    "all_pop_rtts_stl_new = {}\n",
    "\n",
    "all_pop_rtts_stl_new[probe_id] = []\n",
    "all_pop_rtts_stl_old[probe_id] = []\n",
    "\n",
    "all_cdn_rtts_stl_old = {}\n",
    "all_cdn_rtts_stl_new = {}\n",
    "\n",
    "all_cdn_rtts_stl_new[probe_id] = []\n",
    "all_cdn_rtts_stl_old[probe_id] = []\n",
    "\n",
    "rtt_params = {\n",
    "    \"Cloudflare\" : \"cf_prb_wise_\", \n",
    "    \"Akamai\" : \"akamai_prb_wise_\", \n",
    "    \"Cloudfront\" : \"cloudfront_prb_wise_\", \n",
    "    \"PoP\" : \"all_pop_rtts_stl_\"\n",
    "}\n",
    "\n",
    "all_rtt_params = {\n",
    "    \"CDN\" : \"all_cdn_rtts_stl_\",\n",
    "    \"PoP\" : \"all_pop_rtts_stl_\"\n",
    "}\n",
    "\n",
    "for cdn in list(rtt_params.keys()):\n",
    "    if cdn != \"PoP\":\n",
    "        pop_prb_wise_rtts_new = eval(rtt_params[cdn]+\"pop_rtts_stl_new\")\n",
    "        all_pop_rtts_stl_new[probe_id] += pop_prb_wise_rtts_new[probe_id]\n",
    "\n",
    "        pop_prb_wise_rtts_old = eval(rtt_params[cdn]+\"pop_rtts_stl_old\")\n",
    "        all_pop_rtts_stl_old[probe_id] += pop_prb_wise_rtts_old[probe_id]\n",
    "\n",
    "        cdn_prb_wise_rtts_new = eval(rtt_params[cdn]+\"cdn_rtts_stl_new\")\n",
    "        all_cdn_rtts_stl_new[probe_id] += cdn_prb_wise_rtts_new[probe_id]\n",
    "\n",
    "        cdn_prb_wise_rtts_old = eval(rtt_params[cdn]+\"cdn_rtts_stl_old\")\n",
    "        all_cdn_rtts_stl_old[probe_id] += cdn_prb_wise_rtts_old[probe_id]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.66, 2))\n",
    "\n",
    "\n",
    "handles = []\n",
    "labels = []\n",
    "for entity in all_rtt_params.keys():\n",
    "    if entity in [\"CDN\", \"PoP\"]:\n",
    "        rtt_prb_wise_old = []\n",
    "        rtt_prb_wise_new = []\n",
    "\n",
    "        rtt_prb_wise_old = eval(all_rtt_params[entity]+\"old\")\n",
    "\n",
    "        rtt_BEFORE_list = rtt_prb_wise_old[probe_id]\n",
    "        if rtt_BEFORE_list:\n",
    " \n",
    "            xs = np.sort(rtt_BEFORE_list)\n",
    "            ys = np.arange(1, len(xs) + 1) / len(xs)\n",
    "            indices = []\n",
    "            current = xs[0]\n",
    "            for i, x in enumerate(xs): # only take max y value at each x value to smoothen out the graph\n",
    "                if x != current:\n",
    "                    current = x\n",
    "                    indices.append(i - 1)\n",
    "            indices.append(len(ys) - 1)\n",
    "            xs = sorted(set(xs))\n",
    "            ys = [ys[i] for i in indices]\n",
    "            ax.plot(xs, ys, label=f\"{entity}\", color=entity_colors[entity], linestyle=\"dotted\")\n",
    "\n",
    "\n",
    "        rtt_prb_wise_new = eval(all_rtt_params[entity]+\"new\")\n",
    "\n",
    "        rtt_AFTER_list = rtt_prb_wise_new[probe_id]\n",
    "        if rtt_AFTER_list:\n",
    "\n",
    "            xs = np.sort(rtt_AFTER_list)\n",
    "            ys = np.arange(1, len(xs) + 1) / len(xs)\n",
    "            indices = []\n",
    "            current = xs[0]\n",
    "            for i, x in enumerate(xs): # only take max y value at each x value to smoothen out the graph\n",
    "                if x != current:\n",
    "                    current = x\n",
    "                    indices.append(i - 1)\n",
    "            indices.append(len(ys) - 1)\n",
    "            xs = sorted(set(xs))\n",
    "            ys = [ys[i] for i in indices]\n",
    "            ax.plot(xs, ys, label=f\"{entity}\", color=entity_colors[entity], linestyle=\"solid\")\n",
    "\n",
    "        handles.append(Patch(facecolor=entity_colors[entity]))\n",
    "        labels.append(entity)\n",
    "\n",
    "ax.set_xlabel(\"RTT [ms]\")\n",
    "ax.set_ylabel(\"Percentile\")\n",
    "ax.set_yticks(np.arange(0, 1.20, 0.25))\n",
    "ax.set_xticks(np.arange(0, 600, 50))\n",
    "ax.xaxis.get_major_formatter()._usetex = False\n",
    "ax.yaxis.get_major_formatter()._usetex = False\n",
    "\n",
    "\n",
    "solid_line = Line2D([0], [0], color='black', linestyle='-', label='Starlink')\n",
    "dashed_line = Line2D([0], [0], color='black', linestyle=':', label='Terrestrial')\n",
    "\n",
    "net_handles = [solid_line, dashed_line]\n",
    "net_labels = ['AFTER', 'BEFORE']\n",
    "\n",
    "country_legend  = ax.legend(handles, labels, loc=\"lower right\",  fontsize=\"small\", edgecolor=\"k\",  handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4)\n",
    "ax.add_artist(country_legend)\n",
    "ax.legend(net_handles, net_labels,loc=\"lower right\", bbox_to_anchor=(0.65, 0.94), fontsize=\"x-small\", edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3,frameon=False, fancybox=False, ncol=4) # bbox_to_anchor=(0.25, 0.91), \n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "ax.set_xlim(20,300)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/cf_cdn_Guam_BEFORE_vs_AFTER_cdf.pdf\", bbox_inches = \"tight\", pad_inches = 0)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/cf_cdn_Guam_BEFORE_vs_AFTER_cdf.svg\", bbox_inches = \"tight\", pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traceroute server selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloudflare - Late 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"cloudflare\"\n",
    "\n",
    "\n",
    "acc_result_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "\n",
    "cf_acc_tracert_json = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    cf_acc_tracert_json = json.load(json_file)\n",
    "    print(\"Accumulated Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_cf_path = {}\n",
    "all_public_ips = []\n",
    "ip_to_country_dict = {}\n",
    "\n",
    "\n",
    "shortlisted_countries = [\"US\", \"CA\" ,\"DE\", \"HU\", \"CL\", \"CO\", \"AU\", \"NZ\" ,\"PH\", \"GU\", \"BJ\", \"ZW\" , \"ZM\", \"MG\"]\n",
    "\n",
    "class Hop:\n",
    "    def __init__(self,ip,type,min_rtt,asn,hostname,country,location):\n",
    "        self.ip = ip\n",
    "        self.type = type\n",
    "        self.min_rtt = min_rtt\n",
    "        self.asn = asn\n",
    "        self.hostname = hostname\n",
    "        self.country = country\n",
    "        self.location = location\n",
    "        self.children = []\n",
    "\n",
    "    def add_children(self,child_node):\n",
    "        self.children.append(child_node)\n",
    "    \n",
    "    def has_children(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "\n",
    "\n",
    "for idx, each_msm in enumerate(cf_acc_tracert_json,start=0):\n",
    "        print(f\"Index: {idx} out of {len(cf_acc_tracert_json)}\")\n",
    "\n",
    "        pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "        cdn_ip_set = set(each_msm['all_hops'][-1]['hop_ips'])\n",
    "\n",
    "        if len(pop_ip_set) == 0:\n",
    "            continue\n",
    "        \n",
    "        if len(pop_ip_set) != 1:\n",
    "            print(f\"More than 2 PoP IPs in the same hop. Probe id: {prb_id}, domain: {each_msm['domain']}\")\n",
    "            pop_ip_set = {list(pop_ip_set)[0],}\n",
    "            print(f\"Continuing with PoP IP: {list(pop_ip_set)[0]}\")\n",
    "            # continue\n",
    "\n",
    "        if each_msm['country_code'] not in shortlisted_countries:\n",
    "            continue\n",
    "\n",
    "        ## Create new probe in probes if not done already\n",
    "        prb_id = each_msm['prb_id']\n",
    "        if prb_id not in probes_cf_path:\n",
    "            probes_cf_path[prb_id] = {\n",
    "                'id' : prb_id,\n",
    "                'country_code' : each_msm['country_code'],\n",
    "                'paths': {},\n",
    "            }\n",
    "\n",
    "        ## Create first hop for the probe as starting with the pop node if not done already\n",
    "        pop_ip = next(iter(pop_ip_set))\n",
    "        pop_asn = 14593\n",
    "        domain = each_msm['domain']\n",
    "        if domain not in probes_cf_path[prb_id]['paths']:\n",
    "            probes_cf_path[prb_id]['paths'][domain] = {}\n",
    "        if pop_ip not in probes_cf_path[prb_id]['paths'][domain]:\n",
    "                country = None\n",
    "                if pop_ip in ip_to_country_dict:\n",
    "                    country = ip_to_country_dict[pop_ip]\n",
    "                else:\n",
    "                    geo_details = find_ip(pop_ip,ip_to_country_df)\n",
    "                    if geo_details is not None:\n",
    "                        if 'country_code' in geo_details:\n",
    "                            country = geo_details['country_code']\n",
    "                            ip_to_country_dict[pop_ip] = country\n",
    "                    else:\n",
    "                        ip_to_country_dict[pop_ip] = None\n",
    "                probes_cf_path[prb_id]['paths'][domain][pop_ip] = Hop(\n",
    "                    ip=pop_ip,\n",
    "                    type='PoP',\n",
    "                    min_rtt=min(each_msm['pop_rtts']),\n",
    "                    asn=pop_asn,\n",
    "                    hostname=None,\n",
    "                    country=country,\n",
    "                    location=None,\n",
    "                )\n",
    "        else:\n",
    "            this_min_rtt = min(each_msm['pop_rtts'])\n",
    "            prev_min_rtt = probes_cf_path[prb_id]['paths'][domain][pop_ip].min_rtt\n",
    "            if this_min_rtt < prev_min_rtt:\n",
    "                probes_cf_path[prb_id]['paths'][domain][pop_ip].min_rtt = this_min_rtt\n",
    "\n",
    "        pop_reached = False\n",
    "        hopNode = probes_cf_path[prb_id]['paths'][domain][pop_ip]\n",
    "        \n",
    "        ## Go through all the hops\n",
    "        for idx, each_hop in enumerate(each_msm['all_hops']):\n",
    "            hop_ip_set = set(each_hop['hop_ips'])\n",
    "            hop_id = each_hop['hop_id']\n",
    "            min_hop_rtt = min(each_hop['hop_rtts'])\n",
    "\n",
    "            if pop_ip_set.intersection(hop_ip_set):\n",
    "                pop_reached = True\n",
    "                continue\n",
    "\n",
    "            \n",
    "            \n",
    "            if pop_reached:\n",
    "                if len(hop_ip_set) != 1:\n",
    "                    print(f\"More than 2 destinations in the same hop. Probe id: {prb_id}, domain: {each_msm['domain']}, hop id: {hop_id}\")\n",
    "                    \n",
    "                    print(\"Check if the hop ips are part of the same network address\")\n",
    "                    hop_ip_network_count = {}\n",
    "                    hop_ip_network_min_rtt = {}\n",
    "                    for uni_idx, unique_hop_ip in enumerate(each_hop['hop_ips']):\n",
    "                        unique_hop_ip_obj = ipaddress.ip_interface(unique_hop_ip + '/24')\n",
    "                        unique_hop_network = str(unique_hop_ip_obj.network.network_address)\n",
    "\n",
    "                        if unique_hop_network not in hop_ip_network_count:\n",
    "                            hop_ip_network_count[unique_hop_network] = 1\n",
    "                            hop_ip_network_min_rtt[unique_hop_network] = each_hop['hop_rtts'][uni_idx]\n",
    "                        else:\n",
    "                            continue\n",
    "                        for each_idx, each_ip in enumerate(each_hop['hop_ips']):\n",
    "                            if each_idx == uni_idx:\n",
    "                                continue\n",
    "                            each_ip_obj = ipaddress.ip_interface(each_ip + '/24')\n",
    "                            each_ip_network = str(each_ip_obj.network.network_address)\n",
    "                            if each_ip_network == unique_hop_network:\n",
    "                                hop_ip_network_count[unique_hop_network] += 1\n",
    "                                if each_hop['hop_rtts'][each_idx] <  hop_ip_network_min_rtt[unique_hop_network]:\n",
    "                                    hop_ip_network_min_rtt[unique_hop_network] = each_hop['hop_rtts'][each_idx]\n",
    "                    \n",
    "                    max_count = max(hop_ip_network_count.values())\n",
    "                    if max_count < 2:\n",
    "                        print(\"Could not find a majority network address. Skipping measurement.\")\n",
    "                        break\n",
    "                    max_key = max(hop_ip_network_count, key=hop_ip_network_count.get)\n",
    "                    hop_ip_set = {max_key,}\n",
    "                    min_hop_rtt = hop_ip_network_min_rtt[max_key]\n",
    "\n",
    "\n",
    "                need_new_child_node = True\n",
    "                hop_ip = next(iter(hop_ip_set))\n",
    "\n",
    "                if not ipaddress.ip_address(hop_ip).is_private:\n",
    "                    all_public_ips.append(hop_ip)\n",
    "\n",
    "                hopChildNode = None\n",
    "                if hopNode.has_children():\n",
    "                    hopChildNodes = hopNode.get_children()\n",
    "                    for node in hopChildNodes:\n",
    "                        \n",
    "                        if node.ip == hop_ip:\n",
    "                            hopChildNode = node\n",
    "                            need_new_child_node = False\n",
    "                \n",
    "                if need_new_child_node:\n",
    "                    hop_type = 'Node'\n",
    "                    if hop_ip in cdn_ip_set:\n",
    "                        hop_type = 'CDN'\n",
    "                    asn_info, _ = asndb.lookup(hop_ip)\n",
    "                    country = None\n",
    "                    if hop_ip in ip_to_country_dict:\n",
    "                        country = ip_to_country_dict[hop_ip]\n",
    "                    else:\n",
    "                        geo_details = find_ip(hop_ip,ip_to_country_df)\n",
    "                        if geo_details is not None:\n",
    "                            if 'country_code' in geo_details:\n",
    "                                country = geo_details['country_code']\n",
    "                                ip_to_country_dict[hop_ip] = country\n",
    "                        else:\n",
    "                            ip_to_country_dict[hop_ip] = None\n",
    "\n",
    "                    newChildNode = Hop(\n",
    "                        ip=hop_ip,\n",
    "                        type=hop_type,\n",
    "                        min_rtt=min_hop_rtt,\n",
    "                        asn=asn_info,\n",
    "                        hostname=None,\n",
    "                        country=country,\n",
    "                        location=None,\n",
    "                    )\n",
    "                    hopNode.add_children(newChildNode)\n",
    "                    hopChildNode = newChildNode\n",
    "                else:\n",
    "                    this_min_rtt = min_hop_rtt\n",
    "                    prev_min_rtt = hopChildNode.min_rtt\n",
    "                    if this_min_rtt < prev_min_rtt:\n",
    "                        hopChildNode.min_rtt = this_min_rtt\n",
    "                hopNode = hopChildNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_to_details_map_filename = \"../dataset/ip_to_details.json\"\n",
    "ip_to_details = {}\n",
    "with open(ip_to_details_map_filename,'r') as json_file:\n",
    "    ip_to_details = json.load(json_file)\n",
    "\n",
    "ip_to_hostname_map_filename = \"../dataset/ip_to_hostname.json\"\n",
    "ip_to_hostname = {}\n",
    "with open(ip_to_hostname_map_filename,'r') as json_file:\n",
    "    ip_to_hostname = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def go_through_all_nodes_cf(root,pop_ip_addr):\n",
    "    pop_ips_unknown = set()\n",
    "    last_unicast_ips = {}\n",
    "    last_unicast_ips_within_rtt = set()\n",
    "    pop_ips_known = []\n",
    "    pop_ip_dict = {}\n",
    "    loc_to_count = {}\n",
    "\n",
    "\n",
    "    def visit_node(node):\n",
    "        node_ip = node.ip\n",
    "\n",
    "        if node_ip is not None:\n",
    "            \n",
    "            if node_ip not in ip_to_details:\n",
    "                if node_ip not in ip_to_hostname:\n",
    "                    _, hostname = reverse_dns_lookup(node_ip)\n",
    "                    node.hostname = hostname\n",
    "                    ip_to_hostname[node_ip] = hostname\n",
    "\n",
    "                else:\n",
    "                    node.hostname = ip_to_hostname[node_ip]\n",
    "            else:\n",
    "                node.location = ip_to_details[node_ip]['location']\n",
    "\n",
    "            if node.type == 'PoP':\n",
    "\n",
    "                loc = None\n",
    "                if node_ip not in ip_to_details:\n",
    "                    pop_ips_unknown.add(node_ip)\n",
    "\n",
    "                else:\n",
    "                    pop_ips_known.append(node_ip)\n",
    "                    loc = ip_to_details[node_ip]['location']\n",
    "                pop_ip_dict[node_ip] = {\n",
    "                    'min_rtt' : node.min_rtt,\n",
    "                    'location' : loc\n",
    "                }\n",
    "                \n",
    "        for child_node in node.children:\n",
    "            if child_node.type == 'CDN':\n",
    "\n",
    "                loc = \"unknown\"\n",
    "                if node.ip not in ip_to_loc or node.location is None:\n",
    "\n",
    "                    if pop_ip_dict[pop_ip_addr][\"location\"]:\n",
    "\n",
    "                        pop_min_rtt = pop_ip_dict[pop_ip_addr][\"min_rtt\"]\n",
    "                        if child_node.min_rtt >= pop_min_rtt and child_node.min_rtt - pop_min_rtt <= 2:\n",
    "                            loc = pop_ip_dict[pop_ip_addr][\"location\"]\n",
    "                else:\n",
    "                    if child_node.min_rtt >= node.min_rtt and child_node.min_rtt - node.min_rtt <= 2:\n",
    "                        if node.ip in ip_to_loc:\n",
    "                            loc = ip_to_loc[node.ip]\n",
    "                        elif node.location:\n",
    "                            loc = node.location\n",
    "\n",
    "                if node.ip not in last_unicast_ips:\n",
    "                    last_unicast_ips[node.ip] = loc\n",
    "                if child_node.min_rtt >= node.min_rtt and child_node.min_rtt - node.min_rtt <= 2:\n",
    "                    last_unicast_ips_within_rtt.add(node.ip)\n",
    "                    \n",
    "                if loc not in loc_to_count:\n",
    "                    loc_to_count[loc] = 0\n",
    "                loc_to_count[loc] += 1\n",
    "            visit_node(child_node)\n",
    "\n",
    "                    \n",
    "\n",
    "    def save_ip_map_json(filename, dict_to_save, inital_len):\n",
    "        if len(dict_to_save) > inital_len:\n",
    "            with open(filename, \"w+\") as json_file:\n",
    "                json.dump(dict_to_save,json_file)\n",
    "\n",
    "    visit_node(root)\n",
    "    \n",
    "\n",
    "    return pop_ips_unknown, last_unicast_ips, last_unicast_ips_within_rtt, pop_ips_known, pop_ip_dict, loc_to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_dns_lookup(ip_addr):\n",
    "    try:\n",
    "        hostname, _, _ = socket.gethostbyaddr(ip_addr)\n",
    "        return ip_addr, hostname\n",
    "    except socket.herror as e:\n",
    "        return ip_addr, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = [\n",
    "  \"www.broadcom.com\",\n",
    "  \"www.comodoca.com\",\n",
    "  \"www.apnic.net\",\n",
    "  \"www.riskified.com\",\n",
    "  \"www.wiley.com\",\n",
    "  \"www.vmware.com\",\n",
    "  \"www.sportskeeda.com\",\n",
    "  \"www.garmin.com\", #IPV4 only\n",
    "  \"www.fao.org\",\n",
    "  \"www.n-able.com\",\n",
    "    ]\n",
    "\n",
    "glb_cf_loc_to_count = {}\n",
    "glb_cf_loc_to_count_abs_num = {}\n",
    "chosen_countries = [\"US\", \"CA\" ,\"DE\", \"HU\", \"CL\", \"CO\", \"AU\", \"NZ\" ,\"PH\", \"GU\", \"BJ\", \"ZW\" , \"ZM\", \"MG\"]\n",
    "\n",
    "for chosen_country in chosen_countries:\n",
    "  cdn_ip_count_rtt = {}\n",
    "  cf_loc_to_count = {}\n",
    "  print(f\"Country: {chosen_country}\")\n",
    "\n",
    "  probes_list = []\n",
    "  for probe_id, probe_details in probes_cf_path.items():\n",
    "      if chosen_country == probe_details['country_code']:\n",
    "          probes_list.append(probe_id)\n",
    "  print(f\"Probes: {probes_list}\")\n",
    "  probe_id = probes_list[0]\n",
    "  print(f\"Now checking for probe id: {probe_id}\")\n",
    "  print(f\"Prb: {probe_id}\")\n",
    "\n",
    "  # FOR PROBE LIST\n",
    "  pop_ip_addr_set = set()\n",
    "  for probe_id in probes_list:\n",
    "    for domain in domain_list:\n",
    "      if domain in probes_cf_path[probe_id]['paths']:\n",
    "          pop_ip_addr_set = pop_ip_addr_set.union(set(probes_cf_path[probe_id]['paths'][domain].keys()))\n",
    "  pop_ip_addr_list = list(pop_ip_addr_set)\n",
    "  print(pop_ip_addr_list)\n",
    "\n",
    "  glb_pop_ips_unknown = set()\n",
    "  glb_last_unicast_ips = set()\n",
    "  glb_last_unicast_ips_within_rtt = set()\n",
    "  glb_loc_to_count = {}\n",
    "  glb_pop_ip_dict = {}\n",
    "\n",
    "  for probe_id in probes_list:\n",
    "    for domain in domain_list:\n",
    "      for pop_ip_address in pop_ip_addr_list:\n",
    "        if domain not in probes_cf_path[probe_id]['paths']:\n",
    "          continue\n",
    "        if pop_ip_address in probes_cf_path[probe_id]['paths'][domain]:\n",
    "          rootNode = probes_cf_path[probe_id]['paths'][domain][pop_ip_address]\n",
    "          pop_ips_unknown, last_unicast_ips, last_unicast_ips_within_rtt, pop_ips_known, pop_ip_dict, loc_to_count = go_through_all_nodes_cf(root=rootNode,pop_ip_addr=pop_ip_address)\n",
    "          \n",
    "          glb_pop_ips_unknown = glb_pop_ips_unknown.union(pop_ips_unknown)\n",
    "          glb_last_unicast_ips = glb_last_unicast_ips.union(set(last_unicast_ips.keys()))\n",
    "          glb_last_unicast_ips_within_rtt = glb_last_unicast_ips_within_rtt.union(last_unicast_ips_within_rtt)\n",
    "          glb_pop_ip_dict.update(pop_ip_dict)\n",
    "\n",
    "          for ip_location, count in loc_to_count.items():\n",
    "            if ip_location not in glb_loc_to_count:\n",
    "              glb_loc_to_count[ip_location] = 0\n",
    "            glb_loc_to_count[ip_location] += count\n",
    "\n",
    "  print(f\"glb_pop_ip_dict={glb_pop_ip_dict}\")  \n",
    "  print(f\"glb_pop_ips_unknown={glb_pop_ips_unknown}\")\n",
    "  print(f\"glb_loc_to_count={glb_loc_to_count}\")\n",
    "  print(f\"glb_last_unicast_ips_within_rtt={glb_last_unicast_ips_within_rtt}\")\n",
    "\n",
    "  known_unicast_ips = []\n",
    "  for ip in list(glb_last_unicast_ips_within_rtt):\n",
    "    known_unicast_ips.append(ip)\n",
    "    ipinfo_details = find_ip(ip, ip_to_country_df)\n",
    "    if ipinfo_details:\n",
    "      if 'country' in ipinfo_details:\n",
    "        print(f\"IP: {ip} -> {ipinfo_details['country']}\")\n",
    "      else:\n",
    "        print(f\"IP: {ip} -> unknown\")   \n",
    "    else:\n",
    "      print(f\"IP: {ip} -> unknown\")\n",
    "\n",
    "\n",
    "  all_last_unicast_ips = set()\n",
    "  for idx, each_msm in enumerate(cf_acc_tracert_json,start=0):\n",
    "\n",
    "    prb_id = each_msm['prb_id']\n",
    "    if prb_id in probes_list: \n",
    "        pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "        if len(each_msm['all_hops']) >=2:\n",
    "          cdn_ip_list = each_msm['all_hops'][-2]['hop_ips']\n",
    "\n",
    "          if each_msm['domain'] in domain_list:\n",
    "              for msm_idx, ip in enumerate(cdn_ip_list):\n",
    "\n",
    "                  all_last_unicast_ips.add(ip)\n",
    "                  if ip not in cdn_ip_count_rtt:\n",
    "                      cdn_ip_count_rtt[ip] = []\n",
    "                  \n",
    "                  cdn_ip_count_rtt[ip].append(each_msm['all_hops'][-2]['hop_rtts'][msm_idx])\n",
    "\n",
    "\n",
    "\n",
    "  for ip, cdn_rt_list in cdn_ip_count_rtt.items():\n",
    "      loc = \"unknown\"\n",
    "\n",
    "      if ip in glb_last_unicast_ips_within_rtt:\n",
    "        if ip in ip_to_details and ip_to_details[ip]['location'] is not None:\n",
    "            loc = ip_to_details[ip]['location']\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "        else:\n",
    "            ipinfo_details = find_ip(ip,ip_to_country_df)\n",
    "            if ipinfo_details:\n",
    "                loc = ipinfo_details['country']\n",
    "                print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "            else:\n",
    "\n",
    "                print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}]\")\n",
    "      else:\n",
    "        print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}]\")\n",
    "\n",
    "      if loc not in cf_loc_to_count:\n",
    "          cf_loc_to_count[loc] = 0\n",
    "      cf_loc_to_count[loc] += len(cdn_rt_list)\n",
    "\n",
    "  sum = 0\n",
    "  for value in cf_loc_to_count.values():\n",
    "      sum += value\n",
    "\n",
    "  if chosen_country not in glb_cf_loc_to_count:\n",
    "    glb_cf_loc_to_count[chosen_country] = {}\n",
    "  if chosen_country not in glb_cf_loc_to_count_abs_num:\n",
    "    glb_cf_loc_to_count_abs_num[chosen_country] = {}\n",
    "\n",
    "  glb_cf_loc_to_count_abs_num[chosen_country] = copy.deepcopy(cf_loc_to_count)\n",
    "\n",
    "  print(\"************** Final Count ****************\")\n",
    "  for loc, value in cf_loc_to_count.items():\n",
    "      country_percent = round((value/sum) * 100,2)\n",
    "      print(f\"{loc} : {country_percent}%\")\n",
    "\n",
    "      if loc not in glb_cf_loc_to_count[chosen_country]:\n",
    "        glb_cf_loc_to_count[chosen_country][loc] = country_percent\n",
    "\n",
    "      \n",
    "\n",
    "  print(\"********************************\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loc_to_country = {\n",
    "    \"Germany\" : \"DE\",\n",
    "    \"Bulgaria\" : \"BG\",\n",
    "    \"Peru\" : \"PE\",\n",
    "    \"Santiago\" : \"CL\",\n",
    "    \"United States\" : \"US\",\n",
    "    \"Canada\" : \"CA\",\n",
    "    \"Colombia\" : \"CO\",\n",
    "    \"Australia\" : \"AU\",\n",
    "    \"New Zealand\" : \"NZ\",\n",
    "    \"Singapore\" : \"SG\",\n",
    "    \"United Kingdom\" : \"GB\",\n",
    "    \"South Africa\" : \"ZA\",\n",
    "    \"Nigeria\" : \"NG\",\n",
    "    \"unknown\" : \"N/A\"\n",
    "}\n",
    "cf_loc_to_count_filtered = {}\n",
    "for chosen_country in chosen_countries:\n",
    "    print(f\"Country: {chosen_country}\")\n",
    "    cf_loc_to_count_filtered[chosen_country] = {}\n",
    "    total_sum_locs = __builtins__.sum(glb_cf_loc_to_count[chosen_country].values())\n",
    "\n",
    "    print(\"************** CF Final Count ****************\")\n",
    "    for loc, value in glb_cf_loc_to_count[chosen_country].items():\n",
    "        loc_percent = round((value/total_sum_locs) * 100,2)\n",
    "        if loc_percent > 5:\n",
    "            loc_country_code = loc_to_country[loc]\n",
    "            cf_loc_to_count_filtered[chosen_country][loc_country_code] = loc_percent\n",
    "            print(f\"{loc_country_code} : {loc_percent}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloudflare - Early 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"cloudflare\"\n",
    "\n",
    "acc_result_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "print(filepath)\n",
    "\n",
    "cf_accumulated_trace_json_old = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    cf_accumulated_trace_json_old = json.load(json_file)\n",
    "    print(\"Accumulated Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_cf_path_old = {}\n",
    "all_public_ips = []\n",
    "ip_to_country_dict = {}\n",
    "\n",
    "\n",
    "shortlisted_countries = ['GU']\n",
    "\n",
    "class Hop:\n",
    "    def __init__(self,ip,type,min_rtt,asn,hostname,country,location):\n",
    "        self.ip = ip\n",
    "        self.type = type\n",
    "        self.min_rtt = min_rtt\n",
    "        self.asn = asn\n",
    "        self.hostname = hostname\n",
    "        self.country = country\n",
    "        self.location = location\n",
    "        self.children = []\n",
    "\n",
    "    def add_children(self,child_node):\n",
    "        self.children.append(child_node)\n",
    "    \n",
    "    def has_children(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "\n",
    "\n",
    "for idx, each_msm in enumerate(cf_accumulated_trace_json_old,start=0):\n",
    "        print(f\"Index: {idx} out of {len(cf_accumulated_trace_json_old)}\")\n",
    "\n",
    "        pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "        cdn_ip_set = set(each_msm['all_hops'][-1]['hop_ips'])\n",
    "\n",
    "        if len(pop_ip_set) == 0:\n",
    "            continue\n",
    "        \n",
    "        if len(pop_ip_set) != 1:\n",
    "            print(f\"More than 2 PoP IPs in the same hop. Probe id: {prb_id}, domain: {each_msm['domain']}\")\n",
    "            pop_ip_set = {list(pop_ip_set)[0],}\n",
    "            print(f\"Continuing with PoP IP: {list(pop_ip_set)[0]}\")\n",
    "\n",
    "        if each_msm['country_code'] not in shortlisted_countries:\n",
    "            continue\n",
    "\n",
    "        ## Create new probe in probes if not done already\n",
    "        prb_id = each_msm['prb_id']\n",
    "        if prb_id not in probes_cf_path_old:\n",
    "            probes_cf_path_old[prb_id] = {\n",
    "                'id' : prb_id,\n",
    "                'country_code' : each_msm['country_code'],\n",
    "                'paths': {},\n",
    "            }\n",
    "\n",
    "        ## Create first hop for the probe as starting with the pop node if not done already\n",
    "        pop_ip = next(iter(pop_ip_set))\n",
    "        pop_asn = 14593\n",
    "        domain = each_msm['domain']\n",
    "        if domain not in probes_cf_path_old[prb_id]['paths']:\n",
    "            probes_cf_path_old[prb_id]['paths'][domain] = {}\n",
    "        if pop_ip not in probes_cf_path_old[prb_id]['paths'][domain]:\n",
    "                country = None\n",
    "                if pop_ip in ip_to_country_dict:\n",
    "                    country = ip_to_country_dict[pop_ip]\n",
    "                else:\n",
    "                    geo_details = find_ip(pop_ip,ip_to_country_df)\n",
    "                    if geo_details is not None:\n",
    "                        if 'country_code' in geo_details:\n",
    "                            country = geo_details['country_code']\n",
    "                            ip_to_country_dict[pop_ip] = country\n",
    "                    else:\n",
    "                        ip_to_country_dict[pop_ip] = None\n",
    "                probes_cf_path_old[prb_id]['paths'][domain][pop_ip] = Hop(\n",
    "                    ip=pop_ip,\n",
    "                    type='PoP',\n",
    "                    min_rtt=min(each_msm['pop_rtts']),\n",
    "                    asn=pop_asn,\n",
    "                    hostname=None,\n",
    "                    country=country,\n",
    "                    location=None,\n",
    "                )\n",
    "        else:\n",
    "            this_min_rtt = min(each_msm['pop_rtts'])\n",
    "            prev_min_rtt = probes_cf_path_old[prb_id]['paths'][domain][pop_ip].min_rtt\n",
    "            if this_min_rtt < prev_min_rtt:\n",
    "                probes_cf_path_old[prb_id]['paths'][domain][pop_ip].min_rtt = this_min_rtt\n",
    "\n",
    "        pop_reached = False\n",
    "        hopNode = probes_cf_path_old[prb_id]['paths'][domain][pop_ip]\n",
    "        \n",
    "        ## Go through all the hops\n",
    "        for idx, each_hop in enumerate(each_msm['all_hops']):\n",
    "            hop_ip_set = set(each_hop['hop_ips'])\n",
    "            hop_id = each_hop['hop_id']\n",
    "            min_hop_rtt = min(each_hop['hop_rtts'])\n",
    "\n",
    "            if pop_ip_set.intersection(hop_ip_set):\n",
    "                pop_reached = True\n",
    "                continue\n",
    "\n",
    "            \n",
    "            \n",
    "            if pop_reached:\n",
    "                if len(hop_ip_set) != 1:\n",
    "                    print(f\"More than 2 destinations in the same hop. Probe id: {prb_id}, domain: {each_msm['domain']}, hop id: {hop_id}\")\n",
    "                    \n",
    "                    print(\"Check if the hop ips are part of the same network address\")\n",
    "                    hop_ip_network_count = {}\n",
    "                    hop_ip_network_min_rtt = {}\n",
    "                    for uni_idx, unique_hop_ip in enumerate(each_hop['hop_ips']):\n",
    "                        unique_hop_ip_obj = ipaddress.ip_interface(unique_hop_ip + '/24')\n",
    "                        unique_hop_network = str(unique_hop_ip_obj.network.network_address)\n",
    "                        \n",
    "                        if unique_hop_network not in hop_ip_network_count:\n",
    "                            hop_ip_network_count[unique_hop_network] = 1\n",
    "                            hop_ip_network_min_rtt[unique_hop_network] = each_hop['hop_rtts'][uni_idx]\n",
    "                        else:\n",
    "                            continue\n",
    "                        for each_idx, each_ip in enumerate(each_hop['hop_ips']):\n",
    "                            if each_idx == uni_idx:\n",
    "                                continue\n",
    "                            each_ip_obj = ipaddress.ip_interface(each_ip + '/24')\n",
    "                            each_ip_network = str(each_ip_obj.network.network_address)\n",
    "                            if each_ip_network == unique_hop_network:\n",
    "                                hop_ip_network_count[unique_hop_network] += 1\n",
    "                                if each_hop['hop_rtts'][each_idx] <  hop_ip_network_min_rtt[unique_hop_network]:\n",
    "                                    hop_ip_network_min_rtt[unique_hop_network] = each_hop['hop_rtts'][each_idx]\n",
    "                    \n",
    "                    max_count = max(hop_ip_network_count.values())\n",
    "                    if max_count < 2:\n",
    "                        print(\"Could not find a majority network address. Skipping measurement.\")\n",
    "                        break\n",
    "                    max_key = max(hop_ip_network_count, key=hop_ip_network_count.get)\n",
    "                    hop_ip_set = {max_key,}\n",
    "                    min_hop_rtt = hop_ip_network_min_rtt[max_key]\n",
    "\n",
    "              \n",
    "                need_new_child_node = True\n",
    "                hop_ip = next(iter(hop_ip_set))\n",
    "\n",
    "                if not ipaddress.ip_address(hop_ip).is_private:\n",
    "                    all_public_ips.append(hop_ip)\n",
    "\n",
    "                hopChildNode = None\n",
    "                if hopNode.has_children():\n",
    "                    hopChildNodes = hopNode.get_children()\n",
    "                    for node in hopChildNodes:\n",
    "                        \n",
    "                        if node.ip == hop_ip:\n",
    "                            hopChildNode = node\n",
    "                            need_new_child_node = False\n",
    "                \n",
    "                if need_new_child_node:\n",
    "                    hop_type = 'Node'\n",
    "                    if hop_ip in cdn_ip_set:\n",
    "                        hop_type = 'CDN'\n",
    "                    asn_info, _ = asndb.lookup(hop_ip)\n",
    "                    country = None\n",
    "                    if hop_ip in ip_to_country_dict:\n",
    "                        country = ip_to_country_dict[hop_ip]\n",
    "                    else:\n",
    "                        geo_details = find_ip(hop_ip,ip_to_country_df)\n",
    "                        if geo_details is not None:\n",
    "                            if 'country_code' in geo_details:\n",
    "                                country = geo_details['country_code']\n",
    "                                ip_to_country_dict[hop_ip] = country\n",
    "                        else:\n",
    "                            ip_to_country_dict[hop_ip] = None\n",
    "\n",
    "                    newChildNode = Hop(\n",
    "                        ip=hop_ip,\n",
    "                        type=hop_type,\n",
    "                        min_rtt=min_hop_rtt,\n",
    "                        asn=asn_info,\n",
    "                        hostname=None,\n",
    "                        country=country,\n",
    "                        location=None,\n",
    "                    )\n",
    "                    hopNode.add_children(newChildNode)\n",
    "                    hopChildNode = newChildNode\n",
    "                else:\n",
    "                    this_min_rtt = min_hop_rtt\n",
    "                    prev_min_rtt = hopChildNode.min_rtt\n",
    "                    if this_min_rtt < prev_min_rtt:\n",
    "                        hopChildNode.min_rtt = this_min_rtt\n",
    "                hopNode = hopChildNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdn_ip_count_rtt_old = {}\n",
    "cf_loc_to_count_old = {}\n",
    "\n",
    "domain_list = [\n",
    "  \"www.broadcom.com\",\n",
    "  \"www.comodoca.com\",\n",
    "  \"www.apnic.net\",\n",
    "  \"www.riskified.com\",\n",
    "  \"www.wiley.com\",\n",
    "  \"www.vmware.com\",\n",
    "  \"www.sportskeeda.com\",\n",
    "  \"www.garmin.com\", #IPV4 only\n",
    "  \"www.fao.org\",\n",
    "  \"www.n-able.com\",\n",
    "    ]\n",
    "\n",
    "\n",
    "# FOR PROBE LIST\n",
    "probes_list = [65337] # For GU probe\n",
    "pop_ip_addr_set = set()\n",
    "for probe_id in probes_list:\n",
    "  for domain in domain_list:\n",
    "    if domain in probes_cf_path_old[probe_id]['paths']:\n",
    "        pop_ip_addr_set = pop_ip_addr_set.union(set(probes_cf_path_old[probe_id]['paths'][domain].keys()))\n",
    "pop_ip_addr_list = list(pop_ip_addr_set)\n",
    "print(pop_ip_addr_list)\n",
    "\n",
    "\n",
    "glb_pop_ips_unknown = set()\n",
    "glb_last_unicast_ips = set()\n",
    "glb_last_unicast_ips_within_rtt = set()\n",
    "glb_loc_to_count = {}\n",
    "glb_pop_ip_dict = {}\n",
    "\n",
    "for probe_id in probes_list:\n",
    "  for domain in domain_list:\n",
    "    for pop_ip_address in pop_ip_addr_list:\n",
    "      if domain not in probes_cf_path_old[probe_id]['paths']:\n",
    "        continue\n",
    "      if pop_ip_address in probes_cf_path_old[probe_id]['paths'][domain]:\n",
    "        rootNode = probes_cf_path_old[probe_id]['paths'][domain][pop_ip_address]\n",
    "        pop_ips_unknown, last_unicast_ips, last_unicast_ips_within_rtt, pop_ips_known, pop_ip_dict, loc_to_count = go_through_all_nodes_cf(root=rootNode,pop_ip_addr=pop_ip_address)\n",
    "        \n",
    "        glb_pop_ips_unknown = glb_pop_ips_unknown.union(pop_ips_unknown)\n",
    "        glb_last_unicast_ips = glb_last_unicast_ips.union(set(last_unicast_ips.keys()))\n",
    "        glb_last_unicast_ips_within_rtt = glb_last_unicast_ips_within_rtt.union(last_unicast_ips_within_rtt)\n",
    "        glb_pop_ip_dict.update(pop_ip_dict)\n",
    "\n",
    "        for ip_location, count in loc_to_count.items():\n",
    "          if ip_location not in glb_loc_to_count:\n",
    "            glb_loc_to_count[ip_location] = 0\n",
    "          glb_loc_to_count[ip_location] += count\n",
    "\n",
    "print(f\"glb_pop_ip_dict={glb_pop_ip_dict}\")  \n",
    "print(f\"glb_pop_ips_unknown={glb_pop_ips_unknown}\")\n",
    "print(f\"glb_loc_to_count={glb_loc_to_count}\")\n",
    "print(f\"glb_last_unicast_ips_within_rtt={glb_last_unicast_ips_within_rtt}\")\n",
    "\n",
    "known_unicast_ips = []\n",
    "for ip in list(glb_last_unicast_ips_within_rtt):\n",
    "  known_unicast_ips.append(ip)\n",
    "  ipinfo_details = find_ip(ip, ip_to_country_df)\n",
    "  if ipinfo_details:\n",
    "    if 'country' in ipinfo_details:\n",
    "      print(f\"IP: {ip} -> {ipinfo_details['country']}\")\n",
    "    else:\n",
    "      print(f\"IP: {ip} -> unknown\")   \n",
    "  else:\n",
    "    print(f\"IP: {ip} -> unknown\")\n",
    "\n",
    "\n",
    "\n",
    "all_last_unicast_ips = set()\n",
    "for idx, each_msm in enumerate(cf_accumulated_trace_json_old,start=0):\n",
    "\n",
    "  prb_id = each_msm['prb_id']\n",
    "  if prb_id == probe_id: \n",
    "      pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "      if len(each_msm['all_hops']) >=2:\n",
    "        cdn_ip_list = each_msm['all_hops'][-2]['hop_ips']\n",
    "\n",
    "        if each_msm['domain'] in domain_list:\n",
    "            for msm_idx, ip in enumerate(cdn_ip_list):\n",
    "\n",
    "                all_last_unicast_ips.add(ip)\n",
    "                if ip not in cdn_ip_count_rtt_old:\n",
    "                    cdn_ip_count_rtt_old[ip] = []\n",
    "                \n",
    "                cdn_ip_count_rtt_old[ip].append(each_msm['all_hops'][-2]['hop_rtts'][msm_idx])\n",
    "\n",
    "\n",
    "\n",
    "for ip, cdn_rt_list in cdn_ip_count_rtt_old.items():\n",
    "    loc = \"unknown\"\n",
    "\n",
    "    if ip in glb_last_unicast_ips_within_rtt:\n",
    "      if ip in ip_to_details and ip_to_details[ip]['location'] is not None:\n",
    "          loc = ip_to_details[ip]['location']\n",
    "          print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "      else:\n",
    "          ipinfo_details = find_ip(ip,ip_to_country_df)\n",
    "          if ipinfo_details:\n",
    "              loc = ipinfo_details['country']\n",
    "              print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "          else:\n",
    "\n",
    "              print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}]\")\n",
    "    else:\n",
    "       print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}]\")\n",
    "\n",
    "    if loc not in cf_loc_to_count_old:\n",
    "        cf_loc_to_count_old[loc] = 0\n",
    "    cf_loc_to_count_old[loc] += len(cdn_rt_list)\n",
    "\n",
    "sum = 0\n",
    "for value in cf_loc_to_count_old.values():\n",
    "    sum += value\n",
    "\n",
    "print(\"************** Final Count ****************\")\n",
    "for loc, value in cf_loc_to_count_old.items():\n",
    "    print(f\"{loc} : {round((value/sum) * 100,2)}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Akamai - Late 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"akamai\"\n",
    "\n",
    "acc_result_filename = \"acc_trace_akamai_final_result.json\"\n",
    "full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "\n",
    "akamai_accumulated_trace_json = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    akamai_accumulated_trace_json = json.load(json_file)\n",
    "    print(\"Accumulated Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akamai_controlled_nodes_traceroute_files_path = f\"{controlled_top_level_folder_path}/traceroute/08-27-2025-12-31-18_WebTrace_files_list\"\n",
    "akamai_controlled_acc_filename = \"controlled_nodes_acc_trace_akamai_final_result_late.json\"\n",
    "akamai_controlled_accumulated_trace_json = []\n",
    "akamai_controlled_acc_filepath = os.path.join(akamai_controlled_nodes_traceroute_files_path,\"acc_result\",akamai_controlled_acc_filename)\n",
    "with open(akamai_controlled_acc_filepath, \"r\") as json_file:\n",
    "    akamai_controlled_accumulated_trace_json = json.load(json_file)\n",
    "\n",
    "\n",
    "akamai_accumulated_trace_json += akamai_controlled_accumulated_trace_json\n",
    "print(f\"{len(akamai_controlled_accumulated_trace_json)} controlled node measurements added to accumulated_trace_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdn_ip_count_rtt = {}\n",
    "\n",
    "\n",
    "chosen_country_list = [\"US\", \"CA\" ,\"DE\", \"HU\", \"CL\", \"CO\", \"AU\", \"NZ\" ,\"PH\", \"GU\", \"BJ\", \"ZW\" , \"ZM\", \"MG\"]\n",
    "\n",
    "domain_list = [\n",
    "    \"www.microsoft.com\", #IPV4 only\n",
    "    \"www.apple.com\", #IPV4 only\n",
    "    \"www.bing.com\", #IPV4 only\n",
    "    \"www.icloud.com\", #IPV4 only\n",
    "    \"www.intuit.com\",\n",
    "    \"www.unity3d.com\",\n",
    "    \"www.samsung.com\",\n",
    "    \"www.ebay.com\",\n",
    "    \"www.webex.com\", #IPV4 only\n",
    "    \"www.cisco.com\", #IPV4 only\n",
    "    ]\n",
    "\n",
    "for idx, each_msm in enumerate(akamai_accumulated_trace_json,start=0):\n",
    "\n",
    "        prb_id = each_msm['prb_id']\n",
    "        country_code = each_msm['country_code']\n",
    "\n",
    "        if country_code in chosen_country_list:\n",
    "  \n",
    "            if country_code not in cdn_ip_count_rtt:\n",
    "                cdn_ip_count_rtt[country_code] = {}\n",
    "            pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "            cdn_ip_set = set(each_msm['all_hops'][-1]['hop_ips'])\n",
    "            dst_addr = each_msm['dst_addr']\n",
    "            if each_msm['domain'] in domain_list[:5]:\n",
    "                for msm_idx, ip in enumerate(cdn_ip_set):\n",
    "\n",
    "                    if ip == dst_addr:\n",
    "                        if ip not in cdn_ip_count_rtt[country_code]:\n",
    "                            cdn_ip_count_rtt[country_code][ip] = []\n",
    "                        \n",
    "                        cdn_ip_count_rtt[country_code][ip].append(each_msm['all_hops'][-1]['hop_rtts'][msm_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akamai_loc_to_count = {}\n",
    "\n",
    "with open(\"../dataset/ip_to_country_dns_cdn_dict.json\",\"r\") as json_file:\n",
    "    ip_to_country_dns_cdn_dict = json.load(json_file)\n",
    "\n",
    "\n",
    "for country_code in list(cdn_ip_count_rtt.keys()):\n",
    "\n",
    "    if country_code not in akamai_loc_to_count:\n",
    "        akamai_loc_to_count[country_code] = {}\n",
    "    for ip, cdn_rt_list in cdn_ip_count_rtt[country_code].items():\n",
    "        loc = \"unknown\"\n",
    "        if ip in ip_to_country_dns_cdn_dict and ip_to_country_dns_cdn_dict[ip] is not None:\n",
    "            loc = ip_to_country_dns_cdn_dict[ip]\n",
    "\n",
    "        else:\n",
    "            ipinfo_details = find_ip(ip,ip_to_country_df)\n",
    "            if ipinfo_details:\n",
    "                loc = ipinfo_details['country_code']\n",
    "                ip_to_country_dns_cdn_dict[ip] = loc\n",
    "        \n",
    "        \n",
    "        if loc not in akamai_loc_to_count[country_code]:\n",
    "            akamai_loc_to_count[country_code][loc] = 0\n",
    "        akamai_loc_to_count[country_code][loc] += len(cdn_rt_list)\n",
    "\n",
    "with open(\"../dataset/ip_to_country_dns_cdn_dict.json\",\"w\") as json_file:\n",
    "    json.dump(ip_to_country_dns_cdn_dict,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del sum\n",
    "akamai_loc_to_count_filtered = {}\n",
    "for chosen_country in list(akamai_loc_to_count.keys()):\n",
    "    print(f\"Country: {chosen_country}\")\n",
    "    akamai_loc_to_count_filtered[chosen_country] = {}\n",
    "    total_sum_locs = __builtins__.sum(akamai_loc_to_count[chosen_country].values())\n",
    "\n",
    "    print(\"************** Akamai Final Count ****************\")\n",
    "    for loc, value in akamai_loc_to_count[chosen_country].items():\n",
    "        loc_percent = round((value/total_sum_locs) * 100,2)\n",
    "        if loc_percent > 5:\n",
    "            akamai_loc_to_count_filtered[chosen_country][loc] = loc_percent\n",
    "            print(f\"{loc} : {loc_percent}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_list = [65337] # for GU probe\n",
    "\n",
    "cdn_ip_count_rtt = {}\n",
    "akamai_loc_to_count_gu = {}\n",
    "\n",
    "domain_list = [\n",
    "    \"www.microsoft.com\", #IPV4 only\n",
    "    \"www.apple.com\", #IPV4 only\n",
    "    \"www.bing.com\", #IPV4 only\n",
    "    \"www.icloud.com\", #IPV4 only\n",
    "    \"www.intuit.com\",\n",
    "    \"www.unity3d.com\",\n",
    "    \"www.samsung.com\",\n",
    "    \"www.ebay.com\",\n",
    "    \"www.webex.com\", #IPV4 only\n",
    "    \"www.cisco.com\", #IPV4 only\n",
    "    ]\n",
    "prbs_found_new = []\n",
    "for idx, each_msm in enumerate(akamai_accumulated_trace_json,start=0):\n",
    "\n",
    "        prb_id = each_msm['prb_id']\n",
    "        if prb_id in probes_list: \n",
    "            if prb_id not in prbs_found_new:\n",
    "                prbs_found_new.append(prb_id)\n",
    "            pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "            cdn_ip_set = set(each_msm['all_hops'][-1]['hop_ips'])\n",
    "            if each_msm['domain'] in domain_list:\n",
    "                for msm_idx, ip in enumerate(cdn_ip_set):\n",
    "\n",
    "                        if ip not in cdn_ip_count_rtt:\n",
    "                            cdn_ip_count_rtt[ip] = []\n",
    "                        \n",
    "                        cdn_ip_count_rtt[ip].append(each_msm['all_hops'][-1]['hop_rtts'][msm_idx])\n",
    "\n",
    "for ip, cdn_rt_list in cdn_ip_count_rtt.items():\n",
    "    loc = \"unknown\"\n",
    "    if ip in ip_to_details and ip_to_details[ip]['location'] is not None:\n",
    "        loc = ip_to_details[ip]['location']\n",
    "        print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "    else:\n",
    "        ipinfo_details = find_ip(ip,ip_to_country_df)\n",
    "        if ipinfo_details:\n",
    "            loc = ipinfo_details['country']\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "        else:\n",
    "\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}]\")\n",
    "    \n",
    "    if loc not in akamai_loc_to_count_gu:\n",
    "        akamai_loc_to_count_gu[loc] = 0\n",
    "    akamai_loc_to_count_gu[loc] += len(cdn_rt_list)\n",
    "\n",
    "sum = 0\n",
    "for value in akamai_loc_to_count_gu.values():\n",
    "    sum += value\n",
    "\n",
    "print(\"************** Final Count ****************\")\n",
    "for loc, value in akamai_loc_to_count_gu.items():\n",
    "    print(f\"{loc} : {round((value/sum) * 100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Akamai - Early 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"akamai\"\n",
    "\n",
    "acc_result_filename = \"acc_trace_akamai_final_result.json\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "\n",
    "akamai_accumulated_trace_json_old = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    akamai_accumulated_trace_json_old = json.load(json_file)\n",
    "    print(\"Accumulated Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_list = [65337] # For GU probe\n",
    "\n",
    "cdn_ip_count_rtt_old = {}\n",
    "akamai_loc_to_count_old = {} # Holds only for GU\n",
    "\n",
    "domain_list = [\n",
    "    \"www.microsoft.com\", #IPV4 only\n",
    "    \"www.apple.com\", #IPV4 only\n",
    "    \"www.bing.com\", #IPV4 only\n",
    "    \"www.icloud.com\", #IPV4 only\n",
    "    \"www.intuit.com\",\n",
    "    \"www.unity3d.com\",\n",
    "    \"www.samsung.com\",\n",
    "    \"www.ebay.com\",\n",
    "    \"www.webex.com\", #IPV4 only\n",
    "    \"www.cisco.com\", #IPV4 only\n",
    "    ]\n",
    "prbs_found_old = []\n",
    "for idx, each_msm in enumerate(akamai_accumulated_trace_json_old,start=0):\n",
    "\n",
    "        prb_id = each_msm['prb_id']\n",
    "        if prb_id in probes_list: \n",
    "            if prb_id not in prbs_found_old:\n",
    "                prbs_found_old.append(prb_id)\n",
    "            pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "            cdn_ip_set = set(each_msm['all_hops'][-1]['hop_ips'])\n",
    "            if each_msm['domain'] in domain_list:\n",
    "                for msm_idx, ip in enumerate(cdn_ip_set):\n",
    "\n",
    "                        if ip not in cdn_ip_count_rtt_old:\n",
    "                            cdn_ip_count_rtt_old[ip] = []\n",
    "                        \n",
    "                        cdn_ip_count_rtt_old[ip].append(each_msm['all_hops'][-1]['hop_rtts'][msm_idx])\n",
    "\n",
    "for ip, cdn_rt_list in cdn_ip_count_rtt_old.items():\n",
    "    loc = \"unknown\"\n",
    "    if ip in ip_to_details and ip_to_details[ip]['location'] is not None:\n",
    "        loc = ip_to_details[ip]['location']\n",
    "        print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "    else:\n",
    "        ipinfo_details = find_ip(ip,ip_to_country_df)\n",
    "        if ipinfo_details:\n",
    "            loc = ipinfo_details['country']\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "        else:\n",
    "\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}]\")\n",
    "    \n",
    "    if loc not in akamai_loc_to_count_old:\n",
    "        akamai_loc_to_count_old[loc] = 0\n",
    "    akamai_loc_to_count_old[loc] += len(cdn_rt_list)\n",
    "\n",
    "sum = 0\n",
    "for value in akamai_loc_to_count_old.values():\n",
    "    sum += value\n",
    "\n",
    "print(\"************** Final Count ****************\")\n",
    "for loc, value in akamai_loc_to_count_old.items():\n",
    "    print(f\"{loc} : {round((value/sum) * 100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloudfront - Late 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"cloudfront\"\n",
    "\n",
    "acc_result_filename = \"acc_trace_cloudfront_final_result.json\"\n",
    "full_msms_path = os.path.join(top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "\n",
    "cloudfront_acc_tracert_json = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    cloudfront_acc_tracert_json = json.load(json_file)\n",
    "    print(\"Accumulated Cloudfront Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_nodes_traceroute_files_path = f\"{controlled_top_level_folder_path}/traceroute/08-27-2025-12-31-18_WebTrace_files_list\"\n",
    "cfront_controlled_acc_filename = \"controlled_nodes_acc_trace_cloudfront_final_result_late.json\"\n",
    "cfront_controlled_accumulated_trace_json = []\n",
    "cfront_controlled_acc_filepath = os.path.join(controlled_nodes_traceroute_files_path,\"acc_result\",cfront_controlled_acc_filename)\n",
    "with open(cfront_controlled_acc_filepath, \"r\") as json_file:\n",
    "    cloudfront_controlled_accumulated_trace_json = json.load(json_file)\n",
    "\n",
    "\n",
    "cloudfront_acc_tracert_json += cloudfront_controlled_accumulated_trace_json\n",
    "print(f\"{len(cloudfront_controlled_accumulated_trace_json)} controlled node measurements added to accumulated_trace_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfront_cdn_ip_count_rtt = {}\n",
    "all_cfront_countries = set()\n",
    "\n",
    "chosen_country_list = [\"US\", \"CA\" ,\"DE\", \"HU\", \"CL\", \"CO\", \"AU\", \"NZ\" ,\"PH\", \"GU\", \"BJ\", \"ZW\" , \"ZM\", \"MG\"]\n",
    "\n",
    "domain_list = [\n",
    "    \"www.soundcloud.com\",\n",
    "    \"www.zynga.com\", #IPV4 only\n",
    "    \"www.doi.org\",\n",
    "    \"www.booking.com\",\n",
    "    \"www.brave.com\", #IPV4 only\n",
    "    \"www.tycsports.com\", #IPV4 only\n",
    "    \"www.logitech.com\", #IPV4 only\n",
    "    \"www.checkpoint.com\",\n",
    "    \"www.goodreads.com\",\n",
    "    \"www.surveymonkey.com\"  \n",
    "    ]\n",
    "\n",
    "for idx, each_msm in enumerate(cloudfront_acc_tracert_json,start=0):\n",
    "        prb_id = each_msm['prb_id']\n",
    "        country_code = each_msm['country_code']\n",
    "        all_cfront_countries.add(country_code)\n",
    "\n",
    "        if country_code in chosen_country_list:\n",
    "            if country_code not in cfront_cdn_ip_count_rtt:\n",
    "                cfront_cdn_ip_count_rtt[country_code] = {}\n",
    "            pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "            cdn_ip_set = set(each_msm['all_hops'][-1]['hop_ips'])\n",
    "            dst_addr = each_msm['dst_addr']\n",
    "            if each_msm['domain'] in domain_list[:5]:\n",
    "                for msm_idx, ip in enumerate(cdn_ip_set):\n",
    "                    if ip == dst_addr:\n",
    "                        if ip not in cfront_cdn_ip_count_rtt[country_code]:\n",
    "                            cfront_cdn_ip_count_rtt[country_code][ip] = []\n",
    "                        \n",
    "                        cfront_cdn_ip_count_rtt[country_code][ip].append(each_msm['all_hops'][-1]['hop_rtts'][msm_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudfront_loc_to_count = {}\n",
    "\n",
    "with open(\"../dataset/ip_to_country_dns_cdn_dict.json\",\"r\") as json_file:\n",
    "    ip_to_country_dns_cdn_dict = json.load(json_file)\n",
    "\n",
    "\n",
    "for country_code in list(cfront_cdn_ip_count_rtt.keys()):\n",
    "\n",
    "    if country_code not in cloudfront_loc_to_count:\n",
    "        cloudfront_loc_to_count[country_code] = {}\n",
    "    for ip, cdn_rt_list in cfront_cdn_ip_count_rtt[country_code].items():\n",
    "        loc = \"unknown\"\n",
    "        if ip in ip_to_country_dns_cdn_dict and ip_to_country_dns_cdn_dict[ip] is not None:\n",
    "            loc = ip_to_country_dns_cdn_dict[ip]\n",
    "\n",
    "        else:\n",
    "            ipinfo_details = find_ip(ip,ip_to_country_df)\n",
    "            if ipinfo_details:\n",
    "                loc = ipinfo_details['country_code']\n",
    "                ip_to_country_dns_cdn_dict[ip] = loc\n",
    "        \n",
    "        \n",
    "        if loc not in cloudfront_loc_to_count[country_code]:\n",
    "            cloudfront_loc_to_count[country_code][loc] = 0\n",
    "        cloudfront_loc_to_count[country_code][loc] += len(cdn_rt_list)\n",
    "\n",
    "with open(\"../dataset/ip_to_country_dns_cdn_dict.json\",\"w\") as json_file:\n",
    "    json.dump(ip_to_country_dns_cdn_dict,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del sum\n",
    "cloudfront_loc_to_count_filtered = {}\n",
    "for chosen_country in list(cfront_cdn_ip_count_rtt.keys()):\n",
    "    print(f\"Country: {chosen_country}\")\n",
    "    cloudfront_loc_to_count_filtered[chosen_country] = {}\n",
    "    total_sum_locs = __builtins__.sum(cloudfront_loc_to_count[chosen_country].values())\n",
    "\n",
    "    print(\"************** cloudfront Final Count ****************\")\n",
    "    for loc, value in cloudfront_loc_to_count[chosen_country].items():\n",
    "        loc_percent = round((value/total_sum_locs) * 100,2)\n",
    "        if loc_percent > 5:\n",
    "            cloudfront_loc_to_count_filtered[chosen_country][loc] = loc_percent\n",
    "            print(f\"{loc} : {loc_percent}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdn_ip_count_rtt = {}\n",
    "cfront_loc_to_count = {}\n",
    "\n",
    "\n",
    "domain_list = [\n",
    "    \"www.soundcloud.com\",\n",
    "    \"www.zynga.com\", #IPV4 only\n",
    "    \"www.doi.org\",\n",
    "    \"www.booking.com\",\n",
    "    \"www.brave.com\", #IPV4 only\n",
    "    \"www.tycsports.com\", #IPV4 only\n",
    "    \"www.logitech.com\", #IPV4 only\n",
    "    \"www.checkpoint.com\",\n",
    "    \"www.goodreads.com\",\n",
    "    \"www.surveymonkey.com\"\n",
    "    ]\n",
    "\n",
    "\n",
    "probes_list = [65337]\n",
    "\n",
    "for idx, each_msm in enumerate(cloudfront_acc_tracert_json,start=0):\n",
    "\n",
    "        prb_id = each_msm['prb_id']\n",
    "        if prb_id in probes_list: \n",
    "            pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "            cdn_ip_list = each_msm['all_hops'][-1]['hop_ips']\n",
    "            if each_msm['domain'] in domain_list:\n",
    "                for msm_idx, ip in enumerate(cdn_ip_list):\n",
    "\n",
    "                        if ip not in cdn_ip_count_rtt:\n",
    "                            cdn_ip_count_rtt[ip] = []\n",
    "                        \n",
    "                        cdn_ip_count_rtt[ip].append(each_msm['all_hops'][-1]['hop_rtts'][msm_idx])\n",
    "\n",
    "for ip, cdn_rt_list in cdn_ip_count_rtt.items():\n",
    "    loc = \"unknown\"\n",
    "    if ip in ip_to_details and ip_to_details[ip]['location'] is not None:\n",
    "        loc = ip_to_details[ip]['location']\n",
    "        print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "    else:\n",
    "        ipinfo_details = find_ip(ip,ip_to_country_df)\n",
    "        if ipinfo_details:\n",
    "            loc = ipinfo_details['country']\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "        else:\n",
    "\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}]\")\n",
    "    \n",
    "    if loc not in cfront_loc_to_count:\n",
    "        cfront_loc_to_count[loc] = 0\n",
    "    cfront_loc_to_count[loc] += len(cdn_rt_list)\n",
    "\n",
    "sum = 0\n",
    "for value in cfront_loc_to_count.values():\n",
    "    sum += value\n",
    "\n",
    "print(\"************** Final Count ****************\")\n",
    "for loc, value in cfront_loc_to_count.items():\n",
    "    print(f\"{loc} : {round((value/sum) * 100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloudfront - Early 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"cloudfront\"\n",
    "\n",
    "acc_result_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "\n",
    "cfront_accumulated_trace_json_old = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    cfront_accumulated_trace_json_old = json.load(json_file)\n",
    "    print(\"Accumulated Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdn_ip_count_rtt_old = {}\n",
    "cfront_loc_to_count_old = {}\n",
    "\n",
    "\n",
    "domain_list = [\n",
    "    \"www.soundcloud.com\",\n",
    "    \"www.zynga.com\", #IPV4 only\n",
    "    \"www.doi.org\",\n",
    "    \"www.booking.com\",\n",
    "    \"www.brave.com\", #IPV4 only\n",
    "    \"www.tycsports.com\", #IPV4 only\n",
    "    \"www.logitech.com\", #IPV4 only\n",
    "    \"www.checkpoint.com\",\n",
    "    \"www.goodreads.com\",\n",
    "    \"www.surveymonkey.com\"\n",
    "    ]\n",
    "\n",
    "\n",
    "probes_list = [65337]\n",
    "\n",
    "for idx, each_msm in enumerate(cfront_accumulated_trace_json_old,start=0):\n",
    "\n",
    "        prb_id = each_msm['prb_id']\n",
    "        if prb_id in probes_list: \n",
    "            pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "            cdn_ip_list = each_msm['all_hops'][-1]['hop_ips']\n",
    "            if each_msm['domain'] in domain_list:\n",
    "                for msm_idx, ip in enumerate(cdn_ip_list):\n",
    "\n",
    "                        if ip not in cdn_ip_count_rtt_old:\n",
    "                            cdn_ip_count_rtt_old[ip] = []\n",
    "                        \n",
    "                        cdn_ip_count_rtt_old[ip].append(each_msm['all_hops'][-1]['hop_rtts'][msm_idx])\n",
    "\n",
    "for ip, cdn_rt_list in cdn_ip_count_rtt_old.items():\n",
    "    loc = \"unknown\"\n",
    "    if ip in ip_to_details and ip_to_details[ip]['location'] is not None:\n",
    "        loc = ip_to_details[ip]['location']\n",
    "        print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "    else:\n",
    "        ipinfo_details = find_ip(ip,ip_to_country_df)\n",
    "        if ipinfo_details:\n",
    "            loc = ipinfo_details['country']\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}] -> ({loc})\")\n",
    "        else:\n",
    "\n",
    "            print(f\"{ip} : {statistics.median(cdn_rt_list)} ms [{len(cdn_rt_list)}]\")\n",
    "    \n",
    "    if loc not in cfront_loc_to_count_old:\n",
    "        cfront_loc_to_count_old[loc] = 0\n",
    "    cfront_loc_to_count_old[loc] += len(cdn_rt_list)\n",
    "\n",
    "sum = 0\n",
    "for value in cfront_loc_to_count_old.values():\n",
    "    sum += value\n",
    "\n",
    "print(\"************** Final Count ****************\")\n",
    "for loc, value in cfront_loc_to_count_old.items():\n",
    "    print(f\"{loc} : {round((value/sum) * 100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compound bar - All CDN locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import operator\n",
    "rcParams['font.size'] = 10\n",
    "rcParams[\"font.family\"] = \"CMU Sans Serif\"\n",
    "width = 1.2\n",
    "\n",
    "color_map = {}\n",
    "\n",
    "cmap_26 = plt.get_cmap('hsv') \n",
    "\n",
    "# Sample N equally spaced colors from the map's range (0.0 to 1.0)\n",
    "colors_26 = [cmap_26(i) for i in np.linspace(0, 1, 26)]\n",
    "\n",
    "colors_tab20 = plt.get_cmap('tab20').colors \n",
    "\n",
    "# Get 6 additional, distinct colors\n",
    "colors_set1 = plt.get_cmap('Set2').colors[:6] \n",
    "\n",
    "# Combine them for 26 unique colors\n",
    "colors_26_combined = colors_tab20 + colors_set1\n",
    "\n",
    "country_priority_dict = {\n",
    "    \"CA\" : [\"US\", \"CA\"],\n",
    "    \"CO\" : [\"CO\", \"CL\", \"PE\"],\n",
    "    \"PH\" : [\"SG\", \"HK\"],\n",
    "    \"GU\" : [\"SG\", \"HK\", \"US\"],\n",
    "    \"BJ\" : [\"ZA\", \"NG\", \"GB\"],\n",
    "    \"MG\" : [\"ZA\"]\n",
    "}\n",
    "\n",
    "# color_map = {\n",
    "#     \"AT\": cols_tab20[0],\n",
    "#     \"AU\": cols_tab20[1],\n",
    "#     \"US\": cols_tab20[2],\n",
    "#     \"CL\": cols_tab20[3],\n",
    "#     \"CA\": cols_tab20[4],\n",
    "#     \"CO\": cols_tab20[17],\n",
    "#     \"DE\": cols_tab20[6],\n",
    "#     \"GB\": cols_tab20[7],\n",
    "#     \"HK\": cols_tab20[8],\n",
    "#     \"IT\": cols_tab20[9],\n",
    "#     \"JP\": cols_tab20[10],\n",
    "#     \"NZ\" : cols_tab20[11],\n",
    "#     \"PE\" : cols_tab20[12],\n",
    "#     \"SG\" : cols_tab20[13],\n",
    "#     \"BR\" : cols_tab20[19],\n",
    "#     \"ZA\" : cols_tab20[18]\n",
    "# }\n",
    "\n",
    "unique_countries = set()\n",
    "fig, ax = plt.subplots(figsize=(8.37, 4.37))\n",
    "\n",
    "first_handles = [Patch(facecolor='none',edgecolor='darkorange'),Patch(facecolor='none',edgecolor='darkgreen'),Patch(facecolor='none',edgecolor='purple')]\n",
    "first_labels = [\"Cloudflare\", \"Akamai\", \"Cloudfront\"]\n",
    "first_legend = ax.legend(first_handles, first_labels, loc=\"lower left\",bbox_to_anchor=(0.1, 1) , facecolor=\"white\", framealpha=1.0, fontsize=12, edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4, frameon=False)\n",
    "ax.add_artist(first_legend)\n",
    "last_pos = 0\n",
    "space = 0.3\n",
    "alpha_param = 0.2\n",
    "\n",
    "all_labels = []\n",
    "x_A = np.arange(len(chosen_country_list)) * 5.5\n",
    "\n",
    "\n",
    "x_ticks = x_A + width + space\n",
    "\n",
    "color_idx = 0\n",
    "\n",
    "for j_dx, chosen_country_code in enumerate(chosen_country_list):\n",
    "\n",
    "    all_labels.append(chosen_country_code)\n",
    "    bottom_accumulated = 0\n",
    "\n",
    "    cf_loc_to_count_filtered_country = cf_loc_to_count_filtered[chosen_country_code]\n",
    "\n",
    "    if chosen_country_code in country_priority_dict:\n",
    "        cf_loc_to_count_filtered_country = {}\n",
    "        for priority_cdn_loc in country_priority_dict[chosen_country_code]:\n",
    "            if priority_cdn_loc in cf_loc_to_count_filtered[chosen_country_code]:\n",
    "                cf_loc_to_count_filtered_country[priority_cdn_loc] = cf_loc_to_count_filtered[chosen_country_code][priority_cdn_loc]\n",
    "        \n",
    "        remaining_cdn_locs = set(cf_loc_to_count_filtered[chosen_country_code]) - set(cf_loc_to_count_filtered_country.keys())\n",
    "\n",
    "        for other_cdn_loc in remaining_cdn_locs:\n",
    "            cf_loc_to_count_filtered_country[other_cdn_loc] = cf_loc_to_count_filtered[chosen_country_code][other_cdn_loc]\n",
    "\n",
    "    for idx, (cdn_loc, value) in enumerate(cf_loc_to_count_filtered_country.items()):\n",
    "        alpha_param = 0.5\n",
    "        cf_country_percent = value\n",
    "        unique_countries.add(cdn_loc)\n",
    "        chosen_color = None\n",
    "        if cdn_loc not in color_map:\n",
    "            color_map[cdn_loc] = colors_26_combined[color_idx]\n",
    "\n",
    "            color_idx += 1\n",
    "\n",
    "        chosen_color = color_map.get(cdn_loc,\"gray\")\n",
    "\n",
    "        if cdn_loc == \"N/A\":\n",
    "            chosen_color = \"black\"\n",
    "            alpha_param = 1.0\n",
    "        ax.bar(x_A[j_dx],cf_country_percent,bottom=bottom_accumulated,width=width,color=chosen_color,alpha=alpha_param, label=cdn_loc,edgecolor='black')\n",
    "        if cdn_loc != \"N/A\":\n",
    "            ax.text(x_A[j_dx]-0.25,(2*bottom_accumulated+cf_country_percent)/2,cdn_loc, va='center', fontsize=\"xx-small\", color ='black',rotation=90)\n",
    " \n",
    "        bottom_accumulated += cf_country_percent\n",
    "    \n",
    "    if bottom_accumulated != 100:\n",
    "        ax.bar(x_A[j_dx],100-bottom_accumulated,bottom=bottom_accumulated,width=width,color=\"white\", hatch='///',  alpha=alpha_param, label=cdn_loc, edgecolor='black')\n",
    "    \n",
    "    ax.bar(x_A[j_dx],100,bottom=0,width=width,color='none',alpha=1.0,edgecolor='darkorange',linewidth=1.8)\n",
    "\n",
    "    bottom_accumulated = 0\n",
    "\n",
    "    akamai_loc_to_count_filtered_country = akamai_loc_to_count_filtered[chosen_country_code]\n",
    "\n",
    "    if chosen_country_code in country_priority_dict:\n",
    "        akamai_loc_to_count_filtered_country = {}\n",
    "        for priority_cdn_loc in country_priority_dict[chosen_country_code]:\n",
    "            if priority_cdn_loc in akamai_loc_to_count_filtered[chosen_country_code]:\n",
    "                akamai_loc_to_count_filtered_country[priority_cdn_loc] = akamai_loc_to_count_filtered[chosen_country_code][priority_cdn_loc]\n",
    "        \n",
    "        remaining_cdn_locs = set(akamai_loc_to_count_filtered[chosen_country_code]) - set(akamai_loc_to_count_filtered_country.keys())\n",
    "\n",
    "        for other_cdn_loc in remaining_cdn_locs:\n",
    "            akamai_loc_to_count_filtered_country[other_cdn_loc] = akamai_loc_to_count_filtered[chosen_country_code][other_cdn_loc]\n",
    "\n",
    "    for idx, (cdn_loc, value) in enumerate(akamai_loc_to_count_filtered_country.items()):\n",
    "        alpha_param = 0.5\n",
    "        akamai_country_percent = value\n",
    "        unique_countries.add(cdn_loc)\n",
    "        chosen_color = None\n",
    "        if cdn_loc not in color_map:\n",
    "            color_map[cdn_loc] = colors_26_combined[color_idx]\n",
    "         \n",
    "            color_idx += 1\n",
    "        chosen_color = color_map.get(cdn_loc,\"gray\")\n",
    "\n",
    "        hatch_pattern = None\n",
    "        if cdn_loc == \"N/A\":\n",
    "            chosen_color = \"black\"\n",
    "            alpha_param = 1.0\n",
    "        ax.bar(x_A[j_dx]+width+space,akamai_country_percent,bottom=bottom_accumulated,width=width,color=chosen_color,alpha=alpha_param, label=cdn_loc, edgecolor='black')\n",
    "        if cdn_loc != \"N/A\":\n",
    "            ax.text(x_A[j_dx]+width+space-0.25,(2*bottom_accumulated+akamai_country_percent)/2,cdn_loc, va='center', fontsize=\"xx-small\", color ='black', rotation=90)\n",
    "        \n",
    "        bottom_accumulated += akamai_country_percent\n",
    "\n",
    "    if bottom_accumulated != 100:\n",
    "        ax.bar(x_A[j_dx]+width+space,100-bottom_accumulated,bottom=bottom_accumulated,width=width,color=\"white\", hatch='///', alpha=alpha_param, label=cdn_loc, edgecolor='black')\n",
    "\n",
    "    ax.bar(x_A[j_dx]+width+space,100,bottom=0,width=width,color='none',alpha=1.0,edgecolor='darkgreen',linewidth=1.8)\n",
    "\n",
    "    bottom_accumulated = 0\n",
    "\n",
    "    cloudfront_loc_to_count_filtered_country = cloudfront_loc_to_count_filtered[chosen_country_code]\n",
    "\n",
    "    if chosen_country_code in country_priority_dict:\n",
    "        cloudfront_loc_to_count_filtered_country = {}\n",
    "        for priority_cdn_loc in country_priority_dict[chosen_country_code]:\n",
    "            if priority_cdn_loc in cloudfront_loc_to_count_filtered[chosen_country_code]:\n",
    "                cloudfront_loc_to_count_filtered_country[priority_cdn_loc] = cloudfront_loc_to_count_filtered[chosen_country_code][priority_cdn_loc]\n",
    "        \n",
    "        remaining_cdn_locs = set(cloudfront_loc_to_count_filtered[chosen_country_code]) - set(cloudfront_loc_to_count_filtered_country.keys())\n",
    "\n",
    "        for other_cdn_loc in remaining_cdn_locs:\n",
    "            cloudfront_loc_to_count_filtered_country[other_cdn_loc] = cloudfront_loc_to_count_filtered[chosen_country_code][other_cdn_loc]\n",
    "\n",
    "    for idx, (cdn_loc, value) in enumerate(cloudfront_loc_to_count_filtered_country.items()):\n",
    "        alpha_param = 0.5\n",
    "        cloudfront_country_percent = value\n",
    "        unique_countries.add(cdn_loc)\n",
    "        chosen_color = None\n",
    "        if cdn_loc not in color_map:\n",
    "            color_map[cdn_loc] = colors_26_combined[color_idx]\n",
    "            color_idx += 1\n",
    "        chosen_color = color_map.get(cdn_loc,\"gray\")\n",
    "\n",
    "        if cdn_loc == \"N/A\":\n",
    "            chosen_color = \"black\"\n",
    "            alpha_param = 1.0\n",
    "        ax.bar(x_A[j_dx]+2*(width+space),cloudfront_country_percent,bottom=bottom_accumulated,width=width,color=chosen_color,alpha=alpha_param, label=cdn_loc, edgecolor='black')\n",
    "        if cdn_loc != \"N/A\":\n",
    "            ax.text(x_A[j_dx]+2*(width+space)-0.25,(2*bottom_accumulated+cloudfront_country_percent)/2,cdn_loc, va='center', fontsize=\"xx-small\", color ='black', rotation=90)\n",
    "\n",
    "        bottom_accumulated += cloudfront_country_percent\n",
    "\n",
    "    if bottom_accumulated != 100:\n",
    "        ax.bar(x_A[j_dx]+2*(width+space),100-bottom_accumulated,bottom=bottom_accumulated,width=width,color=\"white\", hatch='///', alpha=alpha_param, label=cdn_loc, edgecolor='black')\n",
    "\n",
    "    ax.bar(x_A[j_dx]+2*(width+space),100,bottom=0,width=width,color='none',alpha=1.0,edgecolor='purple',linewidth=1.8)  \n",
    "\n",
    "\n",
    "    last_pos = x_A[idx] + space\n",
    "\n",
    "plt.ylim(0,102)\n",
    "plt.xlim(-1,76)\n",
    "\n",
    "ax.tick_params(axis='both', labelsize=16)\n",
    "ax.set_yticks([0,10,20,30,40,50,60,70,80,90,100])\n",
    "\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_xticklabels(all_labels, rotation=0, ha=\"center\", fontsize=14)\n",
    "ax.set_ylabel(\"Percentage\",fontsize=16)\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='-', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "handles = [Patch(facecolor=\"black\",alpha=1.0,edgecolor='black',hatch=\"o\"),Patch(facecolor='none',edgecolor='black',hatch='///')]\n",
    "labels = [\"unknown\", \"other countries\"]\n",
    "ax.legend(handles, labels, loc=\"lower right\", bbox_to_anchor=(0.84, 1) ,fontsize=12, facecolor=\"white\", framealpha=1.0, edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4, frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/selected_countries_all_cdn_locations_percent.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/selected_countries_all_cdn_locations_percent.svg\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_country_list = [\"US\", \"CA\" ,\"DE\", \"HU\", \"CL\", \"CO\", \"AU\", \"NZ\" ,\"PH\", \"GU\", \"BJ\", \"ZW\" , \"ZM\", \"MG\"]\n",
    "\n",
    "data = {}\n",
    "for chosen_country_code in chosen_country_list:\n",
    "    cf_loc_to_count_filtered_country = cf_loc_to_count_filtered[chosen_country_code]\n",
    "    cf_loc_to_count_filtered_country_sorted = dict(sorted(cf_loc_to_count_filtered_country.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    akamai_loc_to_count_filtered_country = akamai_loc_to_count_filtered[chosen_country_code]\n",
    "    akamai_loc_to_count_filtered_country_sorted = dict(sorted(akamai_loc_to_count_filtered_country.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    cloudfront_loc_to_count_filtered_country = cloudfront_loc_to_count_filtered[chosen_country_code]\n",
    "    cloudfront_loc_to_count_filtered_country_sorted = dict(sorted(cloudfront_loc_to_count_filtered_country.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    if chosen_country_code not in data:\n",
    "        data[chosen_country_code] = {}\n",
    "        data[chosen_country_code]['Cloudflare'] = []\n",
    "        data[chosen_country_code]['Akamai'] = []\n",
    "        data[chosen_country_code]['Cloudfront'] = []\n",
    "\n",
    "    for cdn_loc, cf_country_percent in cf_loc_to_count_filtered_country_sorted.items():\n",
    "        if cf_country_percent > 5:\n",
    "            data[chosen_country_code]['Cloudflare'].append((cdn_loc,cf_country_percent))\n",
    "\n",
    "    for cdn_loc, akamai_country_percent in akamai_loc_to_count_filtered_country_sorted.items():\n",
    "        if akamai_country_percent > 5:\n",
    "            data[chosen_country_code]['Akamai'].append((cdn_loc,akamai_country_percent))\n",
    "\n",
    "    for cdn_loc, cloudfront_country_percent in cloudfront_loc_to_count_filtered_country_sorted.items():\n",
    "        if cloudfront_country_percent > 5:\n",
    "            data[chosen_country_code]['Cloudfront'].append((cdn_loc,cloudfront_country_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rcParams[\"font.size\"] = 12\n",
    "user_countries = list(data.keys())\n",
    "providers = ['Cloudflare', 'Akamai', 'Cloudfront']\n",
    "\n",
    "\n",
    "# 2. Setup Figure with Subplots (1 row, 3 columns)\n",
    "# sharey=True ensures country labels only show on the left\n",
    "\n",
    "gs_kw = dict(width_ratios=[3, 5, 4])\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(8.37, 4.37), \n",
    "                         gridspec_kw=gs_kw, constrained_layout=True)\n",
    "\n",
    "\n",
    "cmap = plt.cm.YlOrRd.copy()\n",
    "cmap.set_bad(color='white')\n",
    "\n",
    "# 3. Iterate through each provider to build its specific subplot\n",
    "for p_idx, provider in enumerate(providers):\n",
    "    ax = axes[p_idx]\n",
    "    if p_idx > 0:\n",
    "        ax.tick_params(axis='y', which='both', left=False, labelleft=False)\n",
    "    # Initialize a matrix for just this provider's sub-cells\n",
    "    if provider == \"Cloudflare\":\n",
    "        max_subcells = 3\n",
    "    elif provider == \"Akamai\":\n",
    "        max_subcells = 5\n",
    "    else:\n",
    "        max_subcells = 4\n",
    "    provider_matrix = np.full((len(user_countries), max_subcells), np.nan)\n",
    "    \n",
    "    for r, u_country in enumerate(user_countries):\n",
    "        cells = data[u_country][provider]\n",
    "        \n",
    "        for c_idx, (loc_code, percent) in enumerate(cells):\n",
    "            if c_idx < max_subcells:\n",
    "                provider_matrix[r, c_idx] = percent\n",
    "                text_color = \"white\" if percent > 70 else \"black\"\n",
    "                ax.text(c_idx, r, loc_code, ha=\"center\", va=\"center\", \n",
    "                        color=text_color, fontsize=12)\n",
    "\n",
    "    # Plot the heatmap for this provider\n",
    "    im = ax.imshow(provider_matrix, cmap=cmap, aspect='auto', vmin=0, vmax=100)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_title(provider, fontsize=14, fontweight='bold', pad=10)\n",
    "    ax.set_xticks([]) # Remove sub-cell ticks\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True) # Hide the box border\n",
    "\n",
    "# 4. Global labels and Colorbar\n",
    "axes[0].set_yticks(np.arange(len(user_countries)))\n",
    "axes[0].set_yticklabels(user_countries)\n",
    "\n",
    "# Position a shared colorbar on the right\n",
    "cbar_ax = fig.add_axes([1.01, 0.15, 0.02, 0.7])\n",
    "cbar_ax.tick_params(labelsize=12)\n",
    "\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/selected_countries_all_cdn_locations_percent_heatmap.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/selected_countries_all_cdn_locations_percent_heatmap.svg\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GU - old vs new CDN locations barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_to_country = {\n",
    "    'United States' : 'US',\n",
    "    'Seattle' : 'US',\n",
    "    'New York' : 'US',\n",
    "    'Chicago' : 'US',\n",
    "    'Toronto' : 'CA',\n",
    "    'Washington' : 'US',\n",
    "    'Minneapolis' : 'US',\n",
    "    'Los Angeles' : 'US',\n",
    "    'Boston' : 'US',\n",
    "    'New York' : 'US',\n",
    "    'San Jose' : 'US',\n",
    "    'Atlanta' : 'US',\n",
    "    'Canada' : 'CA',\n",
    "    'Philadelphia' : 'US',\n",
    "    'Detroit' : 'US,',\n",
    "    'Germany' : 'DE',\n",
    "    'United Kingdom' : 'GB',\n",
    "    'Australia' : 'AU',\n",
    "    'France' : 'FR',\n",
    "    'Hong Kong' : 'HKG',\n",
    "    'Mexico' : 'MX',\n",
    "    'Singapore' : 'SG',\n",
    "    'Philippines' : 'PH',\n",
    "    'Taiwan' : 'TW',\n",
    "    'Manila' : 'PH',\n",
    "    'Japan' : 'JP',\n",
    "    'Tokyo' : 'JP',\n",
    "    'Italy' : 'IT',\n",
    "    'Israel' : 'IL',\n",
    "    'The Netherlands' : 'NL',\n",
    "    'Finland' : 'FI',\n",
    "    'Malaysia' : 'MY',\n",
    "    'Vietnam' : 'VN',\n",
    "    'India' : 'IN',\n",
    "    'unknown' : 'N/A'\n",
    "}\n",
    "country_to_loc = {v:k for k,v in loc_to_country.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_loc_to_count_old = {}\n",
    "cc_loc_to_count_new = {}\n",
    "\n",
    "loc_to_count_dicts_old = [cf_loc_to_count_old,akamai_loc_to_count_old,cfront_loc_to_count_old] # these already are filtered for GU\n",
    "loc_to_count_dicts_new = [glb_cf_loc_to_count_abs_num['GU'],akamai_loc_to_count_gu,cfront_loc_to_count] # only for GU\n",
    "\n",
    "for count_dict in loc_to_count_dicts_old:\n",
    "    for location, count in count_dict.items():\n",
    "        cc_loc = loc_to_country[location]\n",
    "        if cc_loc not in cc_loc_to_count_old:\n",
    "            cc_loc_to_count_old[cc_loc] = 0\n",
    "\n",
    "        cc_loc_to_count_old[cc_loc] += count\n",
    "\n",
    "for count_dict in loc_to_count_dicts_new:\n",
    "    for location, count in count_dict.items():\n",
    "        if location not in loc_to_country.values():\n",
    "            if location == 'HK':\n",
    "                cc_loc = 'HKG'\n",
    "            else:\n",
    "                cc_loc = loc_to_country[location]\n",
    "        else:\n",
    "            cc_loc = location\n",
    "        if cc_loc not in cc_loc_to_count_new:\n",
    "            cc_loc_to_count_new[cc_loc] = 0\n",
    "\n",
    "        cc_loc_to_count_new[cc_loc] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import rcParams\n",
    "import operator\n",
    "rcParams['font.size'] = 10\n",
    "rcParams[\"font.family\"] = \"CMU Sans Serif\"\n",
    "chosen_country_code = 'GU'\n",
    "old_count = __builtins__.sum(cc_loc_to_count_old.values())\n",
    "new_count = __builtins__.sum(cc_loc_to_count_new.values())\n",
    "\n",
    "old_percent_dict = {k: round((v/old_count) * 100) for k, v in cc_loc_to_count_old.items() if round((v/old_count) * 100) >=2}\n",
    "new_percent_dict = {k: round((v/new_count) * 100) for k, v in cc_loc_to_count_new.items() if round((v/new_count) * 100) >=2}\n",
    "\n",
    "sorted_old_percent_dict = sorted(old_percent_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_new_percent_dict = sorted(new_percent_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "cols = plt.get_cmap(\"tab10\").colors\n",
    "color_map = {\n",
    "    \"PH\": cols[0],\n",
    "    \"TW\": cols[1],\n",
    "    \"HKG\": cols[2],\n",
    "    \"SG\": cols[3],\n",
    "    \"N/A\": cols[4],\n",
    "    \"DE\": cols[5],\n",
    "    \"US\": cols[6],\n",
    "    \"CA\": cols[7],\n",
    "    \"IL\": cols[8],\n",
    "    \"GB\": cols[9]\n",
    "}\n",
    "\n",
    "space = 0.8\n",
    "x_A = np.arange(len(old_percent_dict))\n",
    "x_B = np.arange(len(new_percent_dict)) + len(old_percent_dict) + space\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots(figsize=(3.37, 3.37))\n",
    "\n",
    "print(old_percent_dict)\n",
    "print(new_percent_dict)\n",
    "\n",
    "old_countries = []\n",
    "new_countries = []\n",
    "for i, (country, percent) in enumerate(sorted_old_percent_dict):\n",
    "    old_countries.append(country)\n",
    "    ax.bar(x_A[i],percent, width,color=color_map.get(country,\"gray\"), alpha=0.7, label=country)\n",
    "\n",
    "for i, (country, percent) in enumerate(sorted_new_percent_dict):\n",
    "    new_countries.append(country)\n",
    "    ax.bar(x_B[i],percent, width,color=color_map.get(country,\"gray\"), alpha=0.7, label=country)\n",
    "\n",
    "\n",
    "all_labels = old_countries + new_countries\n",
    "x_ticks = np.concatenate([x_A, x_B])\n",
    "ax.set_yticks([0,10,20,30,40,50,60,70,80,90])\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_xticklabels(all_labels, rotation=0, ha=\"center\", fontsize=10)\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "ax.text(-0.35,-15,\"JP PoP\")\n",
    "ax.text(4.0,-15,\"PH PoP\")\n",
    "plt.grid(True, axis='y', linestyle='-', alpha=0.7, linewidth=0.5)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/{chosen_country_code}_Probes_resolved_ip_loc_before_vs_after_PoP_change.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/{chosen_country_code}_Probes_resolved_ip_loc_before_vs_after_PoP_change.svg\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloudflare AIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudflare_glob = f\"../dataset/late-2025/cloudflare-AIM/starlink-bq-results-20251006-190426-1759777511222.json\"\n",
    "\n",
    "starlink_cdn_latency_countrycode = {}\n",
    "starlink_cdn_latency_countryname = {}\n",
    "\n",
    "starlink_cdn_loadedlatency_download_countryname = {}\n",
    "starlink_cdn_loadedlatency_upload_countryname = {}\n",
    "\n",
    "starlink_cdn_loadedlatency_download_city_to_cdn = {}\n",
    "starlink_cdn_loadedlatency_upload_city_to_cdn = {}\n",
    "\n",
    "starlink_country_to_city_map = {}\n",
    "starlink_user_to_cdnloc_map ={}\n",
    "starlink_user_to_cdnloc_minRTT_map ={}\n",
    "\n",
    "code_country_json = json.load(open(f\"../helper/code_to_country_name.json\",\"r\"))\n",
    "\n",
    "with jsonlines.open(cloudflare_glob) as reader:\n",
    "    for obj in reader:\n",
    "        country = obj['clientCountry']\n",
    "        city_name = obj['clientCity']\n",
    "        server_loc = obj['serverPoP']\n",
    "        \n",
    "        if len(obj['latencyMs']) == 20:\n",
    "            if country not in starlink_cdn_latency_countrycode:\n",
    "                starlink_cdn_latency_countrycode[country] = []\n",
    "            starlink_cdn_latency_countrycode[country] += obj['latencyMs']\n",
    "\n",
    "            if country in code_country_json:\n",
    "                country_name = code_country_json[country]\n",
    "                if country_name not in starlink_cdn_latency_countryname:\n",
    "                    starlink_cdn_latency_countryname[country_name] = []\n",
    "                    starlink_cdn_loadedlatency_download_countryname[country_name] = []\n",
    "                    starlink_cdn_loadedlatency_upload_countryname[country_name] = []\n",
    "                starlink_cdn_latency_countryname[country_name] += obj['latencyMs']\n",
    "\n",
    "                if city_name not in starlink_cdn_loadedlatency_download_city_to_cdn:\n",
    "                    starlink_cdn_loadedlatency_download_city_to_cdn[city_name] = {}\n",
    "                if city_name not in starlink_cdn_loadedlatency_upload_city_to_cdn:\n",
    "                    starlink_cdn_loadedlatency_upload_city_to_cdn[city_name] = {}\n",
    "                \n",
    "                if server_loc not in starlink_cdn_loadedlatency_download_city_to_cdn[city_name]:\n",
    "                    starlink_cdn_loadedlatency_download_city_to_cdn[city_name][server_loc] = []\n",
    "                if server_loc not in starlink_cdn_loadedlatency_upload_city_to_cdn[city_name]:\n",
    "                    starlink_cdn_loadedlatency_upload_city_to_cdn[city_name][server_loc] = []\n",
    "\n",
    "                if 'download' in obj['loadedLatencyMs']:\n",
    "                    if len(obj['loadedLatencyMs']['download']):\n",
    "                        dw_inflationRTT = max(obj['loadedLatencyMs']['download']) - min(obj['loadedLatencyMs']['download'])\n",
    "                        starlink_cdn_loadedlatency_download_countryname[country_name].append(dw_inflationRTT)\n",
    "                        starlink_cdn_loadedlatency_download_city_to_cdn[city_name][server_loc].append(dw_inflationRTT)\n",
    "                if 'upload' in obj['loadedLatencyMs']:\n",
    "                    if len(obj['loadedLatencyMs']['upload']):\n",
    "                        up_inflationRTT = max(obj['loadedLatencyMs']['upload']) - min(obj['loadedLatencyMs']['upload'])\n",
    "                        starlink_cdn_loadedlatency_upload_countryname[country_name].append(up_inflationRTT)\n",
    "                        starlink_cdn_loadedlatency_upload_city_to_cdn[city_name][server_loc].append(up_inflationRTT)\n",
    "\n",
    "\n",
    "                if country_name not in starlink_country_to_city_map:\n",
    "                    starlink_country_to_city_map[country_name] = []\n",
    "                if city_name not in starlink_country_to_city_map[country_name]:\n",
    "                    starlink_country_to_city_map[country_name].append(city_name)\n",
    "\n",
    "                if city_name not in starlink_user_to_cdnloc_map:\n",
    "                    starlink_user_to_cdnloc_map[city_name] = {}\n",
    "                    starlink_user_to_cdnloc_minRTT_map[city_name] = {}\n",
    "                \n",
    "                if server_loc not in starlink_user_to_cdnloc_map[city_name]:\n",
    "                    starlink_user_to_cdnloc_map[city_name][server_loc] = []\n",
    "                    starlink_user_to_cdnloc_minRTT_map[city_name][server_loc] = []\n",
    "                starlink_user_to_cdnloc_map[city_name][server_loc] += obj['latencyMs']\n",
    "                starlink_user_to_cdnloc_minRTT_map[city_name][server_loc].append(min(obj['latencyMs']))\n",
    "\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudflare_glob_terrestrial_file = f\"../dataset/late-2025/cloudflare-AIM/terrestrial-bq-results-20251006-194420-1759779889924.json\"\n",
    "\n",
    "terrestrial_cdn_latency_countrycode = {}\n",
    "terrestrial_cdn_latency_countryname = {}\n",
    "\n",
    "\n",
    "terrestrial_cdn_loadedlatency_download_countryname = {}\n",
    "terrestrial_cdn_loadedlatency_upload_countryname = {}\n",
    "\n",
    "terrestrial_cdn_loadedlatency_download_city_to_cdn = {}\n",
    "terrestrial_cdn_loadedlatency_upload_city_to_cdn = {}\n",
    "\n",
    "terrestrial_country_to_city_map ={}\n",
    "terrestrial_user_to_cdnloc_map ={}\n",
    "terrestrial_user_to_cdnloc_minRTT_map ={}\n",
    "\n",
    "code_country_json = json.load(open(f\"../helper/code_to_country_name.json\",\"r\"))\n",
    "idx = 0\n",
    "\n",
    "with jsonlines.open(cloudflare_glob_terrestrial_file) as reader:\n",
    "    for obj in reader:\n",
    "        idx += 1\n",
    "        country = obj['clientCountry']\n",
    "        city_name = obj['clientCity']\n",
    "        server_loc = obj['serverPoP']\n",
    "\n",
    "        if len(obj['latencyMs']) == 20:\n",
    "            if country not in terrestrial_cdn_latency_countrycode:\n",
    "                terrestrial_cdn_latency_countrycode[country] = []\n",
    "            terrestrial_cdn_latency_countrycode[country] += obj['latencyMs']\n",
    "\n",
    "            if country in code_country_json:\n",
    "                country_name = code_country_json[country]\n",
    "                if country_name not in terrestrial_cdn_latency_countryname:\n",
    "                    terrestrial_cdn_latency_countryname[country_name] = []\n",
    "                    terrestrial_cdn_loadedlatency_download_countryname[country_name] = []\n",
    "                    terrestrial_cdn_loadedlatency_upload_countryname[country_name] = []\n",
    "                terrestrial_cdn_latency_countryname[country_name] += obj['latencyMs']\n",
    "\n",
    "                if city_name not in terrestrial_cdn_loadedlatency_download_city_to_cdn:\n",
    "                        terrestrial_cdn_loadedlatency_download_city_to_cdn[city_name] = {}\n",
    "                if city_name not in terrestrial_cdn_loadedlatency_upload_city_to_cdn:\n",
    "                    terrestrial_cdn_loadedlatency_upload_city_to_cdn[city_name] = {}\n",
    "                \n",
    "                if server_loc not in terrestrial_cdn_loadedlatency_download_city_to_cdn[city_name]:\n",
    "                    terrestrial_cdn_loadedlatency_download_city_to_cdn[city_name][server_loc] = []\n",
    "                if server_loc not in terrestrial_cdn_loadedlatency_upload_city_to_cdn[city_name]:\n",
    "                    terrestrial_cdn_loadedlatency_upload_city_to_cdn[city_name][server_loc] = []\n",
    "\n",
    "                if 'download' in obj['loadedLatencyMs']:\n",
    "                    if len(obj['loadedLatencyMs']['download']):\n",
    "                        dw_inflationRTT = max(obj['loadedLatencyMs']['download']) - min(obj['loadedLatencyMs']['download'])\n",
    "                        terrestrial_cdn_loadedlatency_download_countryname[country_name].append(dw_inflationRTT)\n",
    "                        terrestrial_cdn_loadedlatency_download_city_to_cdn[city_name][server_loc].append(dw_inflationRTT)\n",
    "                if 'upload' in obj['loadedLatencyMs']:\n",
    "                    if len(obj['loadedLatencyMs']['upload']):\n",
    "                        up_inflationRTT = max(obj['loadedLatencyMs']['upload']) - min(obj['loadedLatencyMs']['upload'])\n",
    "                        terrestrial_cdn_loadedlatency_upload_countryname[country_name].append(up_inflationRTT)\n",
    "                        terrestrial_cdn_loadedlatency_upload_city_to_cdn[city_name][server_loc].append(up_inflationRTT)\n",
    "\n",
    "                if country_name not in terrestrial_country_to_city_map:\n",
    "                    terrestrial_country_to_city_map[country_name] = []\n",
    "                if city_name not in terrestrial_country_to_city_map[country_name]:\n",
    "                    terrestrial_country_to_city_map[country_name].append(city_name)\n",
    "\n",
    "                if city_name not in terrestrial_user_to_cdnloc_map:\n",
    "                    terrestrial_user_to_cdnloc_map[city_name] = {}\n",
    "                    terrestrial_user_to_cdnloc_minRTT_map[city_name] = {}\n",
    "                \n",
    "                if server_loc not in terrestrial_user_to_cdnloc_map[city_name]:\n",
    "                    terrestrial_user_to_cdnloc_map[city_name][server_loc] = []\n",
    "                    terrestrial_user_to_cdnloc_minRTT_map[city_name][server_loc] = []\n",
    "                terrestrial_user_to_cdnloc_map[city_name][server_loc] += obj['latencyMs']\n",
    "                terrestrial_user_to_cdnloc_minRTT_map[city_name][server_loc].append(min(obj['latencyMs']))\n",
    "            else:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrestrial_user_to_bestcdn_map = {}\n",
    "terrestrial_user_to_bestcdn_minRTT_map = {}\n",
    "\n",
    "for user_city, cdn_latency_dict in terrestrial_user_to_cdnloc_map.items():\n",
    "    temp_dict = {}\n",
    "    for cdn_loc, latency_list in cdn_latency_dict.items():\n",
    "        if len(latency_list) >= 100:\n",
    "            temp_dict[cdn_loc] = statistics.median(latency_list)\n",
    "    if temp_dict :\n",
    "        key_of_min = min(temp_dict, key=temp_dict.get)\n",
    "        terrestrial_user_to_bestcdn_map[user_city] = {\n",
    "            key_of_min : cdn_latency_dict[key_of_min]\n",
    "        }\n",
    "\n",
    "        terrestrial_user_to_bestcdn_minRTT_map[user_city] = {\n",
    "            key_of_min: terrestrial_user_to_cdnloc_minRTT_map[user_city][key_of_min]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starlink_user_to_bestcdn_map = {}\n",
    "starlink_user_to_bestcdn_minRTT_map = {}\n",
    "\n",
    "for user_city, cdn_latency_dict in starlink_user_to_cdnloc_map.items():\n",
    "    temp_dict = {}\n",
    "    for cdn_loc, latency_list in cdn_latency_dict.items():\n",
    "        if len(latency_list) >= 100:\n",
    "            temp_dict[cdn_loc] = statistics.median(latency_list)\n",
    "    if temp_dict :\n",
    "        key_of_min = min(temp_dict, key=temp_dict.get)\n",
    "        starlink_user_to_bestcdn_map[user_city] = {\n",
    "            key_of_min : cdn_latency_dict[key_of_min]\n",
    "        }\n",
    "\n",
    "        starlink_user_to_bestcdn_minRTT_map[user_city] = {\n",
    "            key_of_min: starlink_user_to_cdnloc_minRTT_map[user_city][key_of_min]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrestrial_cdn_latency_countryname_best_cdn_medianrtts = {}\n",
    "\n",
    "for country, city_list in terrestrial_country_to_city_map.items():\n",
    "    if country not in terrestrial_cdn_latency_countryname_best_cdn_medianrtts:\n",
    "        terrestrial_cdn_latency_countryname_best_cdn_medianrtts[country] = []\n",
    "    for city in city_list:\n",
    "        if city in terrestrial_user_to_bestcdn_map:\n",
    "            for cdn, rtts in terrestrial_user_to_bestcdn_map[city].items():\n",
    "                terrestrial_cdn_latency_countryname_best_cdn_medianrtts[country] += rtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starlink_cdn_latency_countryname_best_cdn_medianrtts = {}\n",
    "\n",
    "for country, city_list in starlink_country_to_city_map.items():\n",
    "    if country not in starlink_cdn_latency_countryname_best_cdn_medianrtts:\n",
    "        starlink_cdn_latency_countryname_best_cdn_medianrtts[country] = []\n",
    "    for city in city_list:\n",
    "        if city in starlink_user_to_bestcdn_map:\n",
    "            for cdn, rtts in starlink_user_to_bestcdn_map[city].items():\n",
    "                starlink_cdn_latency_countryname_best_cdn_medianrtts[country] += rtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = plt.get_cmap(\"tab10\").colors\n",
    "rcParams['font.size'] = 10\n",
    "rcParams[\"font.family\"] = \"CMU Sans Serif\"\n",
    "popmarkerfacecolor = cols[2]\n",
    "\n",
    "def plot_gsdata(gsdata_df, ax, label, marker, color, size=10, lw=0.6):\n",
    "    latitude, longitude = gsdata_df[\"latitude\"], gsdata_df[\"longitude\"]\n",
    "    ax.scatter(longitude, latitude,\n",
    "               sizes = [size],\n",
    "               color=color,\n",
    "               zorder = 10,\n",
    "               marker=marker,\n",
    "               edgecolor=\"black\",\n",
    "               linewidth = lw,\n",
    "               label=label)\n",
    "\n",
    "pop_df = pd.read_csv(f'../dataset/pop_locations_Oct2025.csv') #pop_2023-10-10\n",
    "pop_coords = geopandas.GeoDataFrame(pop_df, geometry=geopandas.points_from_xy(pop_df.longitude, pop_df.latitude))\n",
    "\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))\n",
    "world = world[(world.name!=\"Antarctica\")]\n",
    "\n",
    "countries_plotted = set()\n",
    "median_rtt_difference = []\n",
    "all_values_list = []\n",
    "for name, code in zip(world[\"name\"], world[\"iso_a3\"]):    \n",
    "    if name in terrestrial_cdn_latency_countryname_best_cdn_medianrtts and name in starlink_cdn_latency_countryname_best_cdn_medianrtts:\n",
    "        if len(terrestrial_cdn_latency_countryname_best_cdn_medianrtts[name]) > 25 and len(starlink_cdn_latency_countryname_best_cdn_medianrtts[name]) > 25:\n",
    "            rtt_diff = statistics.median(starlink_cdn_latency_countryname_best_cdn_medianrtts[name]) - statistics.median(terrestrial_cdn_latency_countryname_best_cdn_medianrtts[name])\n",
    "            print(f\"Country: {name}, RTT delta: {rtt_diff}\")\n",
    "            median_rtt_difference.append(rtt_diff)\n",
    "            countries_plotted.add(name)\n",
    "            all_values_list.append(rtt_diff)\n",
    "        else:\n",
    "            median_rtt_difference.append(float(\"NaN\"))\n",
    "    elif code == \"-99\":\n",
    "        median_rtt_difference.append(float(\"NaN\"))\n",
    "    else:\n",
    "        median_rtt_difference.append(float(\"nan\"))\n",
    "\n",
    "\n",
    "\n",
    "world[\"rtt_diff\"] = median_rtt_difference\n",
    "fig, ax = plt.subplots(figsize=(4.66, 2), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "total_bins = [-100,-80,-50,-20,0,20,50,80,100]\n",
    "handles = []\n",
    "pop_handles = [Line2D([0], [0], marker=\"o\", color=\"w\", markeredgecolor=\"black\", markerfacecolor=popmarkerfacecolor, markeredgewidth=0.8)\n",
    "           for i in range(1)]\n",
    "labels = [\"PoP\"]\n",
    "handles = pop_handles\n",
    "ax.coastlines(linewidth=0.5)\n",
    "cmap = 'seismic'\n",
    "\n",
    "world.plot(column=\"rtt_diff\", cmap=cmap, scheme='UserDefined', classification_kwds=dict(bins=total_bins),\n",
    "           ax=ax,alpha=0.8,)\n",
    "\n",
    "plot_gsdata(pop_df, ax, \"PoP\", \"o\", popmarkerfacecolor, size=10, lw=0.3)\n",
    "ax.set_extent([-180, 180, -60, 90], ccrs.PlateCarree())\n",
    "ax.get_xaxis().set_ticks([])\n",
    "ax.get_yaxis().set_ticks([])\n",
    "\n",
    "ax.legend(handles, labels,handlelength=1, labelspacing=0.06, columnspacing=0.5, handletextpad=0.3,\n",
    "          loc=\"lower left\", fancybox=False, edgecolor=\"k\", fontsize=\"small\")\n",
    " \n",
    "# Create colorbar as a legend\n",
    "sm = plt.cm.ScalarMappable(norm=pltColors.Normalize(vmin=-100, vmax=100), cmap=cmap)\n",
    "# Empty array for the data range\n",
    "sm._A = []\n",
    "# Add the colorbar to the figure\n",
    "cbaxes = fig.add_axes([0.015, 0.10, 0.02, 0.8])\n",
    "cbar = fig.colorbar(sm, cax=cbaxes)\n",
    "cbar.set_label(\"Median RTT Difference (ms)\", labelpad = -50)\n",
    "cbar.locator = ticker.MaxNLocator(nbins=6)\n",
    "custom_ticks = [-100, -75 ,-50, -25, 0, 25, 50, 75, 100]\n",
    "cbar.set_ticks(custom_ticks)\n",
    "\n",
    "carrowupaxes = fig.add_axes([-0.070, 0.075, 0.02, 0.4])\n",
    "carrowupaxes.arrow(0, 0, 0, -0.00005, length_includes_head=True,\n",
    "          head_width=0.04, head_length=0.0000075, ec=\"black\", fc=\"black\")\n",
    "carrowupaxes.set_axis_off()\n",
    "\n",
    "carrowdownaxes = fig.add_axes([-0.070, 0.495, 0.02, 0.4])\n",
    "carrowdownaxes.arrow(0, 0, 0, 0.00005, length_includes_head=True,\n",
    "          head_width=0.04, head_length=0.0000075, ec=\"black\", fc=\"black\")\n",
    "carrowdownaxes.set_axis_off()\n",
    "plt.figtext(x=-0.095,y=0.120,s=\"Starlink faster\", rotation='vertical', fontsize=8)\n",
    "plt.figtext(x=-0.095,y=0.520,s=\"Terrestrial faster\", rotation='vertical', fontsize=8)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/terrestrial_vs_starlink_rtt_difference_global_heatmap_bestCDN_Cloudflare_AIM.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/terrestrial_vs_starlink_rtt_difference_global_heatmap_bestCDN_Cloudflare_AIM.svg\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iata_to_city_dict = {}\n",
    "city_to_iata_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cloudflare traceroute data to infer PoP locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"cloudflare\"\n",
    "\n",
    "acc_result_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "print(filepath)\n",
    "\n",
    "cf_accumulated_trace_json_old = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    cf_accumulated_trace_json_old = json.load(json_file)\n",
    "    print(\"Accumulated Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes_cf_path_old = {}\n",
    "all_public_ips = []\n",
    "ip_to_country_dict = {}\n",
    "\n",
    "\n",
    "class Hop:\n",
    "    def __init__(self,ip,type,min_rtt,asn,hostname,country,location):\n",
    "        self.ip = ip\n",
    "        self.type = type\n",
    "        self.min_rtt = min_rtt\n",
    "        self.asn = asn\n",
    "        self.hostname = hostname\n",
    "        self.country = country\n",
    "        self.location = location\n",
    "        self.children = []\n",
    "\n",
    "    def add_children(self,child_node):\n",
    "        self.children.append(child_node)\n",
    "    \n",
    "    def has_children(self):\n",
    "        return len(self.children) > 0\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "\n",
    "\n",
    "for idx, each_msm in enumerate(cf_accumulated_trace_json_old,start=0):\n",
    "        print(f\"Index: {idx} out of {len(cf_accumulated_trace_json_old)}\")\n",
    "\n",
    "        pop_ip_set = set(each_msm['pop_hop_ip'])\n",
    "        cdn_ip_set = set(each_msm['all_hops'][-1]['hop_ips'])\n",
    "\n",
    "        if len(pop_ip_set) == 0:\n",
    "            continue\n",
    "        \n",
    "        if len(pop_ip_set) != 1:\n",
    "            print(f\"More than 2 PoP IPs in the same hop. Probe id: {prb_id}, domain: {each_msm['domain']}\")\n",
    "            pop_ip_set = {list(pop_ip_set)[0],}\n",
    "            print(f\"Continuing with PoP IP: {list(pop_ip_set)[0]}\")\n",
    "\n",
    "\n",
    "        ## Create new probe in probes if not done already\n",
    "        prb_id = each_msm['prb_id']\n",
    "        if prb_id not in probes_cf_path_old:\n",
    "            probes_cf_path_old[prb_id] = {\n",
    "                'id' : prb_id,\n",
    "                'country_code' : each_msm['country_code'],\n",
    "                'paths': {},\n",
    "            }\n",
    "\n",
    "        ## Create first hop for the probe as starting with the pop node if not done already\n",
    "        pop_ip = next(iter(pop_ip_set))\n",
    "        pop_asn = 14593\n",
    "        domain = each_msm['domain']\n",
    "        if domain not in probes_cf_path_old[prb_id]['paths']:\n",
    "            probes_cf_path_old[prb_id]['paths'][domain] = {}\n",
    "        if pop_ip not in probes_cf_path_old[prb_id]['paths'][domain]:\n",
    "                country = None\n",
    "                if pop_ip in ip_to_country_dict:\n",
    "                    country = ip_to_country_dict[pop_ip]\n",
    "                else:\n",
    "                    geo_details = find_ip(pop_ip,ip_to_country_df)\n",
    "                    if geo_details is not None:\n",
    "                        if 'country_code' in geo_details:\n",
    "                            country = geo_details['country_code']\n",
    "                            ip_to_country_dict[pop_ip] = country\n",
    "                    else:\n",
    "                        ip_to_country_dict[pop_ip] = None\n",
    "                probes_cf_path_old[prb_id]['paths'][domain][pop_ip] = Hop(\n",
    "                    ip=pop_ip,\n",
    "                    type='PoP',\n",
    "                    min_rtt=min(each_msm['pop_rtts']),\n",
    "                    asn=pop_asn,\n",
    "                    hostname=None,\n",
    "                    country=country,\n",
    "                    location=None,\n",
    "                )\n",
    "        else:\n",
    "            this_min_rtt = min(each_msm['pop_rtts'])\n",
    "            prev_min_rtt = probes_cf_path_old[prb_id]['paths'][domain][pop_ip].min_rtt\n",
    "            if this_min_rtt < prev_min_rtt:\n",
    "                probes_cf_path_old[prb_id]['paths'][domain][pop_ip].min_rtt = this_min_rtt\n",
    "\n",
    "        pop_reached = False\n",
    "        hopNode = probes_cf_path_old[prb_id]['paths'][domain][pop_ip]\n",
    "        \n",
    "        ## Go through all the hops\n",
    "        for idx, each_hop in enumerate(each_msm['all_hops']):\n",
    "            hop_ip_set = set(each_hop['hop_ips'])\n",
    "            hop_id = each_hop['hop_id']\n",
    "            min_hop_rtt = min(each_hop['hop_rtts'])\n",
    "\n",
    "            if pop_ip_set.intersection(hop_ip_set):\n",
    "                pop_reached = True\n",
    "                continue\n",
    "\n",
    "            \n",
    "            \n",
    "            if pop_reached:\n",
    "                if len(hop_ip_set) != 1:\n",
    "                    print(f\"More than 2 destinations in the same hop. Probe id: {prb_id}, domain: {each_msm['domain']}, hop id: {hop_id}\")\n",
    "                    \n",
    "                    print(\"Check if the hop ips are part of the same network address\")\n",
    "                    hop_ip_network_count = {}\n",
    "                    hop_ip_network_min_rtt = {}\n",
    "                    for uni_idx, unique_hop_ip in enumerate(each_hop['hop_ips']):\n",
    "                        unique_hop_ip_obj = ipaddress.ip_interface(unique_hop_ip + '/24')\n",
    "                        unique_hop_network = str(unique_hop_ip_obj.network.network_address)\n",
    "                      \n",
    "                        if unique_hop_network not in hop_ip_network_count:\n",
    "                            hop_ip_network_count[unique_hop_network] = 1\n",
    "                            hop_ip_network_min_rtt[unique_hop_network] = each_hop['hop_rtts'][uni_idx]\n",
    "                        else:\n",
    "                            continue\n",
    "                        for each_idx, each_ip in enumerate(each_hop['hop_ips']):\n",
    "                            if each_idx == uni_idx:\n",
    "                                continue\n",
    "                            each_ip_obj = ipaddress.ip_interface(each_ip + '/24')\n",
    "                            each_ip_network = str(each_ip_obj.network.network_address)\n",
    "                            if each_ip_network == unique_hop_network:\n",
    "                                hop_ip_network_count[unique_hop_network] += 1\n",
    "                                if each_hop['hop_rtts'][each_idx] <  hop_ip_network_min_rtt[unique_hop_network]:\n",
    "                                    hop_ip_network_min_rtt[unique_hop_network] = each_hop['hop_rtts'][each_idx]\n",
    "                    \n",
    "                    max_count = max(hop_ip_network_count.values())\n",
    "                    if max_count < 2:\n",
    "                        print(\"Could not find a majority network address. Skipping measurement.\")\n",
    "                        break\n",
    "                    max_key = max(hop_ip_network_count, key=hop_ip_network_count.get)\n",
    "                    hop_ip_set = {max_key,}\n",
    "                    min_hop_rtt = hop_ip_network_min_rtt[max_key]\n",
    "\n",
    "\n",
    "                need_new_child_node = True\n",
    "                hop_ip = next(iter(hop_ip_set))\n",
    "\n",
    "                if not ipaddress.ip_address(hop_ip).is_private:\n",
    "                    all_public_ips.append(hop_ip)\n",
    "\n",
    "                hopChildNode = None\n",
    "                if hopNode.has_children():\n",
    "                    hopChildNodes = hopNode.get_children()\n",
    "                    for node in hopChildNodes:\n",
    "                        \n",
    "                        if node.ip == hop_ip:\n",
    "                            hopChildNode = node\n",
    "                            need_new_child_node = False\n",
    "                \n",
    "                if need_new_child_node:\n",
    "                    hop_type = 'Node'\n",
    "                    if hop_ip in cdn_ip_set:\n",
    "                        hop_type = 'CDN'\n",
    "                    asn_info, _ = asndb.lookup(hop_ip)\n",
    "                    country = None\n",
    "                    if hop_ip in ip_to_country_dict:\n",
    "                        country = ip_to_country_dict[hop_ip]\n",
    "                    else:\n",
    "                        geo_details = find_ip(hop_ip,ip_to_country_df)\n",
    "                        if geo_details is not None:\n",
    "                            if 'country_code' in geo_details:\n",
    "                                country = geo_details['country_code']\n",
    "                                ip_to_country_dict[hop_ip] = country\n",
    "                        else:\n",
    "                            ip_to_country_dict[hop_ip] = None\n",
    "\n",
    "                    newChildNode = Hop(\n",
    "                        ip=hop_ip,\n",
    "                        type=hop_type,\n",
    "                        min_rtt=min_hop_rtt,\n",
    "                        asn=asn_info,\n",
    "                        hostname=None,\n",
    "                        country=country,\n",
    "                        location=None,\n",
    "                    )\n",
    "                    hopNode.add_children(newChildNode)\n",
    "                    hopChildNode = newChildNode\n",
    "                else:\n",
    "                    this_min_rtt = min_hop_rtt\n",
    "                    prev_min_rtt = hopChildNode.min_rtt\n",
    "                    if this_min_rtt < prev_min_rtt:\n",
    "                        hopChildNode.min_rtt = this_min_rtt\n",
    "                hopNode = hopChildNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "\n",
    "cdn_country_wise_cdn_rtts_stl = {}\n",
    "cdn_country_wise_pop_rtts_stl = {}\n",
    "\n",
    "cdn_prb_wise_pop_rtts_stl = {}\n",
    "cdn_prb_wise_cdn_rtts_stl = {}\n",
    "\n",
    "cf_country_wise_cdn_rtts_stl = {}\n",
    "cf_country_wise_pop_rtts_stl = {}\n",
    "\n",
    "akamai_country_wise_cdn_rtts_stl = {}\n",
    "akamai_country_wise_pop_rtts_stl = {}\n",
    "\n",
    "cloudfront_country_wise_cdn_rtts_stl = {}\n",
    "cloudfront_country_wise_pop_rtts_stl = {}\n",
    "\n",
    "\n",
    "server = \"cloudflare\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "acc_tracert_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "acc_tracert_filepath = os.path.join(full_msms_path,'acc_result',acc_tracert_filename)\n",
    "with open(acc_tracert_filepath, \"r\") as json_file:\n",
    "    acc_tracert_json = json.load(json_file)\n",
    "print(f\"Adding measurements from {acc_tracert_filepath}\")\n",
    "\n",
    "cf_msms_len = len(acc_tracert_json)\n",
    "print(f\"Total cloudflare measurements= {cf_msms_len}\")\n",
    "\n",
    "for each_msm in acc_tracert_json:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    pop_rtts = each_msm['pop_rtts']\n",
    "    cdn_rtts = each_msm['total_rtts']\n",
    "\n",
    "    if prb_id not in cdn_prb_wise_cdn_rtts_stl:\n",
    "        cdn_prb_wise_cdn_rtts_stl[prb_id] = []\n",
    "        cdn_prb_wise_pop_rtts_stl[prb_id] = []\n",
    "\n",
    "    if country_code not in cdn_country_wise_cdn_rtts_stl:\n",
    "        cdn_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        cdn_country_wise_pop_rtts_stl[country_code] = []\n",
    "\n",
    "    if country_code not in cf_country_wise_cdn_rtts_stl:\n",
    "        cf_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        cf_country_wise_pop_rtts_stl[country_code] = []\n",
    "    \n",
    "    if len(cdn_rtts) and len(pop_rtts):\n",
    "        if statistics.mean(cdn_rtts) > statistics.mean(pop_rtts):\n",
    "            min_cdn_rtt = min(cdn_rtts)\n",
    "            min_pop_rtt = min(pop_rtts)\n",
    "            if min_cdn_rtt > 15 and min_pop_rtt > 15: # removing outliers and false positives\n",
    "                cf_country_wise_cdn_rtts_stl[country_code].append(min_cdn_rtt)\n",
    "                cf_country_wise_pop_rtts_stl[country_code].append(min_pop_rtt)\n",
    "                cdn_country_wise_cdn_rtts_stl[country_code].append(min_cdn_rtt)\n",
    "                cdn_country_wise_pop_rtts_stl[country_code].append(min_pop_rtt)\n",
    "                cdn_prb_wise_cdn_rtts_stl[prb_id].append(min_cdn_rtt)\n",
    "                cdn_prb_wise_pop_rtts_stl[prb_id].append(min_pop_rtt)\n",
    "\n",
    "\n",
    "server = \"akamai\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "acc_tracert_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "acc_tracert_filepath = os.path.join(full_msms_path,'acc_result',acc_tracert_filename)\n",
    "with open(acc_tracert_filepath, \"r\") as json_file:\n",
    "    acc_tracert_json = json.load(json_file)\n",
    "print(f\"Adding measurements from {acc_tracert_filepath}\")\n",
    "\n",
    "akamai_msms_len = len(acc_tracert_json)\n",
    "print(f\"Total cloudflare measurements= {akamai_msms_len}\")\n",
    "\n",
    "for each_msm in acc_tracert_json:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    pop_rtts = each_msm['pop_rtts']\n",
    "    cdn_rtts = each_msm['total_rtts']\n",
    "\n",
    "    if prb_id not in cdn_prb_wise_cdn_rtts_stl:\n",
    "        cdn_prb_wise_cdn_rtts_stl[prb_id] = []\n",
    "        cdn_prb_wise_pop_rtts_stl[prb_id] = []\n",
    "\n",
    "    if country_code not in cdn_country_wise_cdn_rtts_stl:\n",
    "        cdn_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        cdn_country_wise_pop_rtts_stl[country_code] = []\n",
    "\n",
    "    if country_code not in akamai_country_wise_cdn_rtts_stl:\n",
    "        akamai_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        akamai_country_wise_pop_rtts_stl[country_code] = []\n",
    "    \n",
    "    if len(cdn_rtts) and len(pop_rtts):\n",
    "        if statistics.mean(cdn_rtts) > statistics.mean(pop_rtts):\n",
    "            min_cdn_rtt = min(cdn_rtts)\n",
    "            min_pop_rtt = min(pop_rtts)\n",
    "            if min_cdn_rtt > 15 and min_pop_rtt > 15: # removing outliers and false positives\n",
    "                akamai_country_wise_cdn_rtts_stl[country_code].append(min_cdn_rtt)\n",
    "                akamai_country_wise_pop_rtts_stl[country_code].append(min_pop_rtt)\n",
    "                cdn_country_wise_cdn_rtts_stl[country_code].append(min_cdn_rtt)\n",
    "                cdn_country_wise_pop_rtts_stl[country_code].append(min_pop_rtt)\n",
    "                cdn_prb_wise_cdn_rtts_stl[prb_id].append(min_cdn_rtt)\n",
    "                cdn_prb_wise_pop_rtts_stl[prb_id].append(min_pop_rtt)\n",
    "\n",
    "server = \"cloudfront\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "acc_tracert_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "acc_tracert_filepath = os.path.join(full_msms_path,'acc_result',acc_tracert_filename)\n",
    "with open(acc_tracert_filepath, \"r\") as json_file:\n",
    "    acc_tracert_json = json.load(json_file)\n",
    "print(f\"Adding measurements from {acc_tracert_filepath}\")\n",
    "\n",
    "cloudfront_msms_len = len(acc_tracert_json)\n",
    "print(f\"Total cloudront measurements= {cloudfront_msms_len}\")\n",
    "\n",
    "for each_msm in acc_tracert_json:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    pop_rtts = each_msm['pop_rtts']\n",
    "    cdn_rtts = each_msm['total_rtts']\n",
    "\n",
    "    if prb_id not in cdn_prb_wise_cdn_rtts_stl:\n",
    "        cdn_prb_wise_cdn_rtts_stl[prb_id] = []\n",
    "        cdn_prb_wise_pop_rtts_stl[prb_id] = []\n",
    "        \n",
    "    if country_code not in cdn_country_wise_cdn_rtts_stl:\n",
    "        cdn_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        cdn_country_wise_pop_rtts_stl[country_code] = []\n",
    "\n",
    "    if country_code not in cloudfront_country_wise_cdn_rtts_stl:\n",
    "        cloudfront_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        cloudfront_country_wise_pop_rtts_stl[country_code] = []\n",
    "    \n",
    "    if len(cdn_rtts) and len(pop_rtts):\n",
    "        if statistics.mean(cdn_rtts) > statistics.mean(pop_rtts):\n",
    "            min_cdn_rtt = min(cdn_rtts)\n",
    "            min_pop_rtt = min(pop_rtts)\n",
    "            if min_cdn_rtt > 15 and min_pop_rtt > 15: # removing outliers and false positives\n",
    "                cloudfront_country_wise_cdn_rtts_stl[country_code].append(min_cdn_rtt)\n",
    "                cloudfront_country_wise_pop_rtts_stl[country_code].append(min_pop_rtt)\n",
    "                cdn_country_wise_cdn_rtts_stl[country_code].append(min_cdn_rtt)\n",
    "                cdn_country_wise_pop_rtts_stl[country_code].append(min_pop_rtt)\n",
    "                cdn_prb_wise_cdn_rtts_stl[prb_id].append(min_cdn_rtt)\n",
    "                cdn_prb_wise_pop_rtts_stl[prb_id].append(min_pop_rtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"Starlink\"\n",
    "dns_server = \"google\"\n",
    "msm_type = \"dns\"\n",
    "\n",
    "acc_result_google_CHAOS_filepath_stl = os.path.join(old_top_level_folder_path,network_type,msm_type,dns_server,\"CHAOS\",\"acc_result\",f\"acc_dns_{dns_server}_CHAOS_final_result.json\")\n",
    "with open(acc_result_google_CHAOS_filepath_stl,\"r\") as file:\n",
    "    try:\n",
    "        google_CHAOS_data_stl = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_google_CHAOS_filepath_stl, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_dns_prb_resolver_location_rtt = {}\n",
    "for prb_tuple_str, result_dict in google_CHAOS_data_stl.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    \n",
    "    if prb_id not in google_dns_prb_resolver_location_rtt:\n",
    "        google_dns_prb_resolver_location_rtt[prb_id] = {\n",
    "            'country_code': country_code,\n",
    "            'dns_resolver': {}\n",
    "        }\n",
    "    \n",
    "    for idx, response_time in enumerate(result_dict['response_time']):\n",
    "        \n",
    "        if response_time > 15:\n",
    "            \n",
    "            dns_loc = result_dict['resolver_location'][idx]\n",
    "            dns_iata = None\n",
    "            if dns_loc.startswith('gpdns'):\n",
    "                dns_iata_tuple = dns_loc.split('-')\n",
    "                dns_iata = dns_iata_tuple[1]\n",
    "            else:\n",
    "                print(f\"Probe: {prb_id}, Country: {country_code}, Resolver Location: {dns_loc} \")\n",
    "            if dns_iata is not None:\n",
    "                if dns_iata == 'mil':\n",
    "                    dns_iata = 'mxp'\n",
    "                if dns_iata.upper() not in google_dns_prb_resolver_location_rtt[prb_id]['dns_resolver']:\n",
    "                    google_dns_prb_resolver_location_rtt[prb_id]['dns_resolver'][dns_iata.upper()] = []\n",
    "                google_dns_prb_resolver_location_rtt[prb_id]['dns_resolver'][dns_iata.upper()].append(response_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import airportsdata\n",
    "\n",
    "def get_city_from_iata_airportsdata(iata_code):\n",
    "\n",
    "  if iata_code == 'MIL':\n",
    "    return 'Milan'\n",
    "\n",
    "  airports = airportsdata.load('IATA')\n",
    "  if iata_code in airports:\n",
    "    city = airports[iata_code]['city']\n",
    "    if city == 'Newark':\n",
    "      return 'New York'\n",
    "    return airports[iata_code]['city']\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_to_loc_map_filename = \"../helper/pop_to_location.json\"\n",
    "pop_to_loc = {}\n",
    "with open(pop_to_loc_map_filename,'r') as pop_loc_map_file:\n",
    "    pop_to_loc = json.load(pop_loc_map_file)\n",
    "\n",
    "def get_PoP_Location(prb_id):\n",
    "    loc_set = set()\n",
    "    pop_not_known_set = set()\n",
    "    if prb_id in probes_cf_path_old:\n",
    "        probe_details  = probes_cf_path_old[prb_id]\n",
    "        if 'www.broadcom.com' in probe_details['paths']:\n",
    "            pop_ip_set = list(probe_details['paths']['www.broadcom.com'].keys())\n",
    "            for pop_ip in pop_ip_set:\n",
    "                if pop_ip in pop_to_loc:\n",
    "                        loc_set.add(pop_to_loc[pop_ip])\n",
    "                else:\n",
    "                    pop_not_known_set.add(pop_ip)\n",
    "            return loc_set, pop_not_known_set\n",
    "    else:\n",
    "         print(f\"{prb_id} not in probes_cf_path_old\")\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_addtnl_distance_to_google_dns_rtts = {}\n",
    "prb_with_unknwn_pop_ips = []\n",
    "for prb_id in google_dns_prb_resolver_location_rtt:\n",
    "    country_code = google_dns_prb_resolver_location_rtt[prb_id]['country_code']\n",
    "    prb_dns_dict = google_dns_prb_resolver_location_rtt[prb_id]['dns_resolver']\n",
    "    pop_loc, pop_not_known = get_PoP_Location(int(prb_id))\n",
    "\n",
    "    if pop_loc:\n",
    "        pop_list = list(pop_loc)\n",
    "        pop_dns_median_rt = None\n",
    "        if len(pop_list) == 1 and len(pop_not_known) == 0:\n",
    "            dns_loc_far_set = set()\n",
    "            for dns_iata in prb_dns_dict:\n",
    "\n",
    "                dns_loc = None\n",
    "                if dns_iata in iata_to_city_dict:\n",
    "                    dns_loc = iata_to_city_dict[dns_iata]\n",
    "                else:\n",
    "                    dns_loc = get_city_from_iata_airportsdata(dns_iata)\n",
    "\n",
    "                if dns_iata not in iata_to_city_dict:\n",
    "                    iata_to_city_dict[dns_iata] = dns_loc\n",
    "                if dns_loc not in city_to_iata_dict:\n",
    "                    city_to_iata_dict[dns_loc] = dns_iata\n",
    "\n",
    "                if dns_loc in pop_list[0] or pop_list[0] in dns_loc:\n",
    "                    dns_rt = prb_dns_dict[dns_iata]\n",
    "                    pop_median_dns_rt = statistics.median(dns_rt)\n",
    "                else:\n",
    "                    dns_loc_far_set.add(dns_loc)\n",
    "            \n",
    "            if int(prb_id) in cdn_prb_wise_pop_rtts_stl:\n",
    "                pop_median_minRTT = statistics.median(cdn_prb_wise_pop_rtts_stl[int(prb_id)])\n",
    "            else:\n",
    "                pop_median_minRTT = 0\n",
    "\n",
    "            if pop_median_minRTT:\n",
    "                for other_dns_loc in dns_loc_far_set:\n",
    "                    if pop_list[0] not in pop_addtnl_distance_to_google_dns_rtts:\n",
    "                        pop_addtnl_distance_to_google_dns_rtts[pop_list[0]] = {}\n",
    "                    if other_dns_loc not in pop_addtnl_distance_to_google_dns_rtts[pop_list[0]]:\n",
    "                        pop_addtnl_distance_to_google_dns_rtts[pop_list[0]][other_dns_loc] = []\n",
    "                    pop_addtnl_distance_to_google_dns_rtts[pop_list[0]][other_dns_loc] = [rt - pop_median_minRTT for rt in google_dns_prb_resolver_location_rtt[prb_id]['dns_resolver'][city_to_iata_dict[other_dns_loc]] if rt > pop_median_minRTT]\n",
    "                  \n",
    "                if len(dns_loc_far_set) > 0:\n",
    "                    print(f\"Probe: {prb_id}, Country: {country_code}, DNS: {dns_loc_far_set}, PoP Loc: {pop_loc}\")\n",
    "    else:\n",
    "        prb_with_unknwn_pop_ips.append(prb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"Starlink\"\n",
    "dns_server = \"cloudflare\"\n",
    "msm_type = \"dns\"\n",
    "\n",
    "acc_result_cf_CHAOS_filepath_stl = os.path.join(old_top_level_folder_path,network_type,msm_type,dns_server,\"CHAOS\",\"acc_result\",f\"acc_dns_{dns_server}_CHAOS_final_result.json\")\n",
    "with open(acc_result_cf_CHAOS_filepath_stl,\"r\") as file:\n",
    "    try:\n",
    "        cf_CHAOS_data_stl = json.load(file)\n",
    "        print(f\"JSON Data loaded with {dns_server} DNS accumulated results!\")\n",
    "    except ValueError as err:\n",
    "        print(\"Skipping invalid json:, \", acc_result_cf_CHAOS_filepath_stl, \"Error: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_dns_prb_resolver_location_rtt = {}\n",
    "for prb_tuple_str, result_dict in cf_CHAOS_data_stl.items():\n",
    "    prb_tuple = ast.literal_eval(prb_tuple_str)\n",
    "    prb_id = prb_tuple[0]\n",
    "    country_code = prb_tuple[1]\n",
    "    \n",
    "    if prb_id not in cf_dns_prb_resolver_location_rtt:\n",
    "        cf_dns_prb_resolver_location_rtt[prb_id] = {\n",
    "            'country_code': country_code,\n",
    "            'dns_resolver': {}\n",
    "        }\n",
    "    \n",
    "    for idx, response_time in enumerate(result_dict['response_time']):\n",
    "        if response_time > 15:\n",
    "            dns_loc = result_dict['resolver_location'][idx]\n",
    "            if dns_loc not in cf_dns_prb_resolver_location_rtt[prb_id]['dns_resolver']:\n",
    "                cf_dns_prb_resolver_location_rtt[prb_id]['dns_resolver'][dns_loc] = []\n",
    "            cf_dns_prb_resolver_location_rtt[prb_id]['dns_resolver'][dns_loc].append(response_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_addtnl_distance_to_cf_dns_rtts = {}\n",
    "for prb_id in cf_dns_prb_resolver_location_rtt:\n",
    "    country_code = cf_dns_prb_resolver_location_rtt[prb_id]['country_code']\n",
    "    prb_dns_dict = cf_dns_prb_resolver_location_rtt[prb_id]['dns_resolver']\n",
    "    pop_loc, pop_not_known = get_PoP_Location(int(prb_id))\n",
    "    if pop_loc:\n",
    "        pop_list = list(pop_loc)\n",
    "        pop_median_dns_rt = None\n",
    "        if len(pop_list) == 1 and len(pop_not_known) == 0:\n",
    "            dns_loc_far_set = set()\n",
    "            for dns_iata in prb_dns_dict:\n",
    "                \n",
    "                dns_loc = get_city_from_iata_airportsdata(dns_iata)\n",
    "                if dns_iata not in iata_to_city_dict:\n",
    "                    iata_to_city_dict[dns_iata] = dns_loc\n",
    "                if dns_loc not in city_to_iata_dict:\n",
    "                    city_to_iata_dict[dns_loc] = dns_iata\n",
    "                if dns_loc in pop_list[0] or pop_list[0] in dns_loc:\n",
    "                    dns_rt = prb_dns_dict[dns_iata]\n",
    "                    pop_median_dns_rt = statistics.median(dns_rt)\n",
    "                else:\n",
    "                    dns_loc_far_set.add(dns_loc)\n",
    "            \n",
    "\n",
    "\n",
    "            if pop_median_dns_rt:\n",
    "                for other_dns_loc in dns_loc_far_set:\n",
    "                    if pop_list[0] not in pop_addtnl_distance_to_cf_dns_rtts:\n",
    "                        pop_addtnl_distance_to_cf_dns_rtts[pop_list[0]] = {}\n",
    "                    if other_dns_loc not in pop_addtnl_distance_to_cf_dns_rtts[pop_list[0]]:\n",
    "                        pop_addtnl_distance_to_cf_dns_rtts[pop_list[0]][other_dns_loc] = []\n",
    "                    pop_addtnl_distance_to_cf_dns_rtts[pop_list[0]][other_dns_loc] = [rt - pop_median_dns_rt for rt in cf_dns_prb_resolver_location_rtt[prb_id]['dns_resolver'][city_to_iata_dict[other_dns_loc]] if rt > pop_median_dns_rt]\n",
    "                  \n",
    "                if len(dns_loc_far_set) > 0:\n",
    "                    print(f\"Probe: {prb_id}, Country: {country_code}, DNS: {dns_loc_far_set}, PoP Loc: {pop_loc}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "cols = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.66, 2))\n",
    "pop_locs = ['Miami', 'Chicago', 'Milan', 'Jakarta', 'Lagos', 'Madrid']\n",
    "\n",
    "idx = 0\n",
    "for popLoc in pop_locs:\n",
    "    addnlDnsRTList = []\n",
    "    dns_resolver_loc = []\n",
    "    if popLoc in pop_addtnl_distance_to_google_dns_rtts:\n",
    "        for dnsLoc, dnsRTList in pop_addtnl_distance_to_google_dns_rtts[popLoc].items():\n",
    "            \n",
    "            if len(dnsRTList) > 50:\n",
    "                addnlDnsRTList += dnsRTList\n",
    "                dns_resolver_loc.append(dnsLoc)\n",
    "                print(f\"{dnsLoc}: {len(dnsRTList)}\")\n",
    "    if popLoc in pop_addtnl_distance_to_cf_dns_rtts:\n",
    "        for dnsLoc, dnsRTList in pop_addtnl_distance_to_cf_dns_rtts[popLoc].items():\n",
    "\n",
    "            if len(dnsRTList) > 50:\n",
    "                addnlDnsRTList += dnsRTList\n",
    "                dns_resolver_loc.append(dnsLoc)\n",
    "                print(f\"{dnsLoc}: {len(dnsRTList)}\")\n",
    "\n",
    "\n",
    "    if len(addnlDnsRTList) > 50:\n",
    "        print(f\"PoP Loc: {popLoc}, DNS Locs: {dns_resolver_loc}\")\n",
    "    \n",
    "        xs = np.sort(addnlDnsRTList)\n",
    "        ys = np.arange(1, len(xs) + 1) / len(xs)\n",
    "        indices = []\n",
    "        current = xs[0]\n",
    "        for i, x in enumerate(xs): # only take max y value at each x value to smoothen out the graph\n",
    "            if x != current:\n",
    "                current = x\n",
    "                indices.append(i - 1)\n",
    "        indices.append(len(ys) - 1)\n",
    "        xs = sorted(set(xs))\n",
    "        ys = [ys[i] for i in indices]\n",
    "        ax.plot(xs, ys, label=popLoc, color=cols[idx], linestyle=\"solid\")\n",
    "        idx += 1\n",
    "\n",
    "ax.set_xlabel(\"Additional DNS Response Time [ms]\")\n",
    "ax.set_ylabel(\"Percentile\")\n",
    "ax.set_yticks(np.arange(0, 1.20, 0.25))\n",
    "\n",
    "ax.xaxis.get_major_formatter()._usetex = False\n",
    "ax.yaxis.get_major_formatter()._usetex = False\n",
    "ax.set_xlim(0,110)\n",
    "ax.set_ylim(0,1)\n",
    "ax.legend(loc=\"lower right\", fontsize=\"small\", ncol=2, edgecolor=\"k\", handlelength=1, labelspacing=0.06,\n",
    "          columnspacing=0.5, handletextpad=0.3, fancybox=False)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Akamai - Africa - Starlink vs Terrestrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Starlink\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"akamai\"\n",
    "\n",
    "acc_result_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "print(filepath)\n",
    "\n",
    "akamai_accumulated_trace_json_old = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    akamai_accumulated_trace_json_old = json.load(json_file)\n",
    "    print(\"Accumulated Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "controlled_nodes_traceroute_files_path = f\"{controlled_top_level_folder_path}/traceroute/08-27-2025-12-31-18_WebTrace_files_list\"\n",
    "\n",
    "cdns_list = [\"akamai\"]\n",
    "\n",
    "for cdn_name in cdns_list:\n",
    "    acc_tracert_filename = f\"controlled_nodes_acc_trace_{cdn_name}_final_result_late.json\"\n",
    "    acc_tracert_filepath = os.path.join(controlled_nodes_traceroute_files_path,'acc_result',acc_tracert_filename)\n",
    "    with open(acc_tracert_filepath, \"r\") as json_file:\n",
    "        acc_tracert_json = json.load(json_file)\n",
    "        akamai_accumulated_trace_json_old += acc_tracert_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type = \"Terrestrial\"\n",
    "msm_type = \"traceroute\"\n",
    "server = \"akamai\"\n",
    "\n",
    "acc_result_filename = f\"acc_trace_{server}_final_result.json\"\n",
    "full_msms_path = os.path.join(old_top_level_folder_path,user_type,msm_type,server)\n",
    "filepath = os.path.join(full_msms_path,'acc_result',acc_result_filename)\n",
    "print(filepath)\n",
    "\n",
    "akamai_accumulated_trace_json_old_TERR = None\n",
    "with open(filepath, \"r\") as json_file:\n",
    "    akamai_accumulated_trace_json_old_TERR = json.load(json_file)\n",
    "    print(\"Accumulated Traceroute JSON file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akamai_AF_country_wise_cdn_rtts_stl = {}\n",
    "akamai_AF_country_wise_pop_rtts_stl = {}\n",
    "\n",
    "idx = 0\n",
    "for each_msm in akamai_accumulated_trace_json_old:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    dst_addr = each_msm['dst_addr']\n",
    "\n",
    "    if country_code not in ['BJ','MG','ZM']:\n",
    "        continue\n",
    "    \n",
    "    total_dst_rtts = []\n",
    "    for idx, hop_ip in enumerate(each_msm['all_hops'][-1]['hop_ips']):\n",
    "        if hop_ip == dst_addr:\n",
    "            total_dst_rtts.append(each_msm['all_hops'][-1]['hop_rtts'][idx])\n",
    "    \n",
    "    if country_code not in akamai_AF_country_wise_cdn_rtts_stl:\n",
    "        akamai_AF_country_wise_cdn_rtts_stl[country_code] = []\n",
    "        akamai_AF_country_wise_pop_rtts_stl[country_code] = []\n",
    "\n",
    "    if len(total_dst_rtts):\n",
    "        akamai_AF_country_wise_cdn_rtts_stl[country_code].append(min(total_dst_rtts))\n",
    "    \n",
    "    if len(total_dst_rtts) and len(each_msm['pop_rtts']):\n",
    "        if statistics.mean(total_dst_rtts) > statistics.mean(each_msm['pop_rtts']):\n",
    "            akamai_AF_country_wise_pop_rtts_stl[country_code].append(min(each_msm['pop_rtts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akamai_AF_country_wise_cdn_rtts_stl_TERR = {}\n",
    "akamai_AF_country_wise_pop_rtts_stl_TERR = {}\n",
    "\n",
    "idx = 0\n",
    "for each_msm in akamai_accumulated_trace_json_old_TERR:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    dst_addr = each_msm['dst_addr']\n",
    "\n",
    "    if country_code not in ['BJ','MG','ZM']:\n",
    "        continue\n",
    "    \n",
    "    total_dst_rtts = []\n",
    "    for idx, hop_ip in enumerate(each_msm['all_hops'][-1]['hop_ips']):\n",
    "        if hop_ip == dst_addr:\n",
    "            total_dst_rtts.append(each_msm['all_hops'][-1]['hop_rtts'][idx])\n",
    "    \n",
    "    if country_code not in akamai_AF_country_wise_cdn_rtts_stl_TERR:\n",
    "        akamai_AF_country_wise_cdn_rtts_stl_TERR[country_code] = []\n",
    "        akamai_AF_country_wise_pop_rtts_stl_TERR[country_code] = []\n",
    "\n",
    "    if len(total_dst_rtts):\n",
    "        akamai_AF_country_wise_cdn_rtts_stl_TERR[country_code].append(min(total_dst_rtts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rcParams['font.size'] = 10\n",
    "\n",
    "\n",
    "country_colors = {\n",
    "    \"BJ\" : cols[3],\n",
    "    \"MG\" : cols[4],\n",
    "    \"ZM\" : cols[2],\n",
    "}\n",
    "\n",
    "african_countries = [\"MG\", \"ZM\", \"BJ\"]\n",
    "fig, ax = plt.subplots(figsize=(4.66, 2))\n",
    "\n",
    "\n",
    "handles = []\n",
    "labels = []\n",
    "for country in african_countries:\n",
    "    country_rt_TERR_list = []\n",
    "    country_rt_TERR_list += akamai_AF_country_wise_cdn_rtts_stl_TERR[country]\n",
    "    if country_rt_TERR_list:\n",
    "\n",
    "        xs = np.sort(country_rt_TERR_list)\n",
    "        ys = np.arange(1, len(xs) + 1) / len(xs)\n",
    "        indices = []\n",
    "        current = xs[0]\n",
    "        for i, x in enumerate(xs): # only take max y value at each x value to smoothen out the graph\n",
    "            if x != current:\n",
    "                current = x\n",
    "                indices.append(i - 1)\n",
    "        indices.append(len(ys) - 1)\n",
    "        xs = sorted(set(xs))\n",
    "        ys = [ys[i] for i in indices]\n",
    "        ax.plot(xs, ys, label=f\"{country}-STL\", color=country_colors[country], linestyle=\"dotted\")\n",
    "\n",
    "    country_rt_STL_list = []\n",
    "    country_rt_STL_list += akamai_AF_country_wise_cdn_rtts_stl[country]\n",
    "    if country_rt_STL_list:\n",
    "\n",
    "        xs = np.sort(country_rt_STL_list)\n",
    "        ys = np.arange(1, len(xs) + 1) / len(xs)\n",
    "        indices = []\n",
    "        current = xs[0]\n",
    "        for i, x in enumerate(xs): # only take max y value at each x value to smoothen out the graph\n",
    "            if x != current:\n",
    "                current = x\n",
    "                indices.append(i - 1)\n",
    "        indices.append(len(ys) - 1)\n",
    "        xs = sorted(set(xs))\n",
    "        ys = [ys[i] for i in indices]\n",
    "        ax.plot(xs, ys, label=f\"{country}-STL\", color=country_colors[country], linestyle=\"solid\")\n",
    "\n",
    "\n",
    "    handles.append(Patch(facecolor=country_colors[country]))\n",
    "    labels.append(country)\n",
    "\n",
    "ax.set_xlabel(\"CDN RTT [ms]\")\n",
    "ax.set_ylabel(\"Percentile\")\n",
    "ax.set_yticks(np.arange(0, 1.20, 0.25))\n",
    "ax.set_xticks(np.arange(0, 600, 50))\n",
    "ax.xaxis.get_major_formatter()._usetex = False\n",
    "ax.yaxis.get_major_formatter()._usetex = False\n",
    "\n",
    "\n",
    "solid_line = Line2D([0], [0], color='black', linestyle='-', label='Starlink')\n",
    "dashed_line = Line2D([0], [0], color='black', linestyle=':', label='Terrestrial')\n",
    "\n",
    "net_handles = [solid_line, dashed_line]\n",
    "net_labels = ['Starlink', 'Terrestrial']\n",
    "\n",
    "country_legend  = ax.legend(handles, labels, loc=\"lower right\",  fontsize=\"small\", edgecolor=\"k\",  handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4)\n",
    "ax.add_artist(country_legend)\n",
    "ax.legend(net_handles, net_labels,loc=\"lower right\", bbox_to_anchor=(0.65, 0.94), fontsize=\"x-small\", edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3,frameon=False, fancybox=False, ncol=4) # bbox_to_anchor=(0.25, 0.91), \n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "\n",
    "ax.set_xlim(0,350)\n",
    "ax.set_ylim(0,1.0)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/cf_cdn_africa_STAR_vs_TERR_cdf.pdf\", bbox_inches = \"tight\", pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_to_country_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_country_to_cdn_dest_stl = {\n",
    "    'BJ' : {},\n",
    "    'MG' : {}\n",
    "}\n",
    "\n",
    "idx_outer = 0\n",
    "for each_msm in akamai_accumulated_trace_json_old:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    dst_addr = each_msm['dst_addr']\n",
    "    idx_outer += 1\n",
    "    print(f\"{idx_outer+1} of {len(akamai_accumulated_trace_json_old)}\")\n",
    "    if country_code not in ['BJ','MG']:\n",
    "        continue\n",
    "    \n",
    "    for idx, hop_ip in enumerate(each_msm['all_hops'][-1]['hop_ips']):\n",
    "        if hop_ip == dst_addr:\n",
    "            if dst_addr in ip_to_country_dict:\n",
    "                cdn_country = ip_to_country_dict[dst_addr]\n",
    "            else:\n",
    "                ip_details = find_ip(dst_addr,ip_to_country_df)\n",
    "                if 'country_code' in ip_details:\n",
    "                    cdn_country = ip_details['country_code']\n",
    "                else:\n",
    "                    cdn_country = 'None'\n",
    "                ip_to_country_dict[dst_addr] = cdn_country\n",
    "\n",
    "            if cdn_country not in AF_country_to_cdn_dest_stl[country_code]:\n",
    "                AF_country_to_cdn_dest_stl[country_code][cdn_country] = 0\n",
    "            AF_country_to_cdn_dest_stl[country_code][cdn_country] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_country_to_cdn_dest_TERR = {\n",
    "    'BJ' : {},\n",
    "    'MG' : {}\n",
    "}\n",
    "\n",
    "idx_outer = 0\n",
    "for each_msm in akamai_accumulated_trace_json_old_TERR:\n",
    "    country_code = each_msm['country_code']\n",
    "    prb_id = each_msm['prb_id']\n",
    "    dst_addr = each_msm['dst_addr']\n",
    "    idx_outer += 1\n",
    "    print(f\"{idx_outer+1} of {len(akamai_accumulated_trace_json_old_TERR)}\")\n",
    "    if country_code not in ['BJ','MG']:\n",
    "        continue\n",
    "    \n",
    "    for idx, hop_ip in enumerate(each_msm['all_hops'][-1]['hop_ips']):\n",
    "        if hop_ip == dst_addr:\n",
    "            if dst_addr in ip_to_country_dict:\n",
    "                cdn_country = ip_to_country_dict[dst_addr]\n",
    "            else:\n",
    "                ip_details = find_ip(dst_addr,ip_to_country_df)\n",
    "                if 'country_code' in ip_details:\n",
    "                    cdn_country = ip_details['country_code']\n",
    "                else:\n",
    "                    cdn_country = 'None'\n",
    "                ip_to_country_dict[dst_addr] = cdn_country\n",
    "\n",
    "            if cdn_country not in AF_country_to_cdn_dest_TERR[country_code]:\n",
    "                AF_country_to_cdn_dest_TERR[country_code][cdn_country] = 0\n",
    "            AF_country_to_cdn_dest_TERR[country_code][cdn_country] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['font.size'] = 12\n",
    "chosen_country_code = 'MG'\n",
    "starlink_count = __builtins__.sum(AF_country_to_cdn_dest_stl[chosen_country_code].values())\n",
    "terrestrial_count = __builtins__.sum(AF_country_to_cdn_dest_TERR[chosen_country_code].values())\n",
    "\n",
    "starlink_percent_dict = {k: round((v/starlink_count) * 100) for k, v in AF_country_to_cdn_dest_stl[chosen_country_code].items() if round((v/starlink_count) * 100) >=1}\n",
    "terrestrial_percent_dict = {k: round((v/terrestrial_count) * 100) for k, v in AF_country_to_cdn_dest_TERR[chosen_country_code].items() if round((v/terrestrial_count) * 100) >=4}\n",
    "\n",
    "sorted_starlink_percent_dict = sorted(starlink_percent_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_terrestrial_percent_dict = sorted(terrestrial_percent_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "\n",
    "color_map = {\n",
    "    \"FR\": cols[0],\n",
    "    \"PL\": cols[1],\n",
    "    \"ZA\": cols[2],\n",
    "    \"ES\": cols[3],\n",
    "    \"IT\": cols[4],\n",
    "    \"DE\": cols[5],\n",
    "    \"US\": cols[6],\n",
    "    \"NL\": cols[7],\n",
    "    \"TR\": cols[8],\n",
    "    \"GB\": cols[9]\n",
    "}\n",
    "\n",
    "\n",
    "space = 0.8\n",
    "x_A = np.arange(len(starlink_percent_dict))\n",
    "x_B = np.arange(len(terrestrial_percent_dict)) + len(starlink_percent_dict) + space\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots(figsize=(3.37, 3.37))\n",
    "\n",
    "print(starlink_percent_dict)\n",
    "print(terrestrial_percent_dict)\n",
    "\n",
    "stl_countries = []\n",
    "terr_countries = []\n",
    "for i, (country, percent) in enumerate(sorted_starlink_percent_dict):\n",
    "    stl_countries.append(country)\n",
    "    ax.bar(x_A[i],percent, width,color=color_map.get(country,\"gray\"), alpha=0.7, label=country)\n",
    "\n",
    "for i, (country, percent) in enumerate(sorted_terrestrial_percent_dict):\n",
    "    terr_countries.append(country)\n",
    "    ax.bar(x_B[i],percent, width,color=color_map.get(country,\"gray\"), alpha=0.7, label=country)\n",
    "\n",
    "\n",
    "all_labels = stl_countries + terr_countries\n",
    "x_ticks = np.concatenate([x_A, x_B])\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_xticklabels(all_labels, rotation=0, ha=\"center\", fontsize=10)\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "ax.text(-0.5,-15,\"Starlink\")\n",
    "ax.text(4.1,-15,\"Terrestrial\")\n",
    "plt.grid(True, axis='y', linestyle='-', alpha=0.7, linewidth=0.5)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/{chosen_country_code}_resolved_ip_loc_akamai_domains.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['font.size'] = 12\n",
    "chosen_country_code = 'BJ'\n",
    "starlink_count = __builtins__.sum(AF_country_to_cdn_dest_stl[chosen_country_code].values())\n",
    "terrestrial_count = __builtins__.sum(AF_country_to_cdn_dest_TERR[chosen_country_code].values())\n",
    "\n",
    "starlink_percent_dict = {k: round((v/starlink_count) * 100) for k, v in AF_country_to_cdn_dest_stl[chosen_country_code].items() if round((v/starlink_count) * 100) >=1}\n",
    "terrestrial_percent_dict = {k: round((v/terrestrial_count) * 100) for k, v in AF_country_to_cdn_dest_TERR[chosen_country_code].items() if round((v/terrestrial_count) * 100) >=4}\n",
    "\n",
    "sorted_starlink_percent_dict = sorted(starlink_percent_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_terrestrial_percent_dict = sorted(terrestrial_percent_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "\n",
    "color_map = {\n",
    "    \"FR\": cols[0],\n",
    "    \"PL\": cols[1],\n",
    "    \"ZA\": cols[2],\n",
    "    \"ES\": cols[3],\n",
    "    \"IT\": cols[4],\n",
    "    \"DE\": cols[5],\n",
    "    \"US\": cols[6],\n",
    "    \"NL\": cols[7],\n",
    "    \"TR\": cols[8],\n",
    "    \"GB\": cols[9]\n",
    "}\n",
    "\n",
    "\n",
    "space = 0.8\n",
    "x_A = np.arange(len(starlink_percent_dict))\n",
    "x_B = np.arange(len(terrestrial_percent_dict)) + len(starlink_percent_dict) + space\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots(figsize=(3.37, 3.37))\n",
    "\n",
    "print(starlink_percent_dict)\n",
    "print(terrestrial_percent_dict)\n",
    "\n",
    "stl_countries = []\n",
    "terr_countries = []\n",
    "for i, (country, percent) in enumerate(sorted_starlink_percent_dict):\n",
    "    stl_countries.append(country)\n",
    "    ax.bar(x_A[i],percent, width,color=color_map.get(country,\"gray\"), alpha=0.7, label=country)\n",
    "\n",
    "for i, (country, percent) in enumerate(sorted_terrestrial_percent_dict):\n",
    "    terr_countries.append(country)\n",
    "    ax.bar(x_B[i],percent, width,color=color_map.get(country,\"gray\"), alpha=0.7, label=country)\n",
    "\n",
    "\n",
    "all_labels = stl_countries + terr_countries\n",
    "x_ticks = np.concatenate([x_A, x_B])\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_xticklabels(all_labels, rotation=0, ha=\"center\", fontsize=10)\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "ax.text(-0.5,-15,\"Starlink\")\n",
    "ax.text(2.4,-15,\"Terrestrial\")\n",
    "plt.grid(True, axis='y', linestyle='-', alpha=0.7, linewidth=0.5)\n",
    "plt.savefig(f\"{figs_top_level_folder_path}/{chosen_country_code}_resolved_ip_loc_akamai_domains.pdf\", bbox_inches = \"tight\", pad_inches = 0.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloudflare AIM Africa analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_raw_jsonfile = \"africa-raw-bq-results-20260121-224019-1769035354623.ndjson\"\n",
    "dataset_af_raw = os.path.join(cloudflare_aim_path, \"all_starlink_africa.ndjson\")\n",
    "raw_af_df = pd.DataFrame()\n",
    "# one shard\n",
    "raw_af_df = pd.read_json(\n",
    "    dataset_af_raw,   # or full/path/*.json.gz\n",
    "    lines=True                            # NDJSON  one JSON object per line\n",
    ")\n",
    "\n",
    "#   verify\n",
    "print(len(raw_af_df))          # rowcount\n",
    "raw_af_df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_pops = {'LOS', 'CPT', 'NBO', 'JNB', 'CPT', 'MRS', 'JIB', 'DUR'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_af_df['year_month'] = pd.to_datetime(raw_af_df['measurementTime']).dt.to_period('M')\n",
    "\n",
    "# 3. Compute each tests mean latency\n",
    "raw_af_df['test_latency_median'] = raw_af_df['latencyMs'].apply(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some cleanup tasks\n",
    "\n",
    "## only keep if download.bps and upload.bps are non-empty lists\n",
    "mask_complete = (\n",
    "    raw_af_df['download']\n",
    "      .apply(lambda d: bool(d.get('bps')))  & \n",
    "    raw_af_df['upload']\n",
    "      .apply(lambda u: bool(u.get('bps')))\n",
    ")\n",
    "raw_af_df = raw_af_df[mask_complete]\n",
    "\n",
    "## only keep data where test_latency_median is greater than 10\n",
    "raw_af_df = raw_af_df[raw_af_df['test_latency_median'] > 10.0]\n",
    "\n",
    "raw_af_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute the minimum test_latency_mean per (country, month, PoP)\n",
    "filtered = raw_af_df.groupby(\n",
    "    ['clientCountry', 'year_month', 'serverPoP']\n",
    ").filter(lambda grp: len(grp) >= 5)\n",
    "\n",
    "pop_min = (\n",
    "    filtered\n",
    "    .groupby(['clientCountry','year_month','serverPoP'])['test_latency_median']\n",
    "    .min()\n",
    "    .reset_index(name='pop_min_latency')\n",
    ")\n",
    "\n",
    "pop_median = (\n",
    "    filtered\n",
    "    .groupby(['clientCountry','year_month','serverPoP'])['test_latency_median']\n",
    "    .median()\n",
    "    .reset_index(name='pop_median_latency')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## print the number of unique serverPoP\n",
    "print(pop_min['serverPoP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pop_min)\n",
    "print(pop_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Restrict to PoPs *outside* Africa\n",
    "pop_min_non = pop_min[~pop_min['serverPoP'].isin(african_pops)]\n",
    "\n",
    "# 5. Pick the best (lowestlatency) nonAfrican PoP per countrymonth\n",
    "idx_non = (\n",
    "    pop_min_non\n",
    "    .groupby(['clientCountry','year_month'])['pop_min_latency']\n",
    "    .idxmin()\n",
    ")\n",
    "\n",
    "best_nonaf = (\n",
    "    pop_min_non\n",
    "    .loc[idx_non, ['clientCountry','year_month','serverPoP','pop_min_latency']]\n",
    "    .rename(columns={'serverPoP':'best_nonafrican_pop',\n",
    "                     'pop_min_latency':'best_nonafrican_latency'})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 6. Preview that mapping\n",
    "print(best_nonaf.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Select the PoP with the absolute lowest latency per (country, month)\n",
    "idx = pop_min.groupby(['clientCountry','year_month'])['pop_min_latency'].idxmin()\n",
    "best_pops = (\n",
    "    pop_min\n",
    "    .loc[idx, ['clientCountry','year_month','serverPoP','pop_min_latency']]\n",
    "    .rename(columns={'serverPoP':'best_pop'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pop_median.groupby(['clientCountry','year_month'])['pop_median_latency'].idxmin()\n",
    "best_pops_median = (\n",
    "    pop_median\n",
    "    .loc[idx, ['clientCountry','year_month','serverPoP','pop_median_latency']]\n",
    "    .rename(columns={'serverPoP':'best_pop_median'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible nice countries to analyze:\n",
    "1. KE (latency reduces from 140 to 90)\n",
    "2. MZ (goes to 40 over time)\n",
    "3. ZM (quite significant decrease)\n",
    "4. ZW (quite significant decrease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create loaded latency values for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_af_df['loaded_latency_down'] = raw_af_df['loadedLatencyMs'].apply(\n",
    "    lambda d: np.median(d.get('download', [])) \n",
    "              if isinstance(d, dict) and d.get('download') else np.nan\n",
    ")\n",
    "\n",
    "raw_af_df['loaded_latency_up'] = raw_af_df['loadedLatencyMs'].apply(\n",
    "    lambda d: np.median(d.get('upload', [])) \n",
    "              if isinstance(d, dict) and d.get('upload') else np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter only for African Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep all rows where serverPoP is in your AfricanPoP set\n",
    "mask_af = raw_af_df['serverPoP'].isin(african_pops)\n",
    "\n",
    "# 2. Keep all rows matching the best non-African PoP mapping\n",
    "mask_nonaf = raw_af_df.merge(\n",
    "    best_nonaf,\n",
    "    how='left',\n",
    "    left_on=['clientCountry','year_month','serverPoP'],\n",
    "    right_on=['clientCountry','year_month','best_nonafrican_pop']\n",
    ")['best_nonafrican_pop'].notna()\n",
    "\n",
    "# 3. Combine masks\n",
    "filtered2 = raw_af_df[ mask_af | mask_nonaf ].copy()\n",
    "\n",
    "# 4. Inspect\n",
    "print(f\"Kept {len(filtered2)} rows ({mask_af.sum()} via African PoPs + {mask_nonaf.sum()} via best non-Af PoPs)\")\n",
    "filtered2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter based on best_pop_median location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Merge the best_pop_median mapping onto your raw data\n",
    "merged = raw_af_df.merge(\n",
    "    best_pops_median,   # cols: clientCountry, year_month, best_pop_median\n",
    "    how='left',\n",
    "    left_on=['clientCountry','year_month'],\n",
    "    right_on=['clientCountry','year_month']\n",
    ")\n",
    "\n",
    "# 3) Keep only rows where serverPoP == best_pop_median\n",
    "filtered_by_median = merged[\n",
    "    merged['serverPoP'] == merged['best_pop_median']\n",
    "].copy()\n",
    "\n",
    "# 4) (Optional) Drop the extra columns from the merge if you like\n",
    "filtered_by_median = filtered_by_median.drop(columns=['best_pop_median','pop_median_latency'])\n",
    "\n",
    "# 5) Inspect\n",
    "print(f\"Kept {len(filtered_by_median)} rows out of {len(raw_af_df)}\")\n",
    "filtered_by_median.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Base DataFrame prep\n",
    "df_base = filtered_by_median.copy()\n",
    "\n",
    "# Normalize year_month  Timestamp\n",
    "if pd.api.types.is_period_dtype(df_base['year_month'].dtype):\n",
    "    df_base['year_month'] = df_base['year_month'].dt.to_timestamp()\n",
    "else:\n",
    "    df_base['year_month'] = pd.to_datetime(\n",
    "        df_base['year_month'].astype(str), format='%Y-%m'\n",
    "    )\n",
    "\n",
    "# Restrict to Nov 2024  Apr 2025\n",
    "months = pd.date_range('2024-11-01', '2025-04-01', freq='MS')\n",
    "df_base = df_base[df_base['year_month'].isin(months)]\n",
    "df_base['month_str'] = df_base['year_month'].dt.strftime('%Y-%m')\n",
    "\n",
    "countries = ['KE','MZ','ZM','ZW']\n",
    "colors    = ['C0','C1','C2','C3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from joypy import joyplot\n",
    "\n",
    "# 1. Prepare & filter your DataFrame\n",
    "df = filtered_by_median.copy()\n",
    "\n",
    "# Normalize year_month  Timestamp\n",
    "if pd.api.types.is_period_dtype(df['year_month'].dtype):\n",
    "    df['year_month'] = df['year_month'].dt.to_timestamp()\n",
    "else:\n",
    "    df['year_month'] = pd.to_datetime(df['year_month'].astype(str), format='%Y-%m')\n",
    "\n",
    "# Restrict to Nov 2024  Apr 2025\n",
    "months = pd.date_range('2024-11-01', '2025-04-01', freq='MS')\n",
    "df = df[df['year_month'].isin(months)]\n",
    "\n",
    "# Explode latency lists into individual rows\n",
    "# df = df.explode('loaded_latency_down').dropna(subset=['loaded_latency_down'])\n",
    "# df['latencyMs'] = df['loaded_latency_down'].astype(float)\n",
    "\n",
    "# df = df[df['latencyMs'] >= 20]\n",
    "\n",
    "# 2. Pivot into wide form: one column per country\n",
    "countries = ['KE', 'MZ',  'ZM', 'ZW']\n",
    "for c in countries:\n",
    "    df[c] = df['loaded_latency_down'].where(df['clientCountry'] == c)\n",
    "\n",
    "# Create a stringlabel for the month (so joyplot uses that as the yaxis)\n",
    "df['month_str'] = df['year_month'].dt.strftime('%Y-%m')\n",
    "\n",
    "# 3. Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "# 1) Disable JoyPys per-axis legend\n",
    "fig, axes = joyplot(\n",
    "    data=df[['month_str','KE','MZ','ZM','ZW']],\n",
    "    by='month_str',\n",
    "    column=['KE','ZM','ZW'],\n",
    "    kind='normalized_counts',\n",
    "    overlap=4,\n",
    "    fade=False,\n",
    "    alpha=0.5,\n",
    "    color=['C0','C2','C3'],\n",
    "    x_range=[0,200],\n",
    "    legend=False,      #  turn off its legend\n",
    "    linewidth=1.2,\n",
    "    bw_method=1,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# 2) Build custom legend handles\n",
    "countries = ['KE','ZM','ZW']\n",
    "colors    = ['C0','C2','C3']\n",
    "handles = [Patch(facecolor=col, alpha=1, label=ctr)\n",
    "           for ctr, col in zip(countries, colors)]\n",
    "\n",
    "# 3) Place a single horizontal legend above the plot\n",
    "\n",
    "plt.legend(\n",
    "    handles=handles,\n",
    "    loc='upper left',\n",
    "    ncol=len(handles),\n",
    "    # bbox_to_anchor=(0.5, 1),\n",
    "    labelspacing=0.06, \n",
    "    columnspacing=0.5, \n",
    "    handletextpad=0.3, \n",
    "    fancybox=False,\n",
    "    # columnspacing=0.5,\n",
    "    # handlelength=1,\n",
    "    # handletextpad=0.3\n",
    ")\n",
    "\n",
    "# plt.title('Latency Distributions by Country (Nov 2024  Apr 2025)')\n",
    "plt.xlabel('Downlink latency under load (ms)')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\n",
    "#     os.path.join(PLOT_DIR, \"joyplot_down_loadedlatency_by_af_country_counts.pdf\"),\n",
    "#     dpi=300,\n",
    "#     bbox_inches='tight',\n",
    "#     pad_inches = 0.1\n",
    "# )\n",
    "# plt.savefig(\n",
    "#     os.path.join(PLOT_DIR, \"joyplot_down_loadedlatency_by_af_country_counts.svg\")\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare your DataFrame\n",
    "df = filtered_by_median.copy()\n",
    "if pd.api.types.is_period_dtype(df['year_month'].dtype):\n",
    "    df['year_month'] = df['year_month'].dt.to_timestamp()\n",
    "else:\n",
    "    df['year_month'] = pd.to_datetime(df['year_month'].astype(str), format='%Y-%m')\n",
    "\n",
    "# explode raw latencies\n",
    "df = df.explode('latencyMs').dropna(subset=['latencyMs'])\n",
    "df['latencyMs'] = df['latencyMs'].astype(float)\n",
    "\n",
    "df = df[df['latencyMs'] >= 20]\n",
    "\n",
    "# 2. Define early and late periods by month strings\n",
    "df['ym_str'] = df['year_month'].dt.strftime('%Y-%m')\n",
    "early_months = ['2024-09','2024-10','2024-11']\n",
    "late_months  = ['2025-03','2025-04','2025-05']\n",
    "\n",
    "# 3. Single-axes CDF plot\n",
    "plt.figure(figsize=(10,6))\n",
    "countries = ['BW','MZ','ZM','SZ','MG']\n",
    "colors    = {'BW':'C0','MZ':'C1','ZM':'C2','SZ':'C3', 'MG':'C4'}\n",
    "\n",
    "for country in countries:\n",
    "    # early period (dashed)\n",
    "    data_e = df.loc[\n",
    "        df['clientCountry'].eq(country) & df['ym_str'].isin(early_months),\n",
    "        'latencyMs'\n",
    "    ].values\n",
    "    if data_e.size:\n",
    "        d_e = np.sort(data_e)\n",
    "        cdf_e = np.arange(1, len(d_e)+1) / len(d_e)\n",
    "        plt.plot(d_e, cdf_e,\n",
    "                 linestyle='--',\n",
    "                 color=colors[country],\n",
    "                 label=f'{country} SepNov 2024')\n",
    "\n",
    "    # late period (solid)\n",
    "    data_l = df.loc[\n",
    "        df['clientCountry'].eq(country) & df['ym_str'].isin(late_months),\n",
    "        'latencyMs'\n",
    "    ].values\n",
    "    if data_l.size:\n",
    "        d_l = np.sort(data_l)\n",
    "        cdf_l = np.arange(1, len(d_l)+1) / len(d_l)\n",
    "        plt.plot(d_l, cdf_l,\n",
    "                 linestyle='-',\n",
    "                 color=colors[country],\n",
    "                 label=f'{country} MarMay 2025')\n",
    "\n",
    "# 4. Final formatting\n",
    "plt.xlim(0, 500)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Latency (ms)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Latency CDF: SepNov 2024 (dashed) vs MarMay 2025 (solid)')\n",
    "plt.legend(loc='lower right', fontsize='small', ncol=2)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_months = ['2024-09','2024-10','2024-11']\n",
    "late_months  = ['2025-03','2025-04','2025-05']\n",
    "countries    = ['BW', 'GH','KE','MG','MW','MZ','NG','SS','SZ','ZM','ZW']\n",
    "cols         = ['C0','C1']  # colors for early and late\n",
    "\n",
    "# Gather the latency arrays\n",
    "early_data = [ df.loc[(df['clientCountry']==c) & df['ym_str'].isin(early_months), 'latencyMs'].values\n",
    "               for c in countries ]\n",
    "late_data  = [ df.loc[(df['clientCountry']==c) & df['ym_str'].isin(late_months),  'latencyMs'].values\n",
    "               for c in countries ]\n",
    "\n",
    "# Positions for boxplots\n",
    "pos1 = np.arange(0, 3*len(countries), 3)\n",
    "pos2 = pos1 + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.6,2))\n",
    "\n",
    "# Early\n",
    "ax.boxplot(\n",
    "    early_data, positions=pos1, widths=0.8, patch_artist=True, showfliers=False,\n",
    "    boxprops=dict(facecolor=cols[0], lw=1), medianprops=dict(color='yellow')\n",
    ")\n",
    "# Late\n",
    "ax.boxplot(\n",
    "    late_data, positions=pos2, widths=0.8, patch_artist=True, showfliers=False,\n",
    "    boxprops=dict(facecolor=cols[1], lw=1), medianprops=dict(color='yellow')\n",
    ")\n",
    "\n",
    "# Alternate background shading\n",
    "for i in range(len(countries)):\n",
    "    if i % 2 == 1:\n",
    "        ax.axvspan(pos1[i]-1, pos2[i]+1, facecolor='k', alpha=0.1)\n",
    "\n",
    "\n",
    "ymin, ymax = ax.get_ylim()\n",
    "yticks = np.arange(0, ymax + 1, 50)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels([f\"{int(y)}\" for y in yticks])\n",
    "\n",
    "\n",
    "# X-axis labels\n",
    "ax.set_xticks((pos1 + pos2)/2)\n",
    "ax.set_xticklabels(countries)\n",
    "ax.set_ylabel('Latency (ms)')\n",
    "\n",
    "ax.xaxis.get_major_formatter()._usetex = False\n",
    "ax.yaxis.get_major_formatter()._usetex = False\n",
    "\n",
    "\n",
    "# Legend\n",
    "handles = [Patch(facecolor=cols[i], label=label) \n",
    "           for i, label in enumerate(['SepNov 2024', 'MarMay 2025'])]\n",
    "\n",
    "ax.legend(handles, [h.get_label() for h in handles], loc=\"upper left\", fontsize=\"small\", edgecolor=\"k\", handlelength=1, \n",
    "          labelspacing=0.06, columnspacing=0.5, handletextpad=0.3, fancybox=False, ncol=4)\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\")\n",
    "\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(figs_top_level_folder_path, \"cdf_af_cloudflare_all_countries.pdf\"),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight',\n",
    "    pad_inches = 0.1\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "webMsms_dir = \"../dataset/webMsms\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "rcParams[\"font.family\"] = \"CMU Sans Serif\"\n",
    "rcParams[\"font.size\"] = 10\n",
    "\n",
    "cols = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "country_mapping = {\n",
    "    \"Lusaka-NBO\": \"ZM (NBO PoP)\",\n",
    "    \"Lusaka-JNB\": \"ZM (JNB PoP)\",\n",
    "    \"Accra\": \"GH (LOS PoP)\",\n",
    "    \"Berlin\": \"DE (FRA PoP)\",\n",
    "    \"Vancouver\": \"CA (SEA PoP)\",\n",
    "    \"Calgary\": \"CA (YYC PoP)\",\n",
    "    \"Toronto\": \"CA (YUL PoP)\",\n",
    "}\n",
    "unique_cities = [\"Lusaka\", \"Accra\", \"Berlin\", \"Vancouver\", \"Calgary\", \"Toronto\"]\n",
    "hit_statuses = {\"HIT\", \"REVALIDATED\"}\n",
    "miss_statuses = {\"MISS\", \"DYNAMIC\", \"EXPIRED\", \"BYPASS\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_allinone(filename: str):\n",
    "    data = json.load(open(filename, \"r\"))\n",
    "    timestamps = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "    timestamps = datetime.strptime(timestamps, \"%Y%m%dT%H%M%SZ\").replace(\n",
    "        tzinfo=pytz.UTC\n",
    "    )\n",
    "    user_details = data[\"user_details\"]\n",
    "    city = user_details[\"City\"]\n",
    "    country = user_details[\"Country\"]\n",
    "    cache_result = []\n",
    "    for domain, result in data[\"web_measurements\"].items():\n",
    "        curl_results = result[\"curl\"]\n",
    "        for ip, curl_resp in curl_results.items():\n",
    "            initconnect_time = curl_resp.get(\"initconnect_time\")\n",
    "            appconnect_time = curl_resp.get(\"appconnect_time\")\n",
    "            pretransfer_time = curl_resp.get(\"pretransfer_time\")\n",
    "            redirect_time = curl_resp.get(\"redirect_time\")\n",
    "            starttransfer_time = curl_resp.get(\"starttransfer_time\")\n",
    "            total_time = curl_resp.get(\"total_time\")\n",
    "            cdn_server_id_key = curl_resp.get(\"cdn_server_id_key\")\n",
    "            cdn_server_id_value = curl_resp.get(\"cdn_server_id_value\")\n",
    "            cf_cache_status = curl_resp.get(\"cf_cache_status\")\n",
    "            x_cache = curl_resp.get(\"x_cache\")\n",
    "            x_cache_remote = curl_resp.get(\"x_cache_remote\")\n",
    "\n",
    "            r = {\n",
    "                \"domain\": domain,\n",
    "                \"timestamp\": timestamps,\n",
    "                \"ip\": ip,\n",
    "                \"city\": city,\n",
    "                \"country\": country,\n",
    "                \"initconnect_time\": initconnect_time,\n",
    "                \"appconnect_time\": appconnect_time,\n",
    "                \"pretransfer_time\": pretransfer_time,\n",
    "                \"redirect_time\": redirect_time,\n",
    "                \"starttransfer_time\": starttransfer_time,\n",
    "                \"total_time\": total_time,\n",
    "                \"cdn_server_id_key\": cdn_server_id_key,\n",
    "                \"cdn_server_id_value\": cdn_server_id_value,\n",
    "                \"cf_cache_status\": cf_cache_status,\n",
    "                \"x_cache\": x_cache,\n",
    "                \"x_cache_remote\": x_cache_remote,\n",
    "            }\n",
    "            cache_result.append(r)\n",
    "    return cache_result, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(daily_city_hitrates):\n",
    "    data_mean = {}\n",
    "    data_std = {}\n",
    "\n",
    "    ordered_cities = [\n",
    "        \"Vancouver\",\n",
    "        \"Lusaka-NBO\",\n",
    "        \"Lusaka-JNB\",\n",
    "        \"Accra\",\n",
    "        \"Berlin\",\n",
    "        \"Calgary\",\n",
    "        \"Toronto\",\n",
    "    ]\n",
    "    for city in ordered_cities:\n",
    "        daily_rates = daily_city_hitrates.get(city, [])\n",
    "        if len(daily_rates) == 0:\n",
    "            mean_hit = 0\n",
    "            std_hit = 0\n",
    "        else:\n",
    "            mean_hit = __builtins__.sum(daily_rates) / len(daily_rates)\n",
    "            std_hit = np.std(daily_rates) if len(daily_rates) > 1 else 0\n",
    "        data_mean[city] = mean_hit\n",
    "        data_std[city] = std_hit\n",
    "\n",
    "    for _, city in enumerate(ordered_cities):\n",
    "        mean_hit = data_mean[city]\n",
    "        std_hit = data_std[city]\n",
    "        print(f\"{country_mapping[city]} mean={mean_hit:.3f} std={std_hit:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Hit rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = []\n",
    "path = Path(webMsms_dir)\n",
    "for dirpath, dirnames, files in os.walk(path):\n",
    "    if len(files) != 0:\n",
    "        for f in files:\n",
    "            if f.endswith(\".json\"):\n",
    "                filename.append(Path(dirpath).joinpath(f))\n",
    "\n",
    "per_day_counts = {\n",
    "    \"Vancouver\": defaultdict(lambda: {\"hit\": 0, \"miss\": 0}),\n",
    "    \"Lusaka-NBO\": defaultdict(lambda: {\"hit\": 0, \"miss\": 0}),\n",
    "    \"Lusaka-JNB\": defaultdict(lambda: {\"hit\": 0, \"miss\": 0}),\n",
    "    \"Accra\": defaultdict(lambda: {\"hit\": 0, \"miss\": 0}),\n",
    "    \"Berlin\": defaultdict(lambda: {\"hit\": 0, \"miss\": 0}),\n",
    "    \"Calgary\": defaultdict(lambda: {\"hit\": 0, \"miss\": 0}),\n",
    "    \"Toronto\": defaultdict(lambda: {\"hit\": 0, \"miss\": 0}),\n",
    "}\n",
    "\n",
    "for i in range(len(filename)):\n",
    "    per_file_results, timestamp = parse_allinone(str(filename[i]))\n",
    "    if per_file_results is None:\n",
    "        continue\n",
    "\n",
    "    for j in range(len(per_file_results)):\n",
    "        domain = per_file_results[j][\"domain\"]\n",
    "        city = per_file_results[j][\"city\"]\n",
    "\n",
    "        if city not in unique_cities:\n",
    "            continue\n",
    "\n",
    "        linestyle = \"-\"\n",
    "\n",
    "        if city == \"Lusaka\":\n",
    "            if timestamp < datetime(2025, 4, 1, tzinfo=pytz.UTC):\n",
    "                city = \"Lusaka-NBO\"\n",
    "            else:\n",
    "                city = \"Lusaka-JNB\"\n",
    "                linestyle = \"dotted\"\n",
    "\n",
    "        cdn_server_id_key = per_file_results[j][\"cdn_server_id_key\"]\n",
    "        cdn_server_id_value = per_file_results[j][\"cdn_server_id_value\"]\n",
    "\n",
    "        if cdn_server_id_key == \"cf-ray\":\n",
    "            if city == \"Calgary\" and \"YYC\" not in cdn_server_id_value:\n",
    "                continue\n",
    "            if city == \"Toronto\" and \"YUL\" not in cdn_server_id_value:\n",
    "                continue\n",
    "            cache_status = per_file_results[j][\"cf_cache_status\"]\n",
    "\n",
    "            date_key = per_file_results[j][\"timestamp\"].date()\n",
    "            if cache_status in hit_statuses:\n",
    "                per_day_counts[city][date_key][\"hit\"] += 1\n",
    "            elif cache_status in miss_statuses:\n",
    "                per_day_counts[city][date_key][\"miss\"] += 1\n",
    "\n",
    "daily_city_hitrates = {\n",
    "    \"Vancouver\": [],\n",
    "    \"Lusaka-NBO\": [],\n",
    "    \"Lusaka-JNB\": [],\n",
    "    \"Accra\": [],\n",
    "    \"Berlin\": [],\n",
    "    \"Calgary\": [],\n",
    "    \"Toronto\": [],\n",
    "}\n",
    "for city, day_map in per_day_counts.items():\n",
    "    for day, counts in day_map.items():\n",
    "        total = counts[\"hit\"] + counts[\"miss\"]\n",
    "        if total > 0:\n",
    "            daily_city_hitrates[city].append(counts[\"hit\"] / total)\n",
    "\n",
    "plot(daily_city_hitrates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-to-first-byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "plt.rc(\"text\", usetex=True)\n",
    "rcParams[\"font.family\"] = \"CMU Sans Serif\"\n",
    "rcParams[\"font.size\"] = 10\n",
    "\n",
    "cols = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "country_mapping = {\n",
    "    \"Lusaka-NBO\": \"ZM (NBO PoP)\",\n",
    "    \"Lusaka-JNB\": \"ZM (JNB PoP)\",\n",
    "    \"Accra\": \"GH (LOS PoP)\",\n",
    "    \"Berlin\": \"DE (FRA PoP)\",\n",
    "    \"Vancouver\": \"CA (SEA PoP)\",\n",
    "    \"Calgary\": \"CA (YYC PoP)\",\n",
    "    \"Toronto\": \"CA (YUL PoP)\",\n",
    "}\n",
    "unique_cities = [\"Lusaka\", \"Accra\", \"Berlin\", \"Vancouver\", \"Calgary\", \"Toronto\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_allinone(filename: str):\n",
    "    data = json.load(open(filename, \"r\"))\n",
    "    timestamps = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "    timestamps = datetime.strptime(timestamps, \"%Y%m%dT%H%M%SZ\").replace(\n",
    "        tzinfo=pytz.UTC\n",
    "    )\n",
    "    user_details = data[\"user_details\"]\n",
    "    city = user_details[\"City\"]\n",
    "    country = user_details[\"Country\"]\n",
    "    cache_result = []\n",
    "    for domain, result in data[\"web_measurements\"].items():\n",
    "        dns_results = result[\"dns\"]\n",
    "        dns_result_q_default = float(dns_results[\"Default\"][\"query_time\"]) / 1000\n",
    "\n",
    "        if \"Google\" in dns_results:\n",
    "            dns_result_q_google = float(dns_results[\"Google\"][\"query_time\"]) / 1000\n",
    "        else:\n",
    "            dns_result_q_google = None\n",
    "\n",
    "        if \"Quad9\" in dns_results:\n",
    "            dns_result_q_quad9 = float(dns_results[\"Quad9\"][\"query_time\"]) / 1000\n",
    "        else:\n",
    "            dns_result_q_quad9 = None\n",
    "\n",
    "        if \"Cloudflare\" in dns_results:\n",
    "            dns_result_q_cloudflare = (\n",
    "                float(dns_results[\"Cloudflare\"][\"query_time\"]) / 1000\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            dns_result_q_cloudflare = None\n",
    "        curl_results = result[\"curl\"]\n",
    "        for ip, curl_resp in curl_results.items():\n",
    "            initconnect_time = curl_resp.get(\"initconnect_time\")\n",
    "            appconnect_time = curl_resp.get(\"appconnect_time\")\n",
    "            pretransfer_time = curl_resp.get(\"pretransfer_time\")\n",
    "            redirect_time = curl_resp.get(\"redirect_time\")\n",
    "            starttransfer_time = curl_resp.get(\"starttransfer_time\")\n",
    "            total_time = curl_resp.get(\"total_time\")\n",
    "            cdn_server_id_key = curl_resp.get(\"cdn_server_id_key\")\n",
    "            cdn_server_id_value = curl_resp.get(\"cdn_server_id_value\")\n",
    "            cf_cache_status = curl_resp.get(\"cf_cache_status\")\n",
    "            x_cache = curl_resp.get(\"x_cache\")\n",
    "            x_cache_remote = curl_resp.get(\"x_cache_remote\")\n",
    "\n",
    "            r = {\n",
    "                \"domain\": domain,\n",
    "                \"timestamp\": timestamps,\n",
    "                \"ip\": ip,\n",
    "                \"city\": city,\n",
    "                \"country\": country,\n",
    "                \"initconnect_time\": initconnect_time,\n",
    "                \"appconnect_time\": appconnect_time,\n",
    "                \"pretransfer_time\": pretransfer_time,\n",
    "                \"redirect_time\": redirect_time,\n",
    "                \"starttransfer_time\": starttransfer_time,\n",
    "                \"total_time\": total_time,\n",
    "                \"cdn_server_id_key\": cdn_server_id_key,\n",
    "                \"cdn_server_id_value\": cdn_server_id_value,\n",
    "                \"cf_cache_status\": cf_cache_status,\n",
    "                \"x_cache\": x_cache,\n",
    "                \"x_cache_remote\": x_cache_remote,\n",
    "                \"dns_query_time_default\": dns_result_q_default,\n",
    "                \"dns_query_time_google\": dns_result_q_google,\n",
    "                \"dns_query_time_quad9\": dns_result_q_quad9,\n",
    "                \"dns_query_time_cloudflare\": dns_result_q_cloudflare,\n",
    "                \"overall_total_time\": total_time + dns_result_q_default,\n",
    "            }\n",
    "            cache_result.append(r)\n",
    "            break\n",
    "    return cache_result, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_df() -> pd.DataFrame:\n",
    "    filename = []\n",
    "    path = Path(webMsms_dir)\n",
    "    for dirpath, _, files in os.walk(path):\n",
    "        if len(files) != 0:\n",
    "            for f in files:\n",
    "                if f.endswith(\".json\"):\n",
    "                    filename.append(Path(dirpath).joinpath(f))\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(filename)):\n",
    "        per_file_results, timestamp = parse_allinone(str(filename[i]))\n",
    "        if per_file_results is None:\n",
    "            continue\n",
    "\n",
    "        for j in range(len(per_file_results)):\n",
    "            country = per_file_results[j][\"country\"]\n",
    "            city = per_file_results[j][\"city\"]\n",
    "            if country in [\"US\", \"CH\"]:\n",
    "                continue\n",
    "            if city not in unique_cities:\n",
    "                continue\n",
    "\n",
    "            if city == \"Lusaka\":\n",
    "                if timestamp < datetime(2025, 4, 1, tzinfo=pytz.UTC):\n",
    "                    city = \"Lusaka-NBO\"\n",
    "                else:\n",
    "                    city = \"Lusaka-JNB\"\n",
    "                per_file_results[j][\"city\"] = city\n",
    "\n",
    "            results.append(per_file_results[j])\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.sort_values(\n",
    "        by=[\"city\", \"country\", \"timestamp\", \"cdn_server_id_key\", \"domain\"]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_plot(df: pd.DataFrame):\n",
    "    df = df[df[\"cdn_server_id_key\"] == \"cf-ray\"].copy()\n",
    "\n",
    "    for col in [\"total_time\", \"starttransfer_time\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"total_time\", \"starttransfer_time\"])\n",
    "\n",
    "    summary = (\n",
    "        df.groupby(\"city\")[[\"total_time\", \"starttransfer_time\"]]\n",
    "        .mean()\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"total_time\": \"mean_total_time\",\n",
    "                \"starttransfer_time\": \"mean_starttransfer_time\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    summary.to_csv(\"cf_ray_city_ttfb_summary.csv\", index=False)\n",
    "    print(\"Cloudflare (cf-ray) mean total_time and starttransfer_time by country:\")\n",
    "    print(summary)\n",
    "\n",
    "    ordered = [\n",
    "        \"Vancouver\",\n",
    "        \"Lusaka-NBO\",\n",
    "        \"Lusaka-JNB\",\n",
    "        \"Accra\",\n",
    "        \"Berlin\",\n",
    "        \"Calgary\",\n",
    "        \"Toronto\",\n",
    "    ]\n",
    "    summary = summary[summary[\"city\"].isin(ordered)].copy()\n",
    "    summary[\"city\"] = pd.Categorical(summary[\"city\"], categories=ordered, ordered=True)\n",
    "    summary = summary.sort_values(\"city\")\n",
    "\n",
    "    if summary.empty:\n",
    "        return\n",
    "\n",
    "    start_vals = summary[\"mean_starttransfer_time\"].values\n",
    "    total_vals = summary[\"mean_total_time\"].values\n",
    "    remaining = (total_vals - start_vals).clip(min=0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4.66, 2))\n",
    "    y = summary[\"city\"].values\n",
    "\n",
    "    ax.barh(\n",
    "        y, start_vals, color=cols[1], edgecolor=\"black\", label=\"Start Transfer (TTFB)\"\n",
    "    )\n",
    "    ax.barh(\n",
    "        y,\n",
    "        remaining,\n",
    "        left=start_vals,\n",
    "        color=cols[0],\n",
    "        edgecolor=\"black\",\n",
    "        label=\"Remaining Transfer\",\n",
    "    )\n",
    "\n",
    "    for yt, s, r in zip(y, start_vals, remaining):\n",
    "        ax.text(s + r + 0.01, yt, f\"{s + r:.2f}s\", va=\"center\", fontsize=8)\n",
    "\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels([country_mapping.get(c, c) for c in y])\n",
    "    ax.set_xlabel(\"Total Page Fetch Time [s]\")\n",
    "    ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.set_xlim(0, max(total_vals) * 1.15)\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"best\",\n",
    "        fontsize=\"small\",\n",
    "        edgecolor=\"k\",\n",
    "        handlelength=1,\n",
    "        labelspacing=0.06,\n",
    "        columnspacing=0.5,\n",
    "        handletextpad=0.3,\n",
    "        fancybox=False,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{figs_top_level_folder_path}/cf_ray_city_ttfb_bar.png\", dpi=300)\n",
    "    plt.savefig(f\"{figs_top_level_folder_path}/cf_ray_city_ttfb_bar.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_plot(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anotherenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
